{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Qadence Model","text":"<p>Qadence Model is a collection of features to enhance Qadence quantum machine learning features</p>"},{"location":"#pre-requisites","title":"Pre-requisites","text":"<p>The library uses the following tools:</p> <ul> <li>hatch for managing virtual environment and dependencies</li> <li>pytest for building the unit tests suite</li> <li>black, isort and flake8 for code formatting and linting</li> <li>mypy for static type checking</li> <li>pre-commit for applying linting and formatting automatically before committing new code</li> </ul> <p>We recommend to use <code>pyenv</code> for managing python versions for managing python versions both globally and locally:</p> <pre><code># System-wide install of a python version.\npyenv install 3.10\n\n# Use 3.10 everywhere.\npyenv global 3.10\n\n# Or locally in the current directory.\npyenv local 3.10\n</code></pre>"},{"location":"#install-from-pypi","title":"Install from PyPi","text":"<p><code>qadence-model</code> is available on PyPi through <code>pip</code>.</p> <pre><code>pip install qadence-model\n</code></pre>"},{"location":"#install-from-source","title":"Install from source","text":"<p>All Pasqal quantum libraries require Python &gt;=3.9. For development, the preferred method to install this package is to use <code>hatch</code>. You can install from source by cloning this repository and run:</p> <pre><code>python -m pip install hatch\npython -m hatch -v shell\n\n# execute any script using the library\npython my_script.py\n</code></pre> <p>Alternatively, you can also:</p> <ul> <li>install with <code>pip</code> in development mode by simply running <code>pip install -e .</code>. Notice that in this way   you will install all the dependencies, including extras.</li> <li>install it with <code>conda</code> by simply using <code>pip</code> inside the Conda environment.</li> </ul>"},{"location":"#develop","title":"Develop","text":"<p>When developing the package, the recommended way is to create a virtual environment with <code>hatch</code> as shown above:</p> <pre><code>python -m pip install hatch\npython -m hatch -v shell\n</code></pre> <p>When inside the shell with development dependencies, install first the pre-commit hook: <pre><code>pre-commit install\n</code></pre></p> <p>In this way, you will get automatic linting and formatting every time you commit new code. Do not forget to run the unit test suite by simply running the <code>pytest</code> command.</p> <p>If you do not want to get into the Hatch shell, you can alternatively do the following:</p> <pre><code>python -m pip install hatch\npython -m hatch -v shell\n\n# install the pre-commit\npython -m hatch run pre-commit install\n\n# commit some code\npython -m hatch run git commit -m \"My awesome commit\"\n\n# run the unit tests suite\npython -m hatch run pytest\n</code></pre>"},{"location":"#document","title":"Document","text":"<p>You can improve the documentation of the package by editing this file for the landing page or adding new markdown or Jupyter notebooks to the <code>docs/</code> folder in the root of the project. In order to modify the table of contents, edit the <code>mkdocs.yml</code> file in the root of the project.</p> <p>In order to build and serve the documentation locally, you can use <code>hatch</code> with the right environment:</p> <pre><code>python -m hatch -v run docs:build\npython -m hatch -v run docs:serve\n</code></pre> <p>If you don't want to use <code>hatch</code>, just check into your favorite virtual environment and execute the following commands:</p> <pre><code>python -m pip install -r docs/requirements.txt\nmkdocs build\nmkdocs serve\n</code></pre>"},{"location":"CODE_OF_CONDUCT/","title":"CODE OF CONDUCT","text":"<p>Code of Conduct</p>"},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"CONTRIBUTING/","title":"How to contribute","text":"<p>We're grateful for your interest in participating in qadence-model. Please follow our guidelines to ensure a smooth contribution process.</p>"},{"location":"CONTRIBUTING/#contribution-guide-for-developers","title":"Contribution Guide for Developers","text":"<ul> <li>Submitting Issues: To submit bug reports or feature requests, please use our issue tracker.</li> </ul>"},{"location":"CONTRIBUTING/#reporting-an-issue-or-proposing-a-feature","title":"Reporting an issue or proposing a feature","text":"<p>Your course of action will depend on your objective, but generally, you should start by creating an issue. If you've discovered a bug or have a feature you'd like to see added to qadence-model, feel free to create an issue on qadence-hubs's GitHub issue tracker. Here are some steps to take:</p> <ol> <li>Quickly search the existing issues using relevant keywords to ensure your issue hasn't been addressed already.</li> <li> <p>If your issue is not listed, create a new one. Try to be as detailed and clear as possible in your description.</p> </li> <li> <p>If you're merely suggesting an improvement or reporting a bug, that's already excellent! We thank you for it. Your issue will be listed and, hopefully, addressed at some point.</p> </li> </ol>"},{"location":"CONTRIBUTING/#setup-with-downloading-the-whole-git-repository","title":"Setup with downloading the whole git repository","text":"<p>To work with <code>qadence-model</code>, you should clone the entire GitHub repository and then access the individual projects. This approach is recommended for easier branch management, and cloning only a specific project is discouraged. After cloning the full repository, navigate to the desired project folder to run the Hatch environment or make code modifications. The example code snippet is like below:</p> <pre><code>git clone https://github.com/pasqal-io/qadence-hub.git\ncd qadence-hub/qadence-model\n</code></pre>"},{"location":"CONTRIBUTING/#making-pull-request","title":"Making Pull Request","text":"<p>If you\u2019ve modified the code of a <code>qadence-model</code> package, you should create a pull request targeting the <code>main-model</code> branch. Our branch structure manages each package through its corresponding <code>sub-main branch</code> before anything is merged into the <code>main branch</code>. Therefore, after cloning the repository, you should follow your previous workflow to create a local branch and push it\u2014but your pull request target should be your <code>main-model</code> branch, not <code>main</code>. After your branch is merged to <code>main-model</code> branch, you can initiate merge request to the <code>main</code> branch. Merging into <code>main</code> branch should be done only when a release is being prepared.</p>"},{"location":"CONTRIBUTING/#releasing-projects-and-publishing-to-pypi","title":"Releasing Projects and Publishing to PyPI","text":"<p>After you merge your <code>main-model</code> branch to <code>main</code> branch, you can publish your documents and Python package through release. To do this, you need to update the version number in the package's <code>pyproject.toml</code>. Then, you create a release with the format of <code>package_name-v.x.y.z,</code> where x, y, and z are for version numbers. For example, if you want to publish <code>qadence-model</code> with version 1.2.5, you must put <code>model-v1.2.5</code> as your release name.</p>"},{"location":"CONTRIBUTING/#setting-up-your-development-environment","title":"Setting up your development environment","text":"<p>We recommended to use <code>hatch</code> for managing environments.</p> <p>To develop within qadence-hub packages, use: <pre><code>cd qadence-model\npip install hatch\nhatch -v shell\n</code></pre></p>"},{"location":"CONTRIBUTING/#useful-thing-for-your-workflow-linting","title":"Useful thing for your workflow: linting","text":"<p>Use <code>pre-commit</code> to lint your code and run the unit tests before pushing a new commit.</p> <p>Using <code>hatch</code>, it's simply:</p> <pre><code>pre-commit install\nhatch -e tests run pre-commit run --all-files\n</code></pre> <p>Our CI/CD pipeline will also test if the documentation can be built correctly. To test it locally, please run:</p> <pre><code>hatch -e docs run mkdocs build --clean --strict\n</code></pre> <p>Without <code>hatch</code>, <code>pip</code> install those libraries first: \"mkdocs\", \"mkdocs-material\", \"mkdocstrings\", \"mkdocstrings-python\", \"mkdocs-section-index\", \"mkdocs-jupyter\", \"mkdocs-exclude\", \"markdown-exec\"</p> <p>And then:</p> <pre><code> mkdocs build --clean --strict\n</code></pre>"},{"location":"docsutils/","title":"Docsutils","text":"In\u00a0[\u00a0]: Copied! <pre>from __future__ import annotations\n</pre> from __future__ import annotations In\u00a0[\u00a0]: Copied! <pre>import itertools\nfrom io import StringIO\nfrom typing import Callable\n</pre> import itertools from io import StringIO from typing import Callable In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport torch\nfrom matplotlib.figure import Figure\n</pre> import numpy as np import torch from matplotlib.figure import Figure In\u00a0[\u00a0]: Copied! <pre>from qadence import (\n    QNN,\n    RX,\n    RY,\n    HamEvo,\n    Parameter,\n    QuantumCircuit,\n    Z,\n    add,\n    chain,\n    hea,\n    kron,\n    tag,\n)\nfrom qadence.blocks import AbstractBlock\n</pre> from qadence import (     QNN,     RX,     RY,     HamEvo,     Parameter,     QuantumCircuit,     Z,     add,     chain,     hea,     kron,     tag, ) from qadence.blocks import AbstractBlock In\u00a0[\u00a0]: Copied! <pre>def fig_to_html(fig: Figure) -&gt; str:\n    buffer = StringIO()\n    fig.savefig(buffer, format=\"svg\")\n    return buffer.getvalue()\n</pre> def fig_to_html(fig: Figure) -&gt; str:     buffer = StringIO()     fig.savefig(buffer, format=\"svg\")     return buffer.getvalue() In\u00a0[\u00a0]: Copied! <pre>def hardware_efficient_ansatz(n_qubits: int = 2, depth: int = 1) -&gt; AbstractBlock:\n    return hea(n_qubits=n_qubits, depth=depth)\n</pre> def hardware_efficient_ansatz(n_qubits: int = 2, depth: int = 1) -&gt; AbstractBlock:     return hea(n_qubits=n_qubits, depth=depth) In\u00a0[\u00a0]: Copied! <pre>def digital_analog_ansatz(\n    h_generator: AbstractBlock, n_qubits: int = 2, depth: int = 1, t_evo: float = 1.0\n) -&gt; AbstractBlock:\n    time_evolution = HamEvo(h_generator, t_evo)\n\n    it = itertools.count()\n    ops = []\n    for _ in range(depth):\n        layer = kron(\n            *[\n                chain(*(gate(n, f\"theta{next(it)}\") for gate in [RX, RY, RX]))\n                for n in range(n_qubits)\n            ]\n        )\n        ops.append(chain(layer, time_evolution))\n    return chain(*ops)\n</pre> def digital_analog_ansatz(     h_generator: AbstractBlock, n_qubits: int = 2, depth: int = 1, t_evo: float = 1.0 ) -&gt; AbstractBlock:     time_evolution = HamEvo(h_generator, t_evo)      it = itertools.count()     ops = []     for _ in range(depth):         layer = kron(             *[                 chain(*(gate(n, f\"theta{next(it)}\") for gate in [RX, RY, RX]))                 for n in range(n_qubits)             ]         )         ops.append(chain(layer, time_evolution))     return chain(*ops) In\u00a0[\u00a0]: Copied! <pre>def qcl_circuit(n_qubits: int = 2, depth: int = 1, use_digital_analog: bool = False):\n    # Chebyshev feature map with input parameter defined as non trainable\n    phi = Parameter(\"phi\", trainable=False)\n    fm = chain(*[RY(i, phi) for i in range(n_qubits)])\n    tag(fm, \"feature_map\")\n\n    if not use_digital_analog:\n        # hardware-efficient ansatz\n        ansatz = hardware_efficient_ansatz(n_qubits=n_qubits, depth=depth)\n    else:\n        # Hamiltonian evolution ansatz (digital-analog)\n        t_evo = 3.0  # length of the time evolution\n        h_generator = add(\n            *[Z(i) for i in range(n_qubits)]\n        )  # use total magnetization as Hamiltonian\n        ansatz = digital_analog_ansatz(h_generator, n_qubits=n_qubits, depth=depth, t_evo=t_evo)\n\n    tag(ansatz, \"ansatz\")\n\n    # add a final fixed layer or rotations\n    fixed_layer = chain(*[RY(i, np.pi / 2) for i in range(n_qubits)])\n    tag(fixed_layer, \"fixed\")\n\n    blocks = [fm, ansatz, fixed_layer]\n    return QuantumCircuit(n_qubits, *blocks)\n</pre> def qcl_circuit(n_qubits: int = 2, depth: int = 1, use_digital_analog: bool = False):     # Chebyshev feature map with input parameter defined as non trainable     phi = Parameter(\"phi\", trainable=False)     fm = chain(*[RY(i, phi) for i in range(n_qubits)])     tag(fm, \"feature_map\")      if not use_digital_analog:         # hardware-efficient ansatz         ansatz = hardware_efficient_ansatz(n_qubits=n_qubits, depth=depth)     else:         # Hamiltonian evolution ansatz (digital-analog)         t_evo = 3.0  # length of the time evolution         h_generator = add(             *[Z(i) for i in range(n_qubits)]         )  # use total magnetization as Hamiltonian         ansatz = digital_analog_ansatz(h_generator, n_qubits=n_qubits, depth=depth, t_evo=t_evo)      tag(ansatz, \"ansatz\")      # add a final fixed layer or rotations     fixed_layer = chain(*[RY(i, np.pi / 2) for i in range(n_qubits)])     tag(fixed_layer, \"fixed\")      blocks = [fm, ansatz, fixed_layer]     return QuantumCircuit(n_qubits, *blocks) In\u00a0[\u00a0]: Copied! <pre>def qcl_training_data(\n    fn: Callable, domain: tuple = (0, 2 * np.pi), n_teacher: int = 100\n) -&gt; tuple[torch.tensor, torch.tensor]:\n    start, end = domain\n    x_rand_np = np.sort(np.random.uniform(low=start, high=end, size=n_teacher))\n    y_rand_np = fn(x_rand_np)\n\n    x_rand = torch.tensor(x_rand_np)\n    y_rand = torch.tensor(y_rand_np)\n\n    return x_rand, y_rand\n</pre> def qcl_training_data(     fn: Callable, domain: tuple = (0, 2 * np.pi), n_teacher: int = 100 ) -&gt; tuple[torch.tensor, torch.tensor]:     start, end = domain     x_rand_np = np.sort(np.random.uniform(low=start, high=end, size=n_teacher))     y_rand_np = fn(x_rand_np)      x_rand = torch.tensor(x_rand_np)     y_rand = torch.tensor(y_rand_np)      return x_rand, y_rand In\u00a0[\u00a0]: Copied! <pre>def qcl_train_model(\n    model: QNN, x_train: torch.Tensor, y_train: torch.Tensor, n_epochs: int = 50, lr: float = 1.0\n) -&gt; QNN:\n    mse_loss = torch.nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    print(f\"Initial loss: {mse_loss(model(x_train), y_train)}\")\n\n    for i in range(n_epochs):\n        optimizer.zero_grad()\n\n        loss = mse_loss(model(x_train), y_train)\n        loss.backward()\n        optimizer.step()\n\n        if (i + 1) % 10 == 0:\n            print(f\"Epoch {i+1} training - Loss: {loss.item()}\")\n\n    return model\n</pre> def qcl_train_model(     model: QNN, x_train: torch.Tensor, y_train: torch.Tensor, n_epochs: int = 50, lr: float = 1.0 ) -&gt; QNN:     mse_loss = torch.nn.MSELoss()     optimizer = torch.optim.Adam(model.parameters(), lr=lr)      print(f\"Initial loss: {mse_loss(model(x_train), y_train)}\")      for i in range(n_epochs):         optimizer.zero_grad()          loss = mse_loss(model(x_train), y_train)         loss.backward()         optimizer.step()          if (i + 1) % 10 == 0:             print(f\"Epoch {i+1} training - Loss: {loss.item()}\")      return model"},{"location":"model/","title":"Variational quantum algorithms","text":"<p>Variational algorithms on noisy devices and quantum machine learning (QML)[^1] in particular are one of the main target applications for Qadence. For this purpose, the library offers both flexible symbolic expressions for the quantum circuit parameters via <code>sympy</code> for more details and native automatic differentiation via integration with PyTorch deep learning framework.</p> <p>Furthermore, Qadence-Model offers a wide range of utilities for helping building and researching quantum machine learning algorithms.</p>"},{"location":"model/#some-simple-examples","title":"Some simple examples","text":"<p>Qadence-Model symbolic parameter interface allows to create arbitrary feature maps to encode classical data into quantum circuits with an arbitrary non-linear function embedding for the input values:</p> <pre><code>import qadence as qd\nimport qadence_model as qdm\nfrom qadence.operations import *\nimport torch\nfrom sympy import acos\n\nn_qubits = 4\n\n# Example feature map, also directly available with the `feature_map` function\nfp = qd.FeatureParameter(\"phi\")\nfm = qd.kron(RX(i, acos(fp)) for i in range(n_qubits))\n\n# the key in the dictionary must correspond to\n# the name of the assigned to the feature parameter\ninputs = {\"phi\": torch.rand(3)}\nsamples = qd.sample(fm, values=inputs)\n</code></pre> <pre><code>samples = OrderedCounter({'1001': 13, '0110': 9, '1010': 8, '0100': 7, '0101': 7, '1000': 7, '1100': 7, '0000': 6, '0011': 6, '1111': 6, '0001': 5, '0010': 5, '0111': 5, '1011': 3, '1101': 3, '1110': 3})\n</code></pre> <p>The <code>constructors.feature_map</code> module provides convenience functions to build commonly used feature maps where the input parameter is encoded in the single-qubit gates rotation angle.</p> <p>Furthermore, Qadence-Model is natively integrated with PyTorch automatic differentiation engine thus Qadence-Model quantum models can be used seamlessly in a PyTorch workflow.</p> <p>Let's create a quantum neural network model using the feature map just defined, a digital-analog variational ansatz and a simple observable \\(X(0) \\otimes X(1)\\). We use the convenience <code>QNN</code> quantum model abstraction.</p> <pre><code>ansatz = qd.hea(n_qubits, strategy=\"sDAQC\")\ncircuit = qd.QuantumCircuit(n_qubits, fm, ansatz)\nobservable = qd.kron(X(0), X(1))\n\nmodel = qdm.models.QNN(circuit, observable)\n\n# NOTE: the `QNN` is a torch.nn.Module\nassert isinstance(model, torch.nn.Module)\n</code></pre> <pre><code>True\n</code></pre> <p>Differentiation works the same way as any other PyTorch module:</p> <pre><code>values = {\"phi\": torch.rand(10, requires_grad=True)}\n\n# the forward pass of the quantum model returns the expectation\n# value of the input observable\nout = model(values)\n\n# you can compute the gradient with respect to inputs using\n# PyTorch autograd differentiation engine\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: \\n{dout}\")\n\n# you can also call directly a backward pass to compute derivatives with respect\n# to the variational parameters and use it for implementing variational\n# optimization\nout.sum().backward()\n</code></pre> <pre><code>Quantum model output: \ntensor([[0.5581],\n        [0.4988],\n        [0.5217],\n        [0.5669],\n        [0.5522],\n        [0.1700],\n        [0.2975],\n        [0.4590],\n        [0.5629],\n        [0.5311]], grad_fn=&lt;CatBackward0&gt;)\n\nFirst-order derivative w.r.t. the feature parameter: \ntensor([-0.2620,  0.5354,  0.4532, -0.1103,  0.2848, -2.8937, -1.8146, -0.9547,\n        -0.1935,  0.4117], grad_fn=&lt;MulBackward0&gt;)\n</code></pre> <p>To run QML on real devices, Qadence-Model offers generalized parameter shift rules (GPSR) <sup>1</sup> for arbitrary quantum operations which can be selected when constructing the <code>QNN</code> model:</p> <pre><code>model = qdm.models.QNN(circuit, observable, diff_mode=\"gpsr\")\nout = model(values)\n\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: \\n{dout}\")\n</code></pre> <pre><code>First-order derivative w.r.t. the feature parameter: \ntensor([-0.2620,  0.5354,  0.4532, -0.1103,  0.2848, -2.8937, -1.8146, -0.9547,\n        -0.1935,  0.4117], grad_fn=&lt;MulBackward0&gt;)\n</code></pre>"},{"location":"model/#references","title":"References","text":"<p>[^1] Schuld, Petruccione, Machine learning on Quantum Computers, Springer Nature (2021)</p> <ol> <li> <p>Kyriienko et al., General quantum circuit differentiation rules \u21a9</p> </li> </ol>"},{"location":"model/classification/","title":"Classification with QNN","text":"<p>In this tutorial we will show how to use Qadence-Model to solve a basic classification task using a hybrid quantum-classical model composed of a QNN and classical layers.</p>"},{"location":"model/classification/#dataset","title":"Dataset","text":"<p>We will use the Iris dataset separated into training and testing sets. The task is to classify iris plants presented as a multivariate dataset of 4 features into 3 labels (Iris Setosa, Iris Versicolour, or Iris Virginica). When applying machine learning models, and particularly neural networks, it is recommended to normalize the data. As such, we use a common StandardScaler (we transform the data \\(x\\) to \\(z = (x - u) / s\\) where \\(u, s\\) are respectively the mean and standard deviation of the training samples).</p> <pre><code>import random\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom torch import Tensor\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom qadence import RX, FeatureParameter, QuantumCircuit, Z, chain, hea, kron\nfrom qadence_model.models import QNN\nfrom perceptrain import TrainConfig, Trainer\n\nclass IrisDataset(Dataset):\n    \"\"\"The Iris dataset split into a training set and a test set.\n\n    A StandardScaler is applied prior to applying models.\n    \"\"\"\n\n    def __init__(self):\n        X, y = load_iris(return_X_y=True)\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n        self.scaler = StandardScaler()\n        self.scaler.fit(X_train)\n        self.X = torch.tensor(self.scaler.transform(X_train), requires_grad=False)\n        self.y = torch.tensor(y_train, requires_grad=False)\n\n        self.X_test = torch.tensor(self.scaler.transform(X_test), requires_grad=False)\n        self.y_test = torch.tensor(y_test, requires_grad=False)\n\n    def __getitem__(self, index) -&gt; tuple[Tensor, Tensor]:\n        return self.X[index], self.y[index]\n\n    def __len__(self) -&gt; int:\n        return len(self.y)\n\nn_features = 4  # sepal length, sepal width, petal length, petal width\nn_layers = 3\nn_neurons_final_linear_layer = 3\nn_epochs = 1000\nlr = 1e-1\ndataset = IrisDataset()\n\ndataloader = DataLoader(dataset, batch_size=20, shuffle=True)\n</code></pre>"},{"location":"model/classification/#hybrid-qnn","title":"Hybrid QNN","text":"<p>We set up the QNN part composed of multiple feature map layers, each followed by a variational layer. The type of variational layer we use is the hardware-efficient-ansatz (HEA). The output will be the expectation value with respect to a \\(Z\\) observable on qubit \\(0\\). Then we add a simple linear layer serving as a classification head. This is equivalent to applying a weight matrix \\(W\\) and bias vector \\(b\\) to the output of the QNN denoted \\(o\\), \\(l = W * o + b\\). To obtain probabilities, we can apply the softmax function defined as: \\(p_i = \\exp(l_i) / \\sum_{j=1}^3 \\exp(l_i)\\). Note softmax is not applied during training with the cross-entropy loss.</p> <pre><code>feature_parameters = [FeatureParameter(f\"x_{i}\") for i in range(n_features)]\nfm_layer = RX(0, feature_parameters[0])\nfor q in range(1, n_features):\n    fm_layer = kron(fm_layer, RX(q, feature_parameters[q]))\n\nansatz_layers = [\n    hea(n_qubits=n_features, depth=1, param_prefix=f\"theta_{layer}\")\n    for layer in range(n_layers)\n]\nblocks = chain(fm_layer, ansatz_layers[0])\nfor layer in range(1, n_layers):\n    blocks = chain(blocks, fm_layer, ansatz_layers[layer])\n\nqc = QuantumCircuit(n_features, blocks)\nqnn = QNN(circuit=qc, observable=Z(0), inputs=[f\"x_{i}\" for i in range(n_features)])\nmodel = nn.Sequential(qnn, nn.Linear(1, n_neurons_final_linear_layer))\n</code></pre> <p>Below is a visualization of the QNN:</p> <pre><code>\n</code></pre> %3 cluster_d61084cf23c9472bbe2eb7ae3e4c11cc HEA cluster_031c93a55b674443833f54361d4d02e0 Obs. cluster_59747e8f19bb40b187361d0bc53e55cb HEA cluster_d713b61cf91249a2907a339b50b11833 HEA 26561df81224460b97c92e3f8464e4af 0 b70c2c2a1d19489ba8ba8fafd181f826 RX(x\u2080) 26561df81224460b97c92e3f8464e4af--b70c2c2a1d19489ba8ba8fafd181f826 31964023033141469552d7634d0363d8 1 681cbdbe9d274f57b7bf1d1047891bc9 RX(theta\u2080\u2080) b70c2c2a1d19489ba8ba8fafd181f826--681cbdbe9d274f57b7bf1d1047891bc9 dd5bba0891d94334bc4c31fc14558662 RY(theta\u2080\u2084) 681cbdbe9d274f57b7bf1d1047891bc9--dd5bba0891d94334bc4c31fc14558662 8c9e07f3641e4752bfd6f7954cb10f37 RX(theta\u2080\u2088) dd5bba0891d94334bc4c31fc14558662--8c9e07f3641e4752bfd6f7954cb10f37 9f7e85bcbd3c4e1e84b446a618e8b75a 8c9e07f3641e4752bfd6f7954cb10f37--9f7e85bcbd3c4e1e84b446a618e8b75a b8aff1ace3524eb898d4bbb71f50aea7 9f7e85bcbd3c4e1e84b446a618e8b75a--b8aff1ace3524eb898d4bbb71f50aea7 98a27325c17b4fb2a0bafa374f46adc7 RX(x\u2080) b8aff1ace3524eb898d4bbb71f50aea7--98a27325c17b4fb2a0bafa374f46adc7 5ad7660b6430424586cf87c3a5bf3070 RX(theta\u2081\u2080) 98a27325c17b4fb2a0bafa374f46adc7--5ad7660b6430424586cf87c3a5bf3070 f7c76359a89b42ec9cc0f815718b871c RY(theta\u2081\u2084) 5ad7660b6430424586cf87c3a5bf3070--f7c76359a89b42ec9cc0f815718b871c d72a80e5ec9945f5bf2b97ba4cd81417 RX(theta\u2081\u2088) f7c76359a89b42ec9cc0f815718b871c--d72a80e5ec9945f5bf2b97ba4cd81417 7e7cd5ad79224bddb40945f161ab8d92 d72a80e5ec9945f5bf2b97ba4cd81417--7e7cd5ad79224bddb40945f161ab8d92 c9d41049c7c04879b487d534eeb4f27a 7e7cd5ad79224bddb40945f161ab8d92--c9d41049c7c04879b487d534eeb4f27a ed296b914f0e4d0cbe2d46f4ea23a6fe RX(x\u2080) c9d41049c7c04879b487d534eeb4f27a--ed296b914f0e4d0cbe2d46f4ea23a6fe fe45b4c2fede4fc69f868bf2575f8ded RX(theta\u2082\u2080) ed296b914f0e4d0cbe2d46f4ea23a6fe--fe45b4c2fede4fc69f868bf2575f8ded 74abc75ef89040728c10ce4aae62d96c RY(theta\u2082\u2084) fe45b4c2fede4fc69f868bf2575f8ded--74abc75ef89040728c10ce4aae62d96c 70fd7a0d3c8940a2b38c87c5ae481c77 RX(theta\u2082\u2088) 74abc75ef89040728c10ce4aae62d96c--70fd7a0d3c8940a2b38c87c5ae481c77 4c96109d99974d118278d11fc796c081 70fd7a0d3c8940a2b38c87c5ae481c77--4c96109d99974d118278d11fc796c081 9a2b2768f08a4371897d9bba65770753 4c96109d99974d118278d11fc796c081--9a2b2768f08a4371897d9bba65770753 18b5cedf1c4743a0a86f80a9ebc42318 Z 9a2b2768f08a4371897d9bba65770753--18b5cedf1c4743a0a86f80a9ebc42318 6c7c8e32ff4a46238aa008e8b6f81c3b 18b5cedf1c4743a0a86f80a9ebc42318--6c7c8e32ff4a46238aa008e8b6f81c3b 6b47d99509084564a2da0bf47f41fece e187046f111f4c4a87459ad583458bc4 RX(x\u2081) 31964023033141469552d7634d0363d8--e187046f111f4c4a87459ad583458bc4 bc60dcf5a54f4f459944257af29b8015 2 246e28fd3cb14fc9a9b29dff3177af7d RX(theta\u2080\u2081) e187046f111f4c4a87459ad583458bc4--246e28fd3cb14fc9a9b29dff3177af7d 1715180eebc34d8c98a00d98ad5a91d2 RY(theta\u2080\u2085) 246e28fd3cb14fc9a9b29dff3177af7d--1715180eebc34d8c98a00d98ad5a91d2 ce1c70e5fc4b4513821d2a373290cf83 RX(theta\u2080\u2089) 1715180eebc34d8c98a00d98ad5a91d2--ce1c70e5fc4b4513821d2a373290cf83 17d0d1cb9a454450ba96bc0d8701c3b9 X ce1c70e5fc4b4513821d2a373290cf83--17d0d1cb9a454450ba96bc0d8701c3b9 17d0d1cb9a454450ba96bc0d8701c3b9--9f7e85bcbd3c4e1e84b446a618e8b75a 53be0ae6fc7f4e1b80b2966051611957 17d0d1cb9a454450ba96bc0d8701c3b9--53be0ae6fc7f4e1b80b2966051611957 6d8c70d2102f47e2af2ad70d91d34a58 RX(x\u2081) 53be0ae6fc7f4e1b80b2966051611957--6d8c70d2102f47e2af2ad70d91d34a58 ff02482d044f4ef9bd458561cf0bab0e RX(theta\u2081\u2081) 6d8c70d2102f47e2af2ad70d91d34a58--ff02482d044f4ef9bd458561cf0bab0e c39d1785c18e4ca3bc069ec24e809d86 RY(theta\u2081\u2085) ff02482d044f4ef9bd458561cf0bab0e--c39d1785c18e4ca3bc069ec24e809d86 fe3c93678f4c43f58e2b7809e5ecd242 RX(theta\u2081\u2089) c39d1785c18e4ca3bc069ec24e809d86--fe3c93678f4c43f58e2b7809e5ecd242 f50225dfcd2b462a912d060ae52f0ad0 X fe3c93678f4c43f58e2b7809e5ecd242--f50225dfcd2b462a912d060ae52f0ad0 f50225dfcd2b462a912d060ae52f0ad0--7e7cd5ad79224bddb40945f161ab8d92 e938b5e262c74146855c082da743850b f50225dfcd2b462a912d060ae52f0ad0--e938b5e262c74146855c082da743850b 3571864709af472ca39a936a502302f9 RX(x\u2081) e938b5e262c74146855c082da743850b--3571864709af472ca39a936a502302f9 5ff8056fceb24df7aaf7555350a18ff9 RX(theta\u2082\u2081) 3571864709af472ca39a936a502302f9--5ff8056fceb24df7aaf7555350a18ff9 153abc3091c541e180038122a1cfd4f3 RY(theta\u2082\u2085) 5ff8056fceb24df7aaf7555350a18ff9--153abc3091c541e180038122a1cfd4f3 384131752d64442996f407c14eafa367 RX(theta\u2082\u2089) 153abc3091c541e180038122a1cfd4f3--384131752d64442996f407c14eafa367 ecd86417b5694e879c574f4bfedfc8bd X 384131752d64442996f407c14eafa367--ecd86417b5694e879c574f4bfedfc8bd ecd86417b5694e879c574f4bfedfc8bd--4c96109d99974d118278d11fc796c081 db9fb009064949518b5e413acf2465fd ecd86417b5694e879c574f4bfedfc8bd--db9fb009064949518b5e413acf2465fd 21968238cc16498d9c9024c5a679466e db9fb009064949518b5e413acf2465fd--21968238cc16498d9c9024c5a679466e 21968238cc16498d9c9024c5a679466e--6b47d99509084564a2da0bf47f41fece 4743fcf12314406dbca41dc0f3cd6236 b7e81d3a487144e3a750bde4ff26440b RX(x\u2082) bc60dcf5a54f4f459944257af29b8015--b7e81d3a487144e3a750bde4ff26440b 622a531f4d1344609cb86fbc27f2c4fd 3 dea3ec74927e41bfadaa1ec7b68e7937 RX(theta\u2080\u2082) b7e81d3a487144e3a750bde4ff26440b--dea3ec74927e41bfadaa1ec7b68e7937 6ef3726b0e0d4d41949bc2eb673bacee RY(theta\u2080\u2086) dea3ec74927e41bfadaa1ec7b68e7937--6ef3726b0e0d4d41949bc2eb673bacee 8d46d3819e354b239bbdb88971a2657f RX(theta\u2080\u2081\u2080) 6ef3726b0e0d4d41949bc2eb673bacee--8d46d3819e354b239bbdb88971a2657f d4f61aff26764de2a6cb437350aacf5a 8d46d3819e354b239bbdb88971a2657f--d4f61aff26764de2a6cb437350aacf5a 19d093c48b864699a33d251c024d3260 X d4f61aff26764de2a6cb437350aacf5a--19d093c48b864699a33d251c024d3260 19d093c48b864699a33d251c024d3260--53be0ae6fc7f4e1b80b2966051611957 2301e432a9b3488d8a7d856cf7acb47d RX(x\u2082) 19d093c48b864699a33d251c024d3260--2301e432a9b3488d8a7d856cf7acb47d 840d0e1c637844e9a1428800a5f93ac7 RX(theta\u2081\u2082) 2301e432a9b3488d8a7d856cf7acb47d--840d0e1c637844e9a1428800a5f93ac7 2e7c02fdfe8e42f6833c8c0231e5fd6d RY(theta\u2081\u2086) 840d0e1c637844e9a1428800a5f93ac7--2e7c02fdfe8e42f6833c8c0231e5fd6d 9bc4821f615a40669a4fa6e5aa0e3ba1 RX(theta\u2081\u2081\u2080) 2e7c02fdfe8e42f6833c8c0231e5fd6d--9bc4821f615a40669a4fa6e5aa0e3ba1 ad14f1fc2dd54fa1a86a9444ac7dfca6 9bc4821f615a40669a4fa6e5aa0e3ba1--ad14f1fc2dd54fa1a86a9444ac7dfca6 33208105e49e4b9b8341e6d0770e9831 X ad14f1fc2dd54fa1a86a9444ac7dfca6--33208105e49e4b9b8341e6d0770e9831 33208105e49e4b9b8341e6d0770e9831--e938b5e262c74146855c082da743850b f63eb9ac053f4b29acf6bb3c477af43a RX(x\u2082) 33208105e49e4b9b8341e6d0770e9831--f63eb9ac053f4b29acf6bb3c477af43a 4793382676e24de9bc11b12fd997f687 RX(theta\u2082\u2082) f63eb9ac053f4b29acf6bb3c477af43a--4793382676e24de9bc11b12fd997f687 804f94c02f26417e91c746eb2ee7ba4d RY(theta\u2082\u2086) 4793382676e24de9bc11b12fd997f687--804f94c02f26417e91c746eb2ee7ba4d b30ee8f36a8047cfa9a797986fc9022b RX(theta\u2082\u2081\u2080) 804f94c02f26417e91c746eb2ee7ba4d--b30ee8f36a8047cfa9a797986fc9022b a6db1509747b4e6d90eba626c85ec743 b30ee8f36a8047cfa9a797986fc9022b--a6db1509747b4e6d90eba626c85ec743 cc00fcff958e42e1a7048278f1a3a0d2 X a6db1509747b4e6d90eba626c85ec743--cc00fcff958e42e1a7048278f1a3a0d2 cc00fcff958e42e1a7048278f1a3a0d2--db9fb009064949518b5e413acf2465fd 13a22342da8340d59815df740e8554c8 cc00fcff958e42e1a7048278f1a3a0d2--13a22342da8340d59815df740e8554c8 13a22342da8340d59815df740e8554c8--4743fcf12314406dbca41dc0f3cd6236 0a557949921a4614ae851beb59e35bf7 3013704215cd4ab2ac927e3b977862c7 RX(x\u2083) 622a531f4d1344609cb86fbc27f2c4fd--3013704215cd4ab2ac927e3b977862c7 fd30f4e5d2194cec9ebf453a1a89b7b6 RX(theta\u2080\u2083) 3013704215cd4ab2ac927e3b977862c7--fd30f4e5d2194cec9ebf453a1a89b7b6 c655e391abc148eaac9078aeaf2bd008 RY(theta\u2080\u2087) fd30f4e5d2194cec9ebf453a1a89b7b6--c655e391abc148eaac9078aeaf2bd008 3a62e7dc84fa44279c68a8569f6f8fd0 RX(theta\u2080\u2081\u2081) c655e391abc148eaac9078aeaf2bd008--3a62e7dc84fa44279c68a8569f6f8fd0 3f00310b60554168842da10d06c9a530 X 3a62e7dc84fa44279c68a8569f6f8fd0--3f00310b60554168842da10d06c9a530 3f00310b60554168842da10d06c9a530--d4f61aff26764de2a6cb437350aacf5a 3bb9548bce904caf93ef64c6649aae9b 3f00310b60554168842da10d06c9a530--3bb9548bce904caf93ef64c6649aae9b 5854dcb9187a476d9e7591676c7b9301 RX(x\u2083) 3bb9548bce904caf93ef64c6649aae9b--5854dcb9187a476d9e7591676c7b9301 ce3d452137c441d5a882d513e0f16b42 RX(theta\u2081\u2083) 5854dcb9187a476d9e7591676c7b9301--ce3d452137c441d5a882d513e0f16b42 df66e6365caa4e80a7cb7844696516e5 RY(theta\u2081\u2087) ce3d452137c441d5a882d513e0f16b42--df66e6365caa4e80a7cb7844696516e5 ca7fc4273955407393ccd7de18b6675e RX(theta\u2081\u2081\u2081) df66e6365caa4e80a7cb7844696516e5--ca7fc4273955407393ccd7de18b6675e b88e4a04a81d4c2a99587cc1f2c2fa56 X ca7fc4273955407393ccd7de18b6675e--b88e4a04a81d4c2a99587cc1f2c2fa56 b88e4a04a81d4c2a99587cc1f2c2fa56--ad14f1fc2dd54fa1a86a9444ac7dfca6 05f4c2d6f4fc46f2869debc6dbfc8aba b88e4a04a81d4c2a99587cc1f2c2fa56--05f4c2d6f4fc46f2869debc6dbfc8aba d3dd4d2e901942c7b9712c2d1715f804 RX(x\u2083) 05f4c2d6f4fc46f2869debc6dbfc8aba--d3dd4d2e901942c7b9712c2d1715f804 071143b25c3f4de588af9da4dcae7917 RX(theta\u2082\u2083) d3dd4d2e901942c7b9712c2d1715f804--071143b25c3f4de588af9da4dcae7917 d2ad3cdbfb594504871f60b39ce0cedf RY(theta\u2082\u2087) 071143b25c3f4de588af9da4dcae7917--d2ad3cdbfb594504871f60b39ce0cedf 4032f54e0320475da02acb23ffef017f RX(theta\u2082\u2081\u2081) d2ad3cdbfb594504871f60b39ce0cedf--4032f54e0320475da02acb23ffef017f ede5cc2603694edbbc915f2ed7510c9d X 4032f54e0320475da02acb23ffef017f--ede5cc2603694edbbc915f2ed7510c9d ede5cc2603694edbbc915f2ed7510c9d--a6db1509747b4e6d90eba626c85ec743 9dc208829a53415ab9e97c95972f3c1c ede5cc2603694edbbc915f2ed7510c9d--9dc208829a53415ab9e97c95972f3c1c 2ab237fb28c14e49b6b116d793c93faa 9dc208829a53415ab9e97c95972f3c1c--2ab237fb28c14e49b6b116d793c93faa 2ab237fb28c14e49b6b116d793c93faa--0a557949921a4614ae851beb59e35bf7"},{"location":"model/classification/#training","title":"Training","text":"<p>Then we can set up the training part:</p> <pre><code>opt = torch.optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()\n\ndef cross_entropy(model: nn.Module, data: Tensor) -&gt; tuple[Tensor, dict]:\n    x, y = data\n    out = model(x)\n    loss = criterion(out, y)\n    return loss, {}\n\ntrain_config = TrainConfig(max_iter=n_epochs, print_every=10, create_subfolder_per_run=True)\nTrainer.set_use_grad(True)\ntrainer = Trainer(model=model, optimizer=opt, config=train_config, loss_fn=cross_entropy)\n\n\nres_train = trainer.fit(dataloader)\n</code></pre>"},{"location":"model/classification/#inference","title":"Inference","text":"<p>Finally, we can apply our model on the test set and check the score.</p> <pre><code>X_test, y_test = dataset.X_test, dataset.y_test\npreds_test = torch.argmax(torch.softmax(model(X_test), dim=1), dim=1)\naccuracy_test = (preds_test == y_test).type(torch.float32).mean()\n## Should reach higher than 0.9\n</code></pre>   Test Accuracy: 0.9399999976158142"},{"location":"model/dqc_1d/","title":"Solving a 1D ODE","text":"<p>In this tutorial we will show how to use Qadence-Model to solve a basic 1D Ordinary Differential Equation (ODE) with a QNN using Differentiable Quantum Circuits (DQC) <sup>1</sup>.</p> <p>Consider the following non-linear ODE and boundary condition:</p> \\[ \\frac{df}{dx}= 5\\times(4x^3+x^2-2x-\\frac12), \\qquad f(0)=0 \\] <p>It admits an exact solution:</p> \\[ f(x)=5\\times(x^4+\\frac13x^3-x^2-\\frac12x) \\] <p>Our goal will be to find this solution for \\(x\\in[-1, 1]\\).</p> <pre><code>import torch\n\ndef dfdx_equation(x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Derivative as per the equation.\"\"\"\n    return 5*(4*x**3 + x**2 - 2*x - 0.5)\n</code></pre> <p>For the purpose of this tutorial, we will compute the derivative of the circuit using <code>torch.autograd</code>. The point of the DQC algorithm is to use differentiable circuits with parameter shift rules. In Qadence, PSR is implemented directly as custom overrides of the derivative function in the autograd engine, and thus we can later change the derivative method for the model itself if we wish.</p> <pre><code>def calc_deriv(outputs: torch.Tensor, inputs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Compute a derivative of model that learns f(x), computes df/dx using torch.autograd.\"\"\"\n    grad = torch.autograd.grad(\n        outputs=outputs,\n        inputs=inputs,\n        grad_outputs = torch.ones_like(inputs),\n        create_graph = True,\n        retain_graph = True,\n    )[0]\n    return grad\n</code></pre>"},{"location":"model/dqc_1d/#defining-the-loss-function","title":"Defining the loss function","text":"<p>The essential part of solving this problem is to define the right loss function to represent our goal. In this case, we want to define a model that has the capacity to learn the target solution, and we want to minimize: - The derivative of this model in comparison with the exact derivative in the equation; - The output of the model at the boundary in comparison with the value for the boundary condition;</p> <p>We can write it like so:</p> <pre><code># Mean-squared error as the comparison criterion\ncriterion = torch.nn.MSELoss()\n\ndef loss_fn(model: torch.nn.Module, inputs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Loss function encoding the problem to solve.\"\"\"\n    # Equation loss\n    model_output = model(inputs)\n    deriv_model = calc_deriv(model_output, inputs)\n    deriv_exact = dfdx_equation(inputs)\n    ode_loss = criterion(deriv_model, deriv_exact)\n\n    # Boundary loss, f(0) = 0\n    boundary_model = model(torch.tensor([[0.0]]))\n    boundary_exact = torch.tensor([[0.0]])\n    boundary_loss = criterion(boundary_model, boundary_exact)\n\n    return ode_loss + boundary_loss\n</code></pre> <p>Different loss criterions could be considered, and we could also play with the balance between the sum of the two loss terms. For now, let's proceed with the definition above.</p> <p>Note that so far we have not used any quantum specific assumption, and we could in principle use the same loss function with a classical neural network.</p>"},{"location":"model/dqc_1d/#defining-a-qnn-with-qadence-model","title":"Defining a QNN with Qadence-Model","text":"<p>Now, we can finally use Qadence-Model to write a QNN. We will use a feature map to encode the input values, a trainable ansatz circuit, and an observable to measure as the output.</p> <pre><code>from qadence import feature_map, hea, chain, QuantumCircuit, Z\nfrom qadence_model.models import QNN\nfrom qadence.types import BasisSet, ReuploadScaling\n\nn_qubits = 3\ndepth = 3\n\n# Feature map\nfm = feature_map(\n    n_qubits = n_qubits,\n    param = \"x\",\n    fm_type = BasisSet.CHEBYSHEV,\n    reupload_scaling = ReuploadScaling.TOWER,\n)\n\n# Ansatz\nansatz = hea(n_qubits = n_qubits, depth = depth)\n\n# Observable\nobservable = Z(0)\n\ncircuit = QuantumCircuit(n_qubits, chain(fm, ansatz))\nmodel = QNN(circuit = circuit, observable = observable, inputs = [\"x\"])\n</code></pre> <p>We used a Chebyshev feature map with a tower-like scaling of the input reupload, and a standard hardware-efficient ansatz. In the observable, for now we consider the simple case of measuring the magnetization of the first qubit.</p> <pre><code>from qadence.draw import display\n\n# display(circuit)\n</code></pre> %3 cluster_751be2f2ab1d4367af356d0ce42b3834 HEA cluster_6093bbd3800c44519e30cf207f56461d Tower Chebyshev FM e45d84f91ec54181953bde052b3faae7 0 7dfc4b3bb81643c38b17167ad7ae721d RX(1.0*acos(x)) e45d84f91ec54181953bde052b3faae7--7dfc4b3bb81643c38b17167ad7ae721d 266b737bb1e7492587aff97c244235bc 1 5d82d34e104042cbb314cdb718f26150 RX(theta\u2080) 7dfc4b3bb81643c38b17167ad7ae721d--5d82d34e104042cbb314cdb718f26150 8cf038423e53487c88d666c3320ec062 RY(theta\u2083) 5d82d34e104042cbb314cdb718f26150--8cf038423e53487c88d666c3320ec062 9fdeffadf224410ba7e4b4e8f774f194 RX(theta\u2086) 8cf038423e53487c88d666c3320ec062--9fdeffadf224410ba7e4b4e8f774f194 a11cf93c69a547d88157bb32cd923e12 9fdeffadf224410ba7e4b4e8f774f194--a11cf93c69a547d88157bb32cd923e12 2f3eccf02f964537a9a471ae6064c2cd a11cf93c69a547d88157bb32cd923e12--2f3eccf02f964537a9a471ae6064c2cd 3a964e873efa471eb1fb67081a829f25 RX(theta\u2089) 2f3eccf02f964537a9a471ae6064c2cd--3a964e873efa471eb1fb67081a829f25 4f2c20f81aee4428b8c6d1103fe1cb83 RY(theta\u2081\u2082) 3a964e873efa471eb1fb67081a829f25--4f2c20f81aee4428b8c6d1103fe1cb83 4c5ffda4f2ea421b94d773074a3c1a49 RX(theta\u2081\u2085) 4f2c20f81aee4428b8c6d1103fe1cb83--4c5ffda4f2ea421b94d773074a3c1a49 fcb7daefebe64f18a1afd961b3c9c0cd 4c5ffda4f2ea421b94d773074a3c1a49--fcb7daefebe64f18a1afd961b3c9c0cd 9f1f48462cb34d9ab4f0da6f593db7b0 fcb7daefebe64f18a1afd961b3c9c0cd--9f1f48462cb34d9ab4f0da6f593db7b0 fea84aed3cca49f29077802d5ce66761 RX(theta\u2081\u2088) 9f1f48462cb34d9ab4f0da6f593db7b0--fea84aed3cca49f29077802d5ce66761 aaaee84dd31a4d648767cc7a0b1d1e09 RY(theta\u2082\u2081) fea84aed3cca49f29077802d5ce66761--aaaee84dd31a4d648767cc7a0b1d1e09 e9ca5946f8f74b18be41c632d6b52d18 RX(theta\u2082\u2084) aaaee84dd31a4d648767cc7a0b1d1e09--e9ca5946f8f74b18be41c632d6b52d18 55c65675d6434c3dba502c787cda060a e9ca5946f8f74b18be41c632d6b52d18--55c65675d6434c3dba502c787cda060a ad226be1812749b9be919e263ba91d50 55c65675d6434c3dba502c787cda060a--ad226be1812749b9be919e263ba91d50 a118d5496f144242aad04d0048265ccf ad226be1812749b9be919e263ba91d50--a118d5496f144242aad04d0048265ccf 1518527c0aab495d86c3f7bfb67a8376 5f5d24bd491642b3bea7a8c3b1d4b050 RX(2.0*acos(x)) 266b737bb1e7492587aff97c244235bc--5f5d24bd491642b3bea7a8c3b1d4b050 194e4965284a4eec900b8605ada6e5cf 2 7c994876d2c84f78b9a4f14949c310e7 RX(theta\u2081) 5f5d24bd491642b3bea7a8c3b1d4b050--7c994876d2c84f78b9a4f14949c310e7 a130f7e520504cbfa3eaa0aa60667d50 RY(theta\u2084) 7c994876d2c84f78b9a4f14949c310e7--a130f7e520504cbfa3eaa0aa60667d50 5e3792cf7c1f4774b4e6920ecc73e2c2 RX(theta\u2087) a130f7e520504cbfa3eaa0aa60667d50--5e3792cf7c1f4774b4e6920ecc73e2c2 f1eedb16e60548ffa21db93f491a2cd8 X 5e3792cf7c1f4774b4e6920ecc73e2c2--f1eedb16e60548ffa21db93f491a2cd8 f1eedb16e60548ffa21db93f491a2cd8--a11cf93c69a547d88157bb32cd923e12 d8bfdeb23e74413c9af506803b22d394 f1eedb16e60548ffa21db93f491a2cd8--d8bfdeb23e74413c9af506803b22d394 c7995766a0f14420b67356612babf3ad RX(theta\u2081\u2080) d8bfdeb23e74413c9af506803b22d394--c7995766a0f14420b67356612babf3ad 2ad25e33d5874fc7a215a12cc43e267f RY(theta\u2081\u2083) c7995766a0f14420b67356612babf3ad--2ad25e33d5874fc7a215a12cc43e267f f2386db8a40548ffad611b42e97d8934 RX(theta\u2081\u2086) 2ad25e33d5874fc7a215a12cc43e267f--f2386db8a40548ffad611b42e97d8934 23232a6053e64bbf9f11a3eb604f87ba X f2386db8a40548ffad611b42e97d8934--23232a6053e64bbf9f11a3eb604f87ba 23232a6053e64bbf9f11a3eb604f87ba--fcb7daefebe64f18a1afd961b3c9c0cd 965a71133d3047709a81561b8bbd8cfe 23232a6053e64bbf9f11a3eb604f87ba--965a71133d3047709a81561b8bbd8cfe ec965cd1f0034bca8b6b3e1bc16e533e RX(theta\u2081\u2089) 965a71133d3047709a81561b8bbd8cfe--ec965cd1f0034bca8b6b3e1bc16e533e 95b1dd3cf84a4d988351513627f8717d RY(theta\u2082\u2082) ec965cd1f0034bca8b6b3e1bc16e533e--95b1dd3cf84a4d988351513627f8717d 61c94226b14a4391a1861183fb0f062f RX(theta\u2082\u2085) 95b1dd3cf84a4d988351513627f8717d--61c94226b14a4391a1861183fb0f062f a1e4720184714fe19a1d7a885ebb8a9f X 61c94226b14a4391a1861183fb0f062f--a1e4720184714fe19a1d7a885ebb8a9f a1e4720184714fe19a1d7a885ebb8a9f--55c65675d6434c3dba502c787cda060a daa1bb3aac8a4f66bda41c93bb563def a1e4720184714fe19a1d7a885ebb8a9f--daa1bb3aac8a4f66bda41c93bb563def daa1bb3aac8a4f66bda41c93bb563def--1518527c0aab495d86c3f7bfb67a8376 da9b642421364c4f89cd51ee52099308 1e1a9d8bad2e4d9db72332a2cb83dab2 RX(3.0*acos(x)) 194e4965284a4eec900b8605ada6e5cf--1e1a9d8bad2e4d9db72332a2cb83dab2 f3a2c82b97a64ba5a2588988cf2ae910 RX(theta\u2082) 1e1a9d8bad2e4d9db72332a2cb83dab2--f3a2c82b97a64ba5a2588988cf2ae910 88f1ffb6c7a1458096f9674559a1ec78 RY(theta\u2085) f3a2c82b97a64ba5a2588988cf2ae910--88f1ffb6c7a1458096f9674559a1ec78 6f0dec85dbff4020adfe54f28246edc1 RX(theta\u2088) 88f1ffb6c7a1458096f9674559a1ec78--6f0dec85dbff4020adfe54f28246edc1 8267736ad3ea494a9ab1a504693cc6d7 6f0dec85dbff4020adfe54f28246edc1--8267736ad3ea494a9ab1a504693cc6d7 afe7ac1c430a4e999770d7d6f0d1a231 X 8267736ad3ea494a9ab1a504693cc6d7--afe7ac1c430a4e999770d7d6f0d1a231 afe7ac1c430a4e999770d7d6f0d1a231--d8bfdeb23e74413c9af506803b22d394 f35efad873a5490ba47c2f06654b3d15 RX(theta\u2081\u2081) afe7ac1c430a4e999770d7d6f0d1a231--f35efad873a5490ba47c2f06654b3d15 61ad7578020741fcb1b877f20a715227 RY(theta\u2081\u2084) f35efad873a5490ba47c2f06654b3d15--61ad7578020741fcb1b877f20a715227 0cab87bea6804c64b112cf43c64de678 RX(theta\u2081\u2087) 61ad7578020741fcb1b877f20a715227--0cab87bea6804c64b112cf43c64de678 50f03b66c0274c38bb63c51ee14a6e7f 0cab87bea6804c64b112cf43c64de678--50f03b66c0274c38bb63c51ee14a6e7f 4527fccbf34c447e914335219ea39746 X 50f03b66c0274c38bb63c51ee14a6e7f--4527fccbf34c447e914335219ea39746 4527fccbf34c447e914335219ea39746--965a71133d3047709a81561b8bbd8cfe b30c41b5085242998963bafc94c001d7 RX(theta\u2082\u2080) 4527fccbf34c447e914335219ea39746--b30c41b5085242998963bafc94c001d7 104ef1e3934347a0a96fd81b2c010f18 RY(theta\u2082\u2083) b30c41b5085242998963bafc94c001d7--104ef1e3934347a0a96fd81b2c010f18 2e761a1199634a40ada862f4c81658df RX(theta\u2082\u2086) 104ef1e3934347a0a96fd81b2c010f18--2e761a1199634a40ada862f4c81658df a7cdf59817b944d4aa5170f7877d9a3c 2e761a1199634a40ada862f4c81658df--a7cdf59817b944d4aa5170f7877d9a3c 771d2d34141b4aacbf9e3113dbeed6ac X a7cdf59817b944d4aa5170f7877d9a3c--771d2d34141b4aacbf9e3113dbeed6ac 771d2d34141b4aacbf9e3113dbeed6ac--daa1bb3aac8a4f66bda41c93bb563def 771d2d34141b4aacbf9e3113dbeed6ac--da9b642421364c4f89cd51ee52099308"},{"location":"model/dqc_1d/#training-the-model","title":"Training the model","text":"<p>Now that the model is defined we can proceed with the training. the <code>QNN</code> class can be used like any other <code>torch.nn.Module</code>.</p> <p>To train the model, we will select a random set of collocation points uniformly distributed within \\(-1.0&lt; x &lt;1.0\\) and compute the loss function for those points.</p> <pre><code>n_epochs = 200\nn_points = 10\n\nxmin = -0.99\nxmax = 0.99\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n\nfor epoch in range(n_epochs):\n    optimizer.zero_grad()\n\n    # Training data. We unsqueeze essentially making each batch have a single x value.\n    x_train = (xmin + (xmax-xmin)*torch.rand(n_points, requires_grad = True)).unsqueeze(1)\n\n    loss = loss_fn(inputs = x_train, model = model)\n    loss.backward()\n    optimizer.step()\n</code></pre> <p>Note the values of \\(x\\) are only picked from \\(x\\in[-0.99, 0.99]\\) since we are using a Chebyshev feature map, and derivative of \\(\\text{acos}(x)\\) diverges at \\(-1\\) and \\(1\\).</p>"},{"location":"model/dqc_1d/#plotting-the-results","title":"Plotting the results","text":"<pre><code>import matplotlib.pyplot as plt\n\ndef f_exact(x: torch.Tensor) -&gt; torch.Tensor:\n    return 5*(x**4 + (1/3)*x**3 - x**2 - 0.5*x)\n\nx_test = torch.arange(xmin, xmax, step = 0.01).unsqueeze(1)\n\nresult_exact = f_exact(x_test).flatten()\n\nresult_model = model(x_test).flatten().detach()\n\nplt.plot(x_test, result_exact, label = \"Exact solution\")\nplt.plot(x_test, result_model, label = \" Trained model\")\n</code></pre> 2025-05-23T14:20:03.542529 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/ <p>Clearly, the result is not optimal.</p>"},{"location":"model/dqc_1d/#improving-the-solution","title":"Improving the solution","text":"<p>One point to consider when defining the QNN is the possible output range, which is bounded by the spectrum of the chosen observable. For the magnetization of a single qubit, this means that the output is bounded between -1 and 1, which we can clearly see in the plot.</p> <p>One option would be to define the observable as the total magnetization over all qubits, which would allow a range of -3 to 3.</p> <pre><code>from qadence import add\n\nobservable = add(Z(i) for i in range(n_qubits))\n\nmodel = QNN(circuit = circuit, observable = observable, inputs = [\"x\"])\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n\nfor epoch in range(n_epochs):\n    optimizer.zero_grad()\n\n    # Training data\n    x_train = (xmin + (xmax-xmin)*torch.rand(n_points, requires_grad = True)).unsqueeze(1)\n\n    loss = loss_fn(inputs = x_train, model = model)\n    loss.backward()\n    optimizer.step()\n</code></pre> <p>And we again plot the result:</p> <pre><code>x_test = torch.arange(xmin, xmax, step = 0.01).unsqueeze(1)\n\nresult_exact = f_exact(x_test).flatten()\n\nresult_model = model(x_test).flatten().detach()\n\nplt.plot(x_test, result_exact, label = \"Exact solution\")\nplt.plot(x_test, result_model, label = \"Trained model\")\n</code></pre> 2025-05-23T14:20:11.065779 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"model/dqc_1d/#references","title":"References","text":"<ol> <li> <p>Kyriienko et al., Solving nonlinear differential equations with differentiable quantum circuits. \u21a9</p> </li> </ol>"},{"location":"model/qaoa/","title":"Solving MaxCut with QAOA","text":"<p>This tutorial shows how to solve the maximum cut (MaxCut) combinatorial optimization problem on a graph using the Quantum Approximate Optimization Algorithm (QAOA), first introduced by Farhi et al. in 2014 <sup>1</sup>.</p> <p>Given an arbitrary graph, the MaxCut problem consists in finding a graph cut which partitions the nodes into two disjoint sets, such that the number of edges in the cut is maximized. This is a very common combinatorial optimization problem known to be computationally hard (NP-hard).</p> <p>The graph used for this tutorial is an unweighted graph randomly generated using the <code>networkx</code> library with a certain probability \\(p\\) of having an edge between two arbitrary nodes (known as Erd\u0151s\u2013R\u00e9nyi graph).</p> <pre><code>import numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport random\n\n# ensure reproducibility\nseed = 42\nnp.random.seed(seed)\nrandom.seed(seed)\n\n# Create random graph\nn_nodes = 4\nedge_prob = 0.8\ngraph = nx.gnp_random_graph(n_nodes, edge_prob)\n\nnx.draw(graph)\n</code></pre> 2025-05-23T14:20:11.149492 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/ <p>The goal of the MaxCut algorithm is to maximize the following cost function:</p> \\[\\mathcal{C}(p) = \\sum_{\\alpha}^m \\mathcal{C}_{\\alpha}(p)\\] <p>where \\(p\\) is a given cut of the graph, \\(\\alpha\\) is an index over the edges and \\(\\mathcal{C}_{\\alpha}(p)\\) is written such that if the nodes connected by the \\(\\alpha\\) edge are in the same set, it returns \\(0\\), otherwise it returns \\(1\\). We will represent a cut \\(p\\) as a bitstring of length \\(N\\), where \\(N\\) is the number of nodes, and where the bit in position \\(i\\) shows to which partition node \\(i\\) belongs. We assign value 0 to one of the partitions defined by the cut and 1 to the other. Since this choice is arbitrary, every cut is represented by two bitstrings, e.g. \"0011\" and \"1100\" are equivalent.</p> <p>Since in this tutorial we are only dealing with small graphs, we can find the maximum cut by brute force to make sure QAOA works as intended. <pre><code># Function to calculate the cost associated with a cut\ndef calculate_cost(cut: str, graph: nx.graph) -&gt; float:\n    \"\"\"Returns the cost of a given cut (represented by a bitstring)\"\"\"\n    cost = 0\n    for edge in graph.edges():\n        (i, j) = edge\n        if cut[i] != cut[j]:\n            cost += 1\n    return cost\n\n\n# Function to get a binary representation of an int\nget_binary = lambda x, n: format(x, \"b\").zfill(n)\n\n# List of all possible cuts\nall_possible_cuts = [bin(k)[2:].rjust(n_nodes, \"0\") for k in range(2**n_nodes)]\n\n# List with the costs associated to each cut\nall_costs = [calculate_cost(cut, graph) for cut in all_possible_cuts]\n\n# Get the maximum cost\nmaxcost = max(all_costs)\n\n# Get all cuts that correspond to the maximum cost\nmaxcuts = [get_binary(i, n_nodes) for i, j in enumerate(all_costs) if j == maxcost]\nprint(f\"The maximum cut is represented by the bitstrings {maxcuts}, with a cost of {maxcost}\")\n</code></pre> <pre><code>The maximum cut is represented by the bitstrings ['0011', '0101', '0110', '1001', '1010', '1100'], with a cost of 4\n</code></pre> </p>"},{"location":"model/qaoa/#the-qaoa-quantum-circuit","title":"The QAOA quantum circuit","text":"<p>The Max-Cut problem can be solved by using the QAOA algorithm. QAOA belongs to the class of Variational Quantum Algorithms (VQAs), which means that its quantum circuit contains a certain number of parametrized quantum gates that need to be optimized with a classical optimizer. The QAOA circuit is composed of two operators:</p> <ul> <li>The cost operator \\(U_c\\): a circuit generated by the cost Hamiltonian which encodes the cost function described above into a quantum circuit. The solution to the optimization problem is encoded in the ground state of the cost Hamiltonian \\(H_c\\). The cost operator  is simply the evolution of the cost Hamiltonian parametrized by a variational parameter \\(\\gamma\\) so that \\(U_c = e^{i\\gamma H_c}.\\)</li> <li>The mixing operator \\(U_b\\): a simple set of single-qubit rotations with adjustable   angles which are tuned during the classical optimization loop to minimize the cost</li> </ul> <p>The cost Hamiltonian of the MaxCut problem can be written as:</p> \\[H_c = \\frac12 \\sum_{\\langle i,j\\rangle} (\\mathbb{1} - Z_iZ_j)\\] <p>where \\(\\langle i,j\\rangle\\) represents the edge between nodes \\(i\\) and \\(j\\). The solution of the MaxCut problem is encoded in the ground state of the above Hamiltonian.</p> <p>The QAOA quantum circuit consists of a number of layers, each layer containing a cost and a mixing operator. Below, the QAOA quantum circuit is defined using <code>qadence</code> operations. First, a layer of Hadamard gates is applied to all qubits to prepare the initial state \\(|+\\rangle ^{\\otimes n}\\). The cost operator of each layer can be built \"manually\", implementing the \\(e^{iZZ\\gamma}\\) terms with CNOTs and a \\(\\rm{RZ}(2\\gamma)\\) rotation, or it can also be automatically decomposed into digital single and two-qubits operations via the <code>.digital_decomposition()</code> method. The decomposition is exact since the Hamiltonian generator is diagonal.</p> <pre><code>from qadence import tag, kron, chain, RX, RZ, Z, H, CNOT, I, add\nfrom qadence import HamEvo, QuantumCircuit, Parameter\n\nn_qubits = graph.number_of_nodes()\nn_edges = graph.number_of_edges()\nn_layers = 6\n\n# Generate the cost Hamiltonian\nzz_ops = add(Z(edge[0]) @ Z(edge[1]) for edge in graph.edges)\ncost_ham = 0.5 * (n_edges * kron(I(i) for i in range(n_qubits)) - zz_ops)\n\n\n# QAOA circuit\ndef build_qaoa_circuit(n_qubits, n_layers, graph):\n    layers = []\n    # Layer of Hadamards\n    initial_layer = kron(H(i) for i in range(n_qubits))\n    layers.append(initial_layer)\n    for layer in range(n_layers):\n\n        # cost layer with digital decomposition\n        # cost_layer = HamEvo(cost_ham, f\"g{layer}\").digital_decomposition(approximation=\"basic\")\n        cost_layer = []\n        for edge in graph.edges():\n            (q0, q1) = edge\n            zz_term = chain(\n                CNOT(q0, q1),\n                RZ(q1, Parameter(f\"g{layer}\")),\n                CNOT(q0, q1),\n            )\n            cost_layer.append(zz_term)\n        cost_layer = chain(*cost_layer)\n        cost_layer = tag(cost_layer, \"cost\")\n\n        # mixing layer with single qubit rotations\n        mixing_layer = kron(RX(i, f\"b{layer}\") for i in range(n_qubits))\n        mixing_layer = tag(mixing_layer, \"mixing\")\n\n        # putting all together in a single ChainBlock\n        layers.append(chain(cost_layer, mixing_layer))\n\n    final_b = chain(*layers)\n    return QuantumCircuit(n_qubits, final_b)\n\n\ncircuit = build_qaoa_circuit(n_qubits, n_layers, graph)\n\n# Print a single layer of the circuit\n</code></pre> %3 cluster_f3537f309fca46fa9d2e43d93aa79d03 mixing cluster_b6e59508d5b2474d99b448dae0015f3a cost d9a469aede6d403d9dbd45a1df561b32 0 77c584001d654430b219d32fa01bc28d H d9a469aede6d403d9dbd45a1df561b32--77c584001d654430b219d32fa01bc28d 60de6618d3024fb9ac85f72515017a2d 1 e84d9b4834be4582a0b565c21e1c6f59 77c584001d654430b219d32fa01bc28d--e84d9b4834be4582a0b565c21e1c6f59 6fc7090b8fae4a90bda54a535b16fbc0 e84d9b4834be4582a0b565c21e1c6f59--6fc7090b8fae4a90bda54a535b16fbc0 e8651afb65e94dcc9ad92cb94d9542b8 6fc7090b8fae4a90bda54a535b16fbc0--e8651afb65e94dcc9ad92cb94d9542b8 27773ad05a6641f2b61665bd6b962c7e e8651afb65e94dcc9ad92cb94d9542b8--27773ad05a6641f2b61665bd6b962c7e 07cb376166f6435c92c6bc501bcd718a 27773ad05a6641f2b61665bd6b962c7e--07cb376166f6435c92c6bc501bcd718a 5420d99c69734f40b27b130f399ae148 07cb376166f6435c92c6bc501bcd718a--5420d99c69734f40b27b130f399ae148 ba0931c37af4444495e64d2de2339dcb 5420d99c69734f40b27b130f399ae148--ba0931c37af4444495e64d2de2339dcb b4e510002d6c4bb7b7a1c75cc595dd3d ba0931c37af4444495e64d2de2339dcb--b4e510002d6c4bb7b7a1c75cc595dd3d 74ce2a6d990c4da491a5bad702f29e62 b4e510002d6c4bb7b7a1c75cc595dd3d--74ce2a6d990c4da491a5bad702f29e62 6eb6dccf404e4598b4915af70f25786c 74ce2a6d990c4da491a5bad702f29e62--6eb6dccf404e4598b4915af70f25786c 6d6ea4530c004050af9f7b16568233de 6eb6dccf404e4598b4915af70f25786c--6d6ea4530c004050af9f7b16568233de 93cec6e436814ac2aa4a338b9e053fcf 6d6ea4530c004050af9f7b16568233de--93cec6e436814ac2aa4a338b9e053fcf 51aa0f1f2b1844e1b2ac727888765ce1 93cec6e436814ac2aa4a338b9e053fcf--51aa0f1f2b1844e1b2ac727888765ce1 3a6aa1e6bc7746b492ffa2bdd5e89fe8 51aa0f1f2b1844e1b2ac727888765ce1--3a6aa1e6bc7746b492ffa2bdd5e89fe8 175291f7620a49e3bafc56d2ac85559a 3a6aa1e6bc7746b492ffa2bdd5e89fe8--175291f7620a49e3bafc56d2ac85559a 1f72b003541a456ba14e9025073099ac 175291f7620a49e3bafc56d2ac85559a--1f72b003541a456ba14e9025073099ac faf669f01b1b4ae5a873ce393a290451 1f72b003541a456ba14e9025073099ac--faf669f01b1b4ae5a873ce393a290451 b49cffdfc782406dacb9dae73343a998 faf669f01b1b4ae5a873ce393a290451--b49cffdfc782406dacb9dae73343a998 2da064c3ffe54deba6254634e81131a8 RX(b0) b49cffdfc782406dacb9dae73343a998--2da064c3ffe54deba6254634e81131a8 d9e7824d59cd4f238b19136380c937d1 2da064c3ffe54deba6254634e81131a8--d9e7824d59cd4f238b19136380c937d1 85f05839864e43f197479b03ee6913d4 99742a97c7614678b8271a024ea09a9e H 60de6618d3024fb9ac85f72515017a2d--99742a97c7614678b8271a024ea09a9e 48acc5773b0b4086b514b2c7c8a33307 2 196eaaf8fa1c4aceab500ab5a6927f17 X 99742a97c7614678b8271a024ea09a9e--196eaaf8fa1c4aceab500ab5a6927f17 196eaaf8fa1c4aceab500ab5a6927f17--e84d9b4834be4582a0b565c21e1c6f59 af7d03956428497bb36726e2eabc03f0 RZ(g0) 196eaaf8fa1c4aceab500ab5a6927f17--af7d03956428497bb36726e2eabc03f0 b3a6e856910341988bdf63b1f4f426c1 X af7d03956428497bb36726e2eabc03f0--b3a6e856910341988bdf63b1f4f426c1 b3a6e856910341988bdf63b1f4f426c1--e8651afb65e94dcc9ad92cb94d9542b8 7e74e438f3934563a1e3bdefe01f2618 b3a6e856910341988bdf63b1f4f426c1--7e74e438f3934563a1e3bdefe01f2618 8f8325f8c0414b6bb01212e6a26cac2a 7e74e438f3934563a1e3bdefe01f2618--8f8325f8c0414b6bb01212e6a26cac2a 17f71fb5c3a2459db5df8a31c8d7b4c8 8f8325f8c0414b6bb01212e6a26cac2a--17f71fb5c3a2459db5df8a31c8d7b4c8 e1f654f59c4542bd9ecc2f09c5de92c2 17f71fb5c3a2459db5df8a31c8d7b4c8--e1f654f59c4542bd9ecc2f09c5de92c2 743d3add7b374c758322d0a40f6d4d23 e1f654f59c4542bd9ecc2f09c5de92c2--743d3add7b374c758322d0a40f6d4d23 e91f20b458b4489b8b744609df971ee4 743d3add7b374c758322d0a40f6d4d23--e91f20b458b4489b8b744609df971ee4 c6fe9a35590f45e691f9747789b4f2bc e91f20b458b4489b8b744609df971ee4--c6fe9a35590f45e691f9747789b4f2bc bcacd531c8464d3fa67aa93a875dfe4d c6fe9a35590f45e691f9747789b4f2bc--bcacd531c8464d3fa67aa93a875dfe4d 2333474b52a7414690f5abf494d1ab16 bcacd531c8464d3fa67aa93a875dfe4d--2333474b52a7414690f5abf494d1ab16 3689a8d6e0a842898b4a3e46c8bd0ba1 2333474b52a7414690f5abf494d1ab16--3689a8d6e0a842898b4a3e46c8bd0ba1 64339e282f6143d8a1cca49be0e73d69 3689a8d6e0a842898b4a3e46c8bd0ba1--64339e282f6143d8a1cca49be0e73d69 79657718d2a142d7ae09c6c5181396c5 64339e282f6143d8a1cca49be0e73d69--79657718d2a142d7ae09c6c5181396c5 8b52144c67164a36b2849054b30a47a8 79657718d2a142d7ae09c6c5181396c5--8b52144c67164a36b2849054b30a47a8 bb91d1ebb2c14be487369c330f0ce8cc 8b52144c67164a36b2849054b30a47a8--bb91d1ebb2c14be487369c330f0ce8cc 97eff6b552bd41f8a8554c29cd0a21aa bb91d1ebb2c14be487369c330f0ce8cc--97eff6b552bd41f8a8554c29cd0a21aa 5800965dd5c845bea1a2e220b622c255 RX(b0) 97eff6b552bd41f8a8554c29cd0a21aa--5800965dd5c845bea1a2e220b622c255 5800965dd5c845bea1a2e220b622c255--85f05839864e43f197479b03ee6913d4 e7c9badfb2aa447e82ad076576638b54 da58a554d3f84fabb34f2ed390107a53 H 48acc5773b0b4086b514b2c7c8a33307--da58a554d3f84fabb34f2ed390107a53 264fdd714c924a3f947e1085de1f3f5a 3 73e6989219594cec84f25e34d875504d da58a554d3f84fabb34f2ed390107a53--73e6989219594cec84f25e34d875504d 0a2912d618e44a439f49b475396a83a2 73e6989219594cec84f25e34d875504d--0a2912d618e44a439f49b475396a83a2 f180a1bc3e924f23b23e95414aed9d10 0a2912d618e44a439f49b475396a83a2--f180a1bc3e924f23b23e95414aed9d10 2b5c3818bce74fce8219658aa6258426 X f180a1bc3e924f23b23e95414aed9d10--2b5c3818bce74fce8219658aa6258426 2b5c3818bce74fce8219658aa6258426--27773ad05a6641f2b61665bd6b962c7e 2829109ee8054f209605837b439a1a42 RZ(g0) 2b5c3818bce74fce8219658aa6258426--2829109ee8054f209605837b439a1a42 35393d9576be46d1a884d81afe45b67d X 2829109ee8054f209605837b439a1a42--35393d9576be46d1a884d81afe45b67d 35393d9576be46d1a884d81afe45b67d--5420d99c69734f40b27b130f399ae148 089d4b67d4b940558b3b3ffc68cce656 35393d9576be46d1a884d81afe45b67d--089d4b67d4b940558b3b3ffc68cce656 dcb621870d934032b7a23ea2441d45ba 089d4b67d4b940558b3b3ffc68cce656--dcb621870d934032b7a23ea2441d45ba 0d2e8b258e9046dd8a691ed8796d9fb1 dcb621870d934032b7a23ea2441d45ba--0d2e8b258e9046dd8a691ed8796d9fb1 b6f8b2df0d7c4396b08c83cb2a0664fd X 0d2e8b258e9046dd8a691ed8796d9fb1--b6f8b2df0d7c4396b08c83cb2a0664fd b6f8b2df0d7c4396b08c83cb2a0664fd--c6fe9a35590f45e691f9747789b4f2bc 58df9f4920d749c28b2f539e7d359c0f RZ(g0) b6f8b2df0d7c4396b08c83cb2a0664fd--58df9f4920d749c28b2f539e7d359c0f 802f338101f54bd292ac80463d84c9a5 X 58df9f4920d749c28b2f539e7d359c0f--802f338101f54bd292ac80463d84c9a5 802f338101f54bd292ac80463d84c9a5--2333474b52a7414690f5abf494d1ab16 a614cffe54bc4a36ae122c606bde5a27 802f338101f54bd292ac80463d84c9a5--a614cffe54bc4a36ae122c606bde5a27 51d39d4728d3474192f1a5dd51541c3c a614cffe54bc4a36ae122c606bde5a27--51d39d4728d3474192f1a5dd51541c3c 3e2c60a5168740bcbae8fb0472e84dc6 51d39d4728d3474192f1a5dd51541c3c--3e2c60a5168740bcbae8fb0472e84dc6 689d0bc02cf442ce85a1c9b1f401b521 3e2c60a5168740bcbae8fb0472e84dc6--689d0bc02cf442ce85a1c9b1f401b521 abdebc814d1a465fbc7769ace1636363 689d0bc02cf442ce85a1c9b1f401b521--abdebc814d1a465fbc7769ace1636363 74e463f4f1e84dd48489198a9b816962 abdebc814d1a465fbc7769ace1636363--74e463f4f1e84dd48489198a9b816962 ed845ce0f1fc416ea389f358f43f51d5 RX(b0) 74e463f4f1e84dd48489198a9b816962--ed845ce0f1fc416ea389f358f43f51d5 ed845ce0f1fc416ea389f358f43f51d5--e7c9badfb2aa447e82ad076576638b54 b9951e9e63294ddc81f69b39f0c8763c 315cf86e13cc4048ab7fffd35dfe78bd H 264fdd714c924a3f947e1085de1f3f5a--315cf86e13cc4048ab7fffd35dfe78bd 76a760c899aa406ca4b96ca2d2ed5390 315cf86e13cc4048ab7fffd35dfe78bd--76a760c899aa406ca4b96ca2d2ed5390 cfd248ea16f04bdfa59338116419e3a9 76a760c899aa406ca4b96ca2d2ed5390--cfd248ea16f04bdfa59338116419e3a9 7a1ee4e1820c4166a699e23d9a7127e4 cfd248ea16f04bdfa59338116419e3a9--7a1ee4e1820c4166a699e23d9a7127e4 f76356743f0f4f05b1ecdb7d2b715436 7a1ee4e1820c4166a699e23d9a7127e4--f76356743f0f4f05b1ecdb7d2b715436 3bb6d3226f1f4185a74ffa19a485389c f76356743f0f4f05b1ecdb7d2b715436--3bb6d3226f1f4185a74ffa19a485389c 31e216bac7d142ac9993ae439c86e17c 3bb6d3226f1f4185a74ffa19a485389c--31e216bac7d142ac9993ae439c86e17c 3f4f721d8c3a435fa246c002dfe93921 X 31e216bac7d142ac9993ae439c86e17c--3f4f721d8c3a435fa246c002dfe93921 3f4f721d8c3a435fa246c002dfe93921--ba0931c37af4444495e64d2de2339dcb da3ce773e1614eb387249035e79abfc3 RZ(g0) 3f4f721d8c3a435fa246c002dfe93921--da3ce773e1614eb387249035e79abfc3 97ba7bdeae5a4360afd0ea289a8dda4a X da3ce773e1614eb387249035e79abfc3--97ba7bdeae5a4360afd0ea289a8dda4a 97ba7bdeae5a4360afd0ea289a8dda4a--74ce2a6d990c4da491a5bad702f29e62 16301608e0b046a8b3acb5bd20fb1f4a 97ba7bdeae5a4360afd0ea289a8dda4a--16301608e0b046a8b3acb5bd20fb1f4a 56a0c77e8acc4f598abac4497f8de9f4 16301608e0b046a8b3acb5bd20fb1f4a--56a0c77e8acc4f598abac4497f8de9f4 b36c4b4ac93b4712be6599fe7b9ef288 56a0c77e8acc4f598abac4497f8de9f4--b36c4b4ac93b4712be6599fe7b9ef288 4ee1e459e2694e2885be2e74fc73bd13 X b36c4b4ac93b4712be6599fe7b9ef288--4ee1e459e2694e2885be2e74fc73bd13 4ee1e459e2694e2885be2e74fc73bd13--3689a8d6e0a842898b4a3e46c8bd0ba1 60279e52f4414b809223ad017d723066 RZ(g0) 4ee1e459e2694e2885be2e74fc73bd13--60279e52f4414b809223ad017d723066 bd71893709b74d898f0847b99d8fb787 X 60279e52f4414b809223ad017d723066--bd71893709b74d898f0847b99d8fb787 bd71893709b74d898f0847b99d8fb787--79657718d2a142d7ae09c6c5181396c5 556fc563f9c14a23b7dd2beb0bb974cc X bd71893709b74d898f0847b99d8fb787--556fc563f9c14a23b7dd2beb0bb974cc 556fc563f9c14a23b7dd2beb0bb974cc--689d0bc02cf442ce85a1c9b1f401b521 91c601ed16c94f2fa0245a1dfcc36522 RZ(g0) 556fc563f9c14a23b7dd2beb0bb974cc--91c601ed16c94f2fa0245a1dfcc36522 37d7f95ee94c40ceb327a674788fed0a X 91c601ed16c94f2fa0245a1dfcc36522--37d7f95ee94c40ceb327a674788fed0a 37d7f95ee94c40ceb327a674788fed0a--74e463f4f1e84dd48489198a9b816962 d7fa6b77a954405eb6cad7ee85d270e2 RX(b0) 37d7f95ee94c40ceb327a674788fed0a--d7fa6b77a954405eb6cad7ee85d270e2 d7fa6b77a954405eb6cad7ee85d270e2--b9951e9e63294ddc81f69b39f0c8763c"},{"location":"model/qaoa/#train-the-qaoa-circuit-to-solve-maxcut","title":"Train the QAOA circuit to solve MaxCut","text":"<p>Given the QAOA circuit above, one can construct the associated Qadence <code>QuantumModel</code> and train it using standard gradient based optimization.</p> <p>The loss function to be minimized reads:</p> \\[\\mathcal{L} =-\\langle \\psi | H_c| \\psi \\rangle= -\\frac12 \\sum_{\\langle i,j\\rangle}  \\left(1 - \\langle \\psi | Z_i Z_j | \\psi \\rangle \\right)\\] <p>where \\(|\\psi\\rangle(\\beta, \\gamma)\\) is the wavefunction obtained by running the QAQA quantum circuit and the sum runs over the edges of the graph \\(\\langle i,j\\rangle\\).</p> <pre><code>import torch\nfrom qadence import QuantumModel\n\ntorch.manual_seed(seed)\n\n\ndef loss_function(model: QuantumModel):\n    # The loss corresponds to the expectation\n    # value of the cost Hamiltonian\n    return -1.0 * model.expectation().squeeze()\n\n\n# initialize the parameters to random values\nmodel = QuantumModel(circuit, observable=cost_ham)\nmodel.reset_vparams(torch.rand(model.num_vparams))\ninitial_loss = loss_function(model)\nprint(f\"Initial loss: {initial_loss}\")\n\n# train the model\nn_epochs = 100\nlr = 0.1\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\nfor i in range(n_epochs):\n    optimizer.zero_grad()\n    loss = loss_function(model)\n    loss.backward()\n    optimizer.step()\n    if (i + 1) % (n_epochs // 10) == 0:\n        print(f\"MaxCut cost at iteration {i+1}: {-loss.item()}\")\n</code></pre> <pre><code>Initial loss: -2.1782381363858794\nMaxCut cost at iteration 10: 3.7470706807026417\nMaxCut cost at iteration 20: 3.8378810288930216\nMaxCut cost at iteration 30: 3.9424197899236133\nMaxCut cost at iteration 40: 3.9981256255766002\nMaxCut cost at iteration 50: 3.996470528508214\nMaxCut cost at iteration 60: 3.9991374608876606\nMaxCut cost at iteration 70: 3.9994678542919555\nMaxCut cost at iteration 80: 3.999872558672829\nMaxCut cost at iteration 90: 3.9999475834121063\nMaxCut cost at iteration 100: 3.9999793311641003\n</code></pre> <p>Qadence offers some convenience functions to implement this training loop with advanced logging and metrics track features.</p>"},{"location":"model/qaoa/#results","title":"Results","text":"<p>Given the trained quantum model, one needs to sample the resulting quantum state to recover the bitstring with the highest probability which corresponds to the maximum cut of the graph.</p> <pre><code>samples = model.sample(n_shots=100)[0]\nmost_frequent = max(samples, key=samples.get)\n\nprint(f\"Most frequently sampled bitstring corresponding to the maximum cut: {most_frequent}\")\n\n# let's now draw the cut obtained with the QAOA procedure\ncolors = []\nlabels = {}\nfor node, b in zip(graph.nodes(), most_frequent):\n    colors.append(\"green\") if int(b) == 0 else colors.append(\"red\")\n    labels[node] = \"A\" if int(b) == 0 else \"B\"\n\nnx.draw_networkx(graph, node_color=colors, with_labels=True, labels=labels)\n</code></pre>   Most frequently sampled bitstring corresponding to the maximum cut: 1001  2025-05-23T14:20:15.310827 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"model/qaoa/#references","title":"References","text":"<ol> <li> <p>Farhi et al. - A Quantum Approximate Optimization Algorithm\u00a0\u21a9</p> </li> </ol>"},{"location":"model/qcl/","title":"Quantum circuit learning","text":"<p>This tutorial shows how to apply <code>qadenc-model</code> for solving a basic quantum machine learning application: fitting a simple function with the quantum circuit learning<sup>1</sup> (QCL) algorithm.</p> <p>QCL is a supervised quantum machine learning algorithm that uses a parametrized quantum neural network to learn the behavior of an arbitrary mathematical function using a set of function values as training data. This tutorial shows how to fit the \\(\\sin(x)\\) function in the \\([-1, 1]\\) domain.</p> <p>In the following, train and test data are defined.</p> <pre><code>import torch\nfrom torch.utils.data import random_split\n\n# make sure all tensors are kept on the same device\n# only available from PyTorch 2.0\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch.set_default_device(device)\n\ndef qcl_training_data(\n    domain: tuple = (0, 2*torch.pi), n_points: int = 200\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n\n    start, end = domain\n\n    x_rand, _ = torch.sort(torch.DoubleTensor(n_points).uniform_(start, end))\n    y_rand = torch.sin(x_rand)\n\n    return x_rand, y_rand\n\nx, y = qcl_training_data()\n\n# random train/test split of the dataset\ntrain_subset, test_subset = random_split(x, [0.75, 0.25])\ntrain_ind = sorted(train_subset.indices)\ntest_ind = sorted(test_subset.indices)\n\nx_train, y_train = x[train_ind], y[train_ind]\nx_test, y_test = x[test_ind], y[test_ind]\n</code></pre>"},{"location":"model/qcl/#train-the-qcl-model","title":"Train the QCL model","text":"<p>Qadence-model provides the <code>QNN</code> convenience constructor to build a quantum neural network. The <code>QNN</code> class needs a circuit and a list of observables; the number of feature parameters in the input circuit determines the number of input features (i.e. the dimensionality of the classical data given as input) whereas the number of observables determines the number of outputs of the quantum neural network.</p> <p>Total qubit magnetization is used as observable:</p> \\[ \\hat{O} = \\sum_i^N \\hat{\\sigma}_i^z \\] <p>In the following the observable, quantum circuit and corresponding QNN model are constructed.</p> <pre><code>import qadence as qd\nimport qadence_model as qdm\n\nn_qubits = 4\n\n# create a simple feature map to encode the input data\nfeature_param = qd.FeatureParameter(\"phi\")\nfeature_map = qd.kron(qd.RX(i, feature_param) for i in range(n_qubits))\nfeature_map = qd.tag(feature_map, \"feature_map\")\n\n# create a digital-analog variational ansatz using Qadence convenience constructors\nansatz = qd.hea(n_qubits, depth=n_qubits)\nansatz = qd.tag(ansatz, \"ansatz\")\n\n# total qubit magnetization observable\nobservable = qd.hamiltonian_factory(n_qubits, detuning=qd.Z)\n\ncircuit = qd.QuantumCircuit(n_qubits, feature_map, ansatz)\nmodel = qdm.models.QNN(circuit, [observable])\nexpval = model(values=torch.rand(10))\n</code></pre> <pre><code>tensor([[ 0.0092],\n        [-0.0207],\n        [-0.4616],\n        [-0.1845],\n        [-0.3761],\n        [-0.1463],\n        [-0.4563],\n        [-0.0016],\n        [-0.3436],\n        [-0.4252]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> <p>The QCL algorithm uses the output of the quantum neural network as a tunable universal function approximator. Standard PyTorch code is used for training the QNN using a mean-square error loss, Adam optimizer. Training is performend on the GPU if available:</p> <pre><code>n_epochs = 100\nlr = 0.25\n\ninput_values = {\"phi\": x_train}\nmse_loss = torch.nn.MSELoss()  # standard PyTorch loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)  # standard PyTorch Adam optimizer\n\nprint(f\"Initial loss: {mse_loss(model(values=x_train), y_train)}\")\ny_pred_initial = model(values=x_test)\n\nfor i in range(n_epochs):\n\n    optimizer.zero_grad()\n\n    # given a `n_batch` number of input points and a `n_observables`\n    # number of input observables to measure, the QNN returns\n    # an output of the following shape: [n_batch x n_observables]\n    # given that there is only one observable, a squeeze is applied to get\n    # a 1-dimensional tensor\n    loss = mse_loss(model(values=x_train).squeeze(), y_train)\n    loss.backward()\n    optimizer.step()\n\n    if (i+1) % 20 == 0:\n        print(f\"Epoch {i+1} - Loss: {loss.item()}\")\n\nassert loss.item() &lt; 1e-3\n</code></pre> <pre><code>Initial loss: 0.6272721767455237\nEpoch 20 - Loss: 0.008173087377230498\nEpoch 40 - Loss: 0.0011247726222838813\nEpoch 60 - Loss: 0.0001415308609619855\nEpoch 80 - Loss: 2.3606578815826947e-05\nEpoch 100 - Loss: 2.503287372853267e-06\n</code></pre> <p>Qadence-model offers some convenience functions to implement this training loop with advanced logging and metrics track features.</p> <p>The quantum model is now trained on the training data points. To determine the quality of the results, one can check to see how well it fits the function on the test set.</p> <pre><code>import matplotlib.pyplot as plt\n\ny_pred = model({\"phi\": x_test})\n\n# convert all the results to numpy arrays for plotting\nx_train_np = x_train.cpu().detach().numpy().flatten()\ny_train_np = y_train.cpu().detach().numpy().flatten()\nx_test_np = x_test.cpu().detach().numpy().flatten()\ny_test_np = y_test.cpu().detach().numpy().flatten()\ny_pred_initial_np = y_pred_initial.cpu().detach().numpy().flatten()\ny_pred_np = y_pred.cpu().detach().numpy().flatten()\n\nfig, _ = plt.subplots()\nplt.scatter(x_test_np, y_test_np, label=\"Test points\", marker=\"o\", color=\"orange\")\nplt.plot(x_test_np, y_pred_initial_np, label=\"Initial prediction\", color=\"green\", alpha=0.5)\nplt.plot(x_test_np, y_pred_np, label=\"Final prediction\")\nplt.legend()\n</code></pre> 2025-05-23T14:20:19.676418 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"model/qcl/#references","title":"References","text":"<ol> <li> <p>Mitarai et al., Quantum Circuit Learning \u21a9</p> </li> </ol>"},{"location":"model/qng/","title":"The Quantum Natural Gradient optimizer","text":"<p>Qadence-Model provides a set of optimizers based on quantum information tools, in particular based on the Quantum Fisher Information<sup>1</sup> (QFI). The Quantum Natural Gradient <sup>2</sup> (QNG) is a gradient-based optimizer which uses the QFI matrix to better navigate the optimizer's descent to the minimum. The parameter update rule for the QNG optimizer is written as:</p> \\[ \\theta_{t+1} = \\theta_t - \\eta g^{-1}(\\theta_t)\\nabla \\mathcal{L}(\\theta_t) \\] <p>where \\(g(\\theta)\\) is the Fubiny-Study metric tensor (aka Quantum Geometric Tensor), which is equivalent to the Quantum Fisher Information matrix \\(F(\\theta)\\) up to a constant factor \\(F(\\theta)= 4 g(\\theta)\\). The Quantum Fisher Information can be written as the Hessian of the fidelity of a quantum state:</p> \\[   F_{i j}(\\theta)=-\\left.2 \\frac{\\partial}{\\partial \\theta_i} \\frac{\\partial}{\\partial \\theta_j}\\left|\\left\\langle\\psi\\left(\\theta^{\\prime}\\right) \\mid \\psi(\\theta)\\right\\rangle\\right|^2\\right|_{{\\theta}^{\\prime}=\\theta} \\] <p>However, computing the above expression is a costly operation scaling quadratically with the number of parameters in the variational quantum circuit. It is thus usual to use approximate methods when dealing with the QFI matrix. Qadence-Model provides a SPSA-based implementation of the Quantum Natural Gradient<sup>3</sup>. The SPSA (Simultaneous Perturbation Stochastic Approximation) algorithm is a well known finite differences-based algorithm. QNG-SPSA constructs an iterative approximation to the QFI matrix with a constant number of circuit evaluations that does not scale with the number of parameters. Although the SPSA algorithm outputs a rough approximation of the QFI matrix, the QNG-SPSA has been proven to work well while being a very efficient method due to the constant overhead in circuit evaluations (only 6 extra evaluations per iteration).</p> <p>In this tutorial, we use the QNG and QNG-SPSA optimizers with the Quantum Circuit Learning algorithm, a variational quantum algorithm which uses Quantum Neural Networks as universal function approximators.</p> <p>Keep in mind that only circuit parameters can be optimized with the QNG optimizer, since we can only calculate the QFI matrix of parameters contained in the circuit. If your model holds other trainable, non-circuit parameters, such as scaling or shifting of the input/output, another optimizer must be used for to optimize those parameters. <pre><code>import torch\nfrom torch.utils.data import random_split\nimport random\nimport matplotlib.pyplot as plt\n\nfrom qadence import QuantumCircuit, FeatureParameter\nfrom qadence import kron, tag, hea, RX, Z, hamiltonian_factory\n\nfrom qadence_model.models import QNN\nfrom qadence_model.optimizers import QuantumNaturalGradient\nfrom qadence_model.types import FisherApproximation\n</code></pre> </p> <p>First, we prepare the Quantum Circuit Learning data. In this case we will fit a simple one-dimensional sin(\\(x\\)) function: <pre><code># Ensure reproducibility\nseed = 0\ntorch.manual_seed(seed)\nrandom.seed(seed)\n\n# Create dataset\ndef qcl_training_data(\n    domain: tuple = (0, 2 * torch.pi), n_points: int = 200\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    start, end = domain\n\n    x_rand, _ = torch.sort(torch.DoubleTensor(n_points).uniform_(start, end))\n    y_rand = torch.sin(x_rand)\n\n    return x_rand, y_rand\n\n\nx, y = qcl_training_data()\n\n# random train/test split of the dataset\ntrain_subset, test_subset = random_split(x, [0.75, 0.25])\ntrain_ind = sorted(train_subset.indices)\ntest_ind = sorted(test_subset.indices)\n\nx_train, y_train = x[train_ind], y[train_ind]\nx_test, y_test = x[test_ind], y[test_ind]\n</code></pre> </p> <p>We now create the base Quantum Circuit that we will use with all the optimizers: <pre><code>n_qubits = 3\n\n# create a simple feature map to encode the input data\nfeature_param = FeatureParameter(\"phi\")\nfeature_map = kron(RX(i, feature_param) for i in range(n_qubits))\nfeature_map = tag(feature_map, \"feature_map\")\n\n# create a digital-analog variational ansatz using Qadence convenience constructors\nansatz = hea(n_qubits, depth=n_qubits)\nansatz = tag(ansatz, \"ansatz\")\n\n# Observable\nobservable = hamiltonian_factory(n_qubits, detuning= Z)\n</code></pre> </p>"},{"location":"model/qng/#optimizers","title":"Optimizers","text":"<p>We will experiment with three different optimizers: ADAM, QNG and QNG-SPSA. To train a model with the different optimizers we will create a <code>QuantumModel</code> and reset the values of their variational parameters before each training loop so that all of them have the same starting point.</p> <pre><code># Build circuit and model\ncircuit = QuantumCircuit(n_qubits, feature_map, ansatz)\nmodel = QNN(circuit, [observable])\n\n# Loss function\nmse_loss = torch.nn.MSELoss()\n\n# Initial parameter values\ninitial_params = torch.rand(model.num_vparams)\n</code></pre> <p>We can now train the model with the different corresponding optimizers:</p>"},{"location":"model/qng/#adam","title":"ADAM","text":"<pre><code># Train with ADAM\nn_epochs_adam = 20\nlr_adam = 0.1\n\nmodel.reset_vparams(initial_params)\noptimizer = torch.optim.Adam(model.parameters(), lr=lr_adam)\n\nloss_adam = []\nfor i in range(n_epochs_adam):\n    optimizer.zero_grad()\n    loss = mse_loss(model(values=x_train).squeeze(), y_train.squeeze())\n    loss_adam.append(float(loss))\n    loss.backward()\n    optimizer.step()\n</code></pre>"},{"location":"model/qng/#qng","title":"QNG","text":"<p>The way to initialize the <code>QuantumNaturalGradient</code> optimizer in <code>qadence-model</code> is slightly different from other usual Torch optimizers. Normally, one needs to pass a <code>params</code> argument to the optimizer to specify which parameters of the model should be optimized. In the <code>QuantumNaturalGradient</code>, it is assumed that all circuit parameters are to be optimized, whereas the non-circuit parameters will not be optimized. By circuit parameters, we mean parameters that somehow affect the quantum gates of the circuit and therefore influence the final quantum state. Any parameters affecting the observable (such as ouput scaling or shifting) are not considered circuit parameters, as those parameters will not be included in the QFI matrix as they don't affect the final state of the circuit.</p> <p>The <code>QuantumNaturalGradient</code> constructor takes a qadence's <code>QuantumModel</code> as the <code>model</code>, and it will automatically identify its circuit and non-circuit parameters. The <code>approximation</code> argument defaults to the SPSA method, however the exact version of the QNG is also implemented and can be used for small circuits (beware of using the exact version for large circuits, as it scales badly). \\(\\beta\\) is a small constant added to the QFI matrix before inversion to ensure numerical stability,</p> \\[(F_{ij} + \\beta \\mathbb{I})^{-1}\\] <p>where \\(\\mathbb{I}\\) is the identify matrix. It is always a good idea to try out different values of \\(\\beta\\) if the training is not converging, which might be due to a too small \\(\\beta\\).</p> <pre><code># Train with QNG\nn_epochs_qng = 20\nlr_qng = 0.1\n\nmodel.reset_vparams(initial_params)\noptimizer = QuantumNaturalGradient(\n    model=model,\n    lr=lr_qng,\n    approximation=FisherApproximation.EXACT,\n    beta=0.1,\n)\n\nloss_qng = []\nfor i in range(n_epochs_qng):\n    optimizer.zero_grad()\n    loss = mse_loss(model(values=x_train).squeeze(), y_train.squeeze())\n    loss_qng.append(float(loss))\n    loss.backward()\n    optimizer.step()\n</code></pre>"},{"location":"model/qng/#qng-spsa","title":"QNG-SPSA","text":"<p>The QNG-SPSA optimizer can be constructed similarly to the exact QNG, where now a new argument \\(\\epsilon\\) is used to control the shift used in the finite differences derivatives of the SPSA algorithm.</p> <pre><code># Train with QNG-SPSA\nn_epochs_qng_spsa = 20\nlr_qng_spsa = 0.01\n\nmodel.reset_vparams(initial_params)\noptimizer = QuantumNaturalGradient(\n    model=model,\n    lr=lr_qng_spsa,\n    approximation=FisherApproximation.SPSA,\n    beta=0.1,\n    epsilon=0.01,\n)\n\nloss_qng_spsa = []\nfor i in range(n_epochs_qng_spsa):\n    optimizer.zero_grad()\n    loss = mse_loss(model(values=x_train).squeeze(), y_train.squeeze())\n    loss_qng_spsa.append(float(loss))\n    loss.backward()\n    optimizer.step()\n</code></pre>"},{"location":"model/qng/#plotting","title":"Plotting","text":"<p>We now plot the losses corresponding to each of the optimizers: <pre><code># Plot losses\nfig, _ = plt.subplots()\nplt.plot(range(n_epochs_adam), loss_adam, label=\"Adam optimizer\")\nplt.plot(range(n_epochs_qng), loss_qng, label=\"QNG optimizer\")\nplt.plot(range(n_epochs_qng_spsa), loss_qng_spsa, label=\"QNG-SPSA optimizer\")\nplt.legend()\nplt.xlabel(\"Training epochs\")\nplt.ylabel(\"Loss\")\n</code></pre> </p>"},{"location":"model/qng/#references","title":"References","text":"<ol> <li> <p>Meyer J., Information in Noisy Intermediate-Scale Quantum Applications, Quantum 5, 539 (2021) \u21a9</p> </li> <li> <p>Stokes et al., Quantum Natural Gradient, Quantum 4, 269 (2020). \u21a9</p> </li> <li> <p>Gacon et al., Simultaneous Perturbation Stochastic Approximation of the Quantum Fisher Information, Quantum 5, 567 (2021). \u21a9</p> </li> </ol>"},{"location":"model/qnn_config/","title":"Configuring a QNN","text":"<p>In <code>qadence-model</code>, the <code>QNN</code> is a variational quantum model that can potentially take multi-dimensional input.</p> <p>The <code>QNN</code> class needs a circuit and a list of observables; the number of feature parameters in the input circuit determines the number of input features (i.e. the dimensionality of the classical data given as input) whereas the number of observables determines the number of outputs of the quantum neural network.</p> <p>The circuit has two parts, the feature map and the ansatz. The feature map is responsible for encoding the input data into the quantum state, while the ansatz is responsible for the variational part of the model. In addition, a third part of the QNN is the observables, which is (a list of) operators that are measured at the end of the circuit. In this tutorial, we will see how to do the same using configs.</p> <p>One convenient way to construct these two parts of the model is to use the config classes, namely, <code>FeatureMapConfig</code> and <code>AnsatzConfig</code>. These classes allow you to specify the type of circuit and the parameters of the circuit in a structured way.</p>"},{"location":"model/qnn_config/#defining-the-observable","title":"Defining the Observable","text":"<p>The model output is the expectation value of the defined observable(s). We use the <code>ObservableConfig</code> class to specify the observable.</p> <p>It can be used to create Hamiltonians with 2-qubit interactions and single-qubit detunings. Any Hamiltonian supported by <code>hamiltonian_factory</code> can be specified as an observable. For example, suppose we want to measure the Z operator:</p> <pre><code>from qadence import ObservableConfig, Z\nfrom qadence_model.models import create_observable\n\nobservable_config = ObservableConfig(\n    detuning=Z,\n    interaction = None,\n    scale = 2.0,\n    shift=-1.0,\n)\n\nobservable = create_observable(register=4, config=observable_config)\n</code></pre> %3 cluster_580af2a752564ef980cadb2c4b692952 5f06134d64504846baef1b1bc7e96f27 0 b9694ec03dcf4bd6b831826ec432b907 5f06134d64504846baef1b1bc7e96f27--b9694ec03dcf4bd6b831826ec432b907 00bda5eeaa7949f9bf76630f2e31ca37 1 9661552a703d45a69784d98fa62f74df b9694ec03dcf4bd6b831826ec432b907--9661552a703d45a69784d98fa62f74df fdcec80df0a945139491b48b4c92b237 7286daa164f04039921218187b25e991 AddBlock 00bda5eeaa7949f9bf76630f2e31ca37--7286daa164f04039921218187b25e991 9510769259574b408d66f700da6d87c0 2 7286daa164f04039921218187b25e991--fdcec80df0a945139491b48b4c92b237 af383862a70b4612ac2646d26e4ffe22 4d4b40a4a38b44f5bf937b173179de80 9510769259574b408d66f700da6d87c0--4d4b40a4a38b44f5bf937b173179de80 23a67a52476340448b746ffd78a12b00 3 4d4b40a4a38b44f5bf937b173179de80--af383862a70b4612ac2646d26e4ffe22 2b2486cd1e6f4c288b0e09f51e011202 ddc3f235c1284ed1a077d3e7bf35abee 23a67a52476340448b746ffd78a12b00--ddc3f235c1284ed1a077d3e7bf35abee ddc3f235c1284ed1a077d3e7bf35abee--2b2486cd1e6f4c288b0e09f51e011202"},{"location":"model/qnn_config/#defining-the-feature-map","title":"Defining the Feature Map","text":"<p>Let us say we want to build a 4-qubit QNN that takes two inputs, namely, the \\(x\\) and the \\(y\\) coordinates of a point in the plane. We can use the <code>FeatureMapConfig</code> class to specify the feature map.</p> <pre><code>from qadence import BasisSet, chain, ReuploadScaling\nfrom qadence_model.models import create_fm_blocks, FeatureMapConfig\n\nfm_config = FeatureMapConfig(\n    num_features=2,\n    inputs = [\"x\", \"y\"],\n    basis_set=BasisSet.CHEBYSHEV,\n    reupload_scaling=ReuploadScaling.TOWER,\n    feature_range={\n        \"x\": (-1.0, 1.0),\n        \"y\": (0.0, 1.0),\n    },\n)\n\nfm_blocks = create_fm_blocks(register=4, config=fm_config)\nfeature_map = chain(*fm_blocks)\n</code></pre> %3 cluster_edccd1f7da7f4370a4f7e236621e40a6 Tower Chebyshev FM cluster_0e1a843860614db7b6020ea68544c170 Tower Chebyshev FM 03d015d7eaef49f7bfe7e5fa5d40a8b0 0 9dd307744dbd4ba8a875fa8492e9d42f RX(1.0*acos(x)) 03d015d7eaef49f7bfe7e5fa5d40a8b0--9dd307744dbd4ba8a875fa8492e9d42f cbf8efc21d3347799e1c3f1687320339 1 dd55391a7de74793a905c3cd2a75e245 9dd307744dbd4ba8a875fa8492e9d42f--dd55391a7de74793a905c3cd2a75e245 854bbbe98bd1477484adcbe5eb37c758 0407b41d81a543ec976d3e3b261b4a85 RX(2.0*acos(x)) cbf8efc21d3347799e1c3f1687320339--0407b41d81a543ec976d3e3b261b4a85 3e3ce88ece934fa2b60e850f77b0dfd0 2 0407b41d81a543ec976d3e3b261b4a85--854bbbe98bd1477484adcbe5eb37c758 10788efe18c34f409faf33fca00f294c ce77730384cb44ddb38e65b990a1b427 RX(1.0*acos(2.0*y - 1.0)) 3e3ce88ece934fa2b60e850f77b0dfd0--ce77730384cb44ddb38e65b990a1b427 6a0183ac04c04d2cb6c02427dbf0de5f 3 ce77730384cb44ddb38e65b990a1b427--10788efe18c34f409faf33fca00f294c d178760b9e7d4eac8b8029cc3fc06516 53003d106d6b44e28a63d29f8dd67e97 RX(2.0*acos(2.0*y - 1.0)) 6a0183ac04c04d2cb6c02427dbf0de5f--53003d106d6b44e28a63d29f8dd67e97 53003d106d6b44e28a63d29f8dd67e97--d178760b9e7d4eac8b8029cc3fc06516 <p>We have specified that the feature map should take two features, and have named the <code>FeatureParameter</code> \"x\" and \"y\" respectively. Both these parameters are encoded using the Chebyshev basis set, and the reupload scaling is set to <code>ReuploadScaling.TOWER</code>. One can optionally add the basis and the reupload scaling for each parameter separately.</p> <p>The <code>feature_range</code> parameter is a dictionary that specifies the range of values that each feature comes from. This is useful for scaling the input data to the range that the encoding function can handle. In default case, this range is mapped to the target range of the Chebyshev basis set which is \\([-1, 1]\\). One can also specify the target range for each feature separately..</p>"},{"location":"model/qnn_config/#defining-the-ansatz","title":"Defining the Ansatz","text":"<p>The next part of the QNN is the ansatz. We use <code>AnsatzConfig</code> class to specify the type of ansatz.</p> <p>Let us say, we want to follow this feature map with 2 layers of hardware efficient ansatz.</p> <pre><code>from qadence import AnsatzType, Strategy\nfrom qadence_model.models import AnsatzConfig, create_ansatz\n\nansatz_config = AnsatzConfig(\n    depth=2,\n    ansatz_type=AnsatzType.HEA,\n    ansatz_strategy=Strategy.DIGITAL,\n)\n\nansatz = create_ansatz(register=4, config=ansatz_config)\n</code></pre> %3 3e05792be8424cd385d9c13268b38292 0 9a888c77bf1543f292420c8ec8f9e9ce RX(theta\u2080) 3e05792be8424cd385d9c13268b38292--9a888c77bf1543f292420c8ec8f9e9ce 94457de9a5844a6da17f7f8679702c64 1 085f213ecd5a4d3789ec1a15b55ebd9e RY(theta\u2084) 9a888c77bf1543f292420c8ec8f9e9ce--085f213ecd5a4d3789ec1a15b55ebd9e 14850229363247c7aaab0fac460338f6 RX(theta\u2088) 085f213ecd5a4d3789ec1a15b55ebd9e--14850229363247c7aaab0fac460338f6 eab8b0d1e7f5480c85fb3cc001f59594 14850229363247c7aaab0fac460338f6--eab8b0d1e7f5480c85fb3cc001f59594 0f8d047c759843c2ad4dad08f63875f6 eab8b0d1e7f5480c85fb3cc001f59594--0f8d047c759843c2ad4dad08f63875f6 1e2eecb4cc6648d582ba75d3407b1ecb RX(theta\u2081\u2082) 0f8d047c759843c2ad4dad08f63875f6--1e2eecb4cc6648d582ba75d3407b1ecb 22ae2d9b842d4921806cf7817d09f624 RY(theta\u2081\u2086) 1e2eecb4cc6648d582ba75d3407b1ecb--22ae2d9b842d4921806cf7817d09f624 4146c80a06784f458d8cc582fe843d23 RX(theta\u2082\u2080) 22ae2d9b842d4921806cf7817d09f624--4146c80a06784f458d8cc582fe843d23 61975c0cb52c47deadf7efc588446720 4146c80a06784f458d8cc582fe843d23--61975c0cb52c47deadf7efc588446720 c9539ba2783548e0b380f885f1f8eae3 61975c0cb52c47deadf7efc588446720--c9539ba2783548e0b380f885f1f8eae3 d2401291a49e46419cc6c3b5613135d6 c9539ba2783548e0b380f885f1f8eae3--d2401291a49e46419cc6c3b5613135d6 d6c0796475424b23a73bd30208cc5c83 aa694d3951ed42bea31b91e1f0029988 RX(theta\u2081) 94457de9a5844a6da17f7f8679702c64--aa694d3951ed42bea31b91e1f0029988 d6c099e086284e898f2056c48ffc10d9 2 155287b86cb54996aba4d759a7f363b4 RY(theta\u2085) aa694d3951ed42bea31b91e1f0029988--155287b86cb54996aba4d759a7f363b4 23c33e9955b842a2a173cca11e1efcf1 RX(theta\u2089) 155287b86cb54996aba4d759a7f363b4--23c33e9955b842a2a173cca11e1efcf1 84795da5ce304168844666070cdb5af7 X 23c33e9955b842a2a173cca11e1efcf1--84795da5ce304168844666070cdb5af7 84795da5ce304168844666070cdb5af7--eab8b0d1e7f5480c85fb3cc001f59594 a381e15ec6da4812b04123adc0f9efd6 84795da5ce304168844666070cdb5af7--a381e15ec6da4812b04123adc0f9efd6 056f8d8dffd74113912c9b2b51e6d899 RX(theta\u2081\u2083) a381e15ec6da4812b04123adc0f9efd6--056f8d8dffd74113912c9b2b51e6d899 b0956952351d4cd182636ddfffc553b0 RY(theta\u2081\u2087) 056f8d8dffd74113912c9b2b51e6d899--b0956952351d4cd182636ddfffc553b0 56fd10f1126d4e8bbaab9968ba49ccf9 RX(theta\u2082\u2081) b0956952351d4cd182636ddfffc553b0--56fd10f1126d4e8bbaab9968ba49ccf9 1fbef4a75dc54c9ba03c8572c436b0cd X 56fd10f1126d4e8bbaab9968ba49ccf9--1fbef4a75dc54c9ba03c8572c436b0cd 1fbef4a75dc54c9ba03c8572c436b0cd--61975c0cb52c47deadf7efc588446720 4888c636ab1743d6bf117a411e15294c 1fbef4a75dc54c9ba03c8572c436b0cd--4888c636ab1743d6bf117a411e15294c 4888c636ab1743d6bf117a411e15294c--d6c0796475424b23a73bd30208cc5c83 0ed5a705e0174de48d596569f66798fd a23768d42790428f8115d1d46ee028ae RX(theta\u2082) d6c099e086284e898f2056c48ffc10d9--a23768d42790428f8115d1d46ee028ae 34295e4f9e974e799a00042ef06d7afd 3 976195b70eb64680b7f06fefe3795d6c RY(theta\u2086) a23768d42790428f8115d1d46ee028ae--976195b70eb64680b7f06fefe3795d6c 79703d16af914de8968275279fa3b94f RX(theta\u2081\u2080) 976195b70eb64680b7f06fefe3795d6c--79703d16af914de8968275279fa3b94f ecaab4ed9cde49fd99a786be07d5e327 79703d16af914de8968275279fa3b94f--ecaab4ed9cde49fd99a786be07d5e327 21865835c78e438eb384bb031c7faebd X ecaab4ed9cde49fd99a786be07d5e327--21865835c78e438eb384bb031c7faebd 21865835c78e438eb384bb031c7faebd--a381e15ec6da4812b04123adc0f9efd6 db5b4b5673454dc4a7f5fbac531cd012 RX(theta\u2081\u2084) 21865835c78e438eb384bb031c7faebd--db5b4b5673454dc4a7f5fbac531cd012 140a87c60a2640e39ea09103b2ce78e2 RY(theta\u2081\u2088) db5b4b5673454dc4a7f5fbac531cd012--140a87c60a2640e39ea09103b2ce78e2 f58fbf6977a54e138cddd0bf49a75d69 RX(theta\u2082\u2082) 140a87c60a2640e39ea09103b2ce78e2--f58fbf6977a54e138cddd0bf49a75d69 ba2b22b77f074d808d32859edb58186e f58fbf6977a54e138cddd0bf49a75d69--ba2b22b77f074d808d32859edb58186e 19d150f237104d4bb277809d4d1207f3 X ba2b22b77f074d808d32859edb58186e--19d150f237104d4bb277809d4d1207f3 19d150f237104d4bb277809d4d1207f3--4888c636ab1743d6bf117a411e15294c 19d150f237104d4bb277809d4d1207f3--0ed5a705e0174de48d596569f66798fd f010a1748e994fcea33a0f9d5931fb0e e29b3baf449149029f6e6559e248be1a RX(theta\u2083) 34295e4f9e974e799a00042ef06d7afd--e29b3baf449149029f6e6559e248be1a c2eb4bc4d41c4a039303dca69c99c7d9 RY(theta\u2087) e29b3baf449149029f6e6559e248be1a--c2eb4bc4d41c4a039303dca69c99c7d9 acb4d73a94d2423aae00ac75f72b5cdf RX(theta\u2081\u2081) c2eb4bc4d41c4a039303dca69c99c7d9--acb4d73a94d2423aae00ac75f72b5cdf 5010130896f64b2e81e3841a705e83a2 X acb4d73a94d2423aae00ac75f72b5cdf--5010130896f64b2e81e3841a705e83a2 5010130896f64b2e81e3841a705e83a2--ecaab4ed9cde49fd99a786be07d5e327 b451e99a00c84391b9664bec3a96571b 5010130896f64b2e81e3841a705e83a2--b451e99a00c84391b9664bec3a96571b 741858134fdd4bfa9753cf132a399931 RX(theta\u2081\u2085) b451e99a00c84391b9664bec3a96571b--741858134fdd4bfa9753cf132a399931 be58aacc40a545019367050292608148 RY(theta\u2081\u2089) 741858134fdd4bfa9753cf132a399931--be58aacc40a545019367050292608148 1119796545aa470b87cf76fca652501a RX(theta\u2082\u2083) be58aacc40a545019367050292608148--1119796545aa470b87cf76fca652501a a7ee382fdbc149d28a0a6878582d5dff X 1119796545aa470b87cf76fca652501a--a7ee382fdbc149d28a0a6878582d5dff a7ee382fdbc149d28a0a6878582d5dff--ba2b22b77f074d808d32859edb58186e 7dd9599c39a2455785f0889b7e806de7 a7ee382fdbc149d28a0a6878582d5dff--7dd9599c39a2455785f0889b7e806de7 7dd9599c39a2455785f0889b7e806de7--f010a1748e994fcea33a0f9d5931fb0e <p>We have specified that the ansatz should have a depth of 2, and the ansatz type is \"hea\" (Hardware Efficient Ansatz). The ansatz strategy is set to \"digital\", which means digital gates are being used. One could alternatively use \"analog\" or \"rydberg\" as the ansatz strategy.</p>"},{"location":"model/qnn_config/#defining-the-qnn-from-the-configs","title":"Defining the QNN from the Configs","text":"<p>To build the QNN, we can now use the <code>QNN</code> class as a <code>QuantumModel</code> subtype. In addition to the feature map, ansatz and the observable configs, we can also specify options such as the <code>backend</code>, <code>diff_mode</code>, etc.</p> <pre><code>from qadence import BackendName, DiffMode, ObservableConfig, Z\nfrom qadence_model.models import QNN\n\nobservable_config = ObservableConfig(\n    detuning=Z,\n    interaction = None,\n    scale = 2.0,\n    shift=-1.0,\n)\n\nqnn = QNN.from_configs(\n    register=4,\n    obs_config=observable_config,\n    fm_config=fm_config,\n    ansatz_config=ansatz_config,\n    backend=BackendName.PYQTORCH,\n    diff_mode=DiffMode.AD,\n)\n</code></pre> %3 cluster_8ad9c5c7970a4f5ba626937bb960996e Obs. cluster_79d31682b3ff4819bfc68b9f8e2f95b9 cluster_a05a1061ebf24028a50eaabca1d1eb73 Tower Chebyshev FM cluster_dce03147246a4fa6ac20643ece949c4d Tower Chebyshev FM cluster_44602ad5390c4671ae45f2f3aeaa6e78 HEA 7982456067f84dbbafc73b2fc288d951 0 0628c9d8b55f4889b42cb26151bbe593 RX(1.0*acos(x)) 7982456067f84dbbafc73b2fc288d951--0628c9d8b55f4889b42cb26151bbe593 a06d652c483448788585f6938aa448ed 1 82f67e38ba01490398848c9ea33e6796 RX(theta\u2080) 0628c9d8b55f4889b42cb26151bbe593--82f67e38ba01490398848c9ea33e6796 8697f5d0a56146b0b5bc5a54a38f6379 RY(theta\u2084) 82f67e38ba01490398848c9ea33e6796--8697f5d0a56146b0b5bc5a54a38f6379 535d6b9a8b7040ebb7aeb23d2afdbd4f RX(theta\u2088) 8697f5d0a56146b0b5bc5a54a38f6379--535d6b9a8b7040ebb7aeb23d2afdbd4f 6c99045183354848bbc9243d5b5513ec 535d6b9a8b7040ebb7aeb23d2afdbd4f--6c99045183354848bbc9243d5b5513ec b50927e8750748bc8c71ccb66b24ca2d 6c99045183354848bbc9243d5b5513ec--b50927e8750748bc8c71ccb66b24ca2d 6377a682ab20478598258018c0d7a773 RX(theta\u2081\u2082) b50927e8750748bc8c71ccb66b24ca2d--6377a682ab20478598258018c0d7a773 8a93ec3e373e4f5eaee97fcfd35f5783 RY(theta\u2081\u2086) 6377a682ab20478598258018c0d7a773--8a93ec3e373e4f5eaee97fcfd35f5783 6a856e7cc0c6426bb6c2db4c0d80182a RX(theta\u2082\u2080) 8a93ec3e373e4f5eaee97fcfd35f5783--6a856e7cc0c6426bb6c2db4c0d80182a 4bc399bb38174affa38be975424e377e 6a856e7cc0c6426bb6c2db4c0d80182a--4bc399bb38174affa38be975424e377e 1a4f35228a394890906efb8d81d176cf 4bc399bb38174affa38be975424e377e--1a4f35228a394890906efb8d81d176cf 96ba72efee624c92a13699562e7858db 1a4f35228a394890906efb8d81d176cf--96ba72efee624c92a13699562e7858db 0037d6c664d74cbca084efbc58f4e287 96ba72efee624c92a13699562e7858db--0037d6c664d74cbca084efbc58f4e287 7f0ce7869ba74ae38df5636505a0d29e a5f0b0997ffe40439b290747d3c14681 RX(2.0*acos(x)) a06d652c483448788585f6938aa448ed--a5f0b0997ffe40439b290747d3c14681 df50ea63f5b04ac5ae29a736cccd9be0 2 aced224583be40e28bfc8eca7dadba4a RX(theta\u2081) a5f0b0997ffe40439b290747d3c14681--aced224583be40e28bfc8eca7dadba4a fc4b192019734ad2b26c29cc894c7f82 RY(theta\u2085) aced224583be40e28bfc8eca7dadba4a--fc4b192019734ad2b26c29cc894c7f82 9e58c81c804240e3969e768c7ff61dd6 RX(theta\u2089) fc4b192019734ad2b26c29cc894c7f82--9e58c81c804240e3969e768c7ff61dd6 8cfc701540c04bcd911718f2924b88af X 9e58c81c804240e3969e768c7ff61dd6--8cfc701540c04bcd911718f2924b88af 8cfc701540c04bcd911718f2924b88af--6c99045183354848bbc9243d5b5513ec 33d6cf01b1de4409badb2d6f3dbcaadc 8cfc701540c04bcd911718f2924b88af--33d6cf01b1de4409badb2d6f3dbcaadc e40d9d0ddaa949fa87e5d51bcdcc830b RX(theta\u2081\u2083) 33d6cf01b1de4409badb2d6f3dbcaadc--e40d9d0ddaa949fa87e5d51bcdcc830b 3fbfdf73b9aa4b8b8f735297027c2d05 RY(theta\u2081\u2087) e40d9d0ddaa949fa87e5d51bcdcc830b--3fbfdf73b9aa4b8b8f735297027c2d05 66adad47cc8a4aa59493ba6bbb2bd48a RX(theta\u2082\u2081) 3fbfdf73b9aa4b8b8f735297027c2d05--66adad47cc8a4aa59493ba6bbb2bd48a 10db8b6ec4d1401986054bcf35bbf908 X 66adad47cc8a4aa59493ba6bbb2bd48a--10db8b6ec4d1401986054bcf35bbf908 10db8b6ec4d1401986054bcf35bbf908--4bc399bb38174affa38be975424e377e 821e8ec3ab304898bf97cf64328ba9ca 10db8b6ec4d1401986054bcf35bbf908--821e8ec3ab304898bf97cf64328ba9ca adbcfd6038ba4fbfaca22ae90b9719a1 AddBlock 821e8ec3ab304898bf97cf64328ba9ca--adbcfd6038ba4fbfaca22ae90b9719a1 adbcfd6038ba4fbfaca22ae90b9719a1--7f0ce7869ba74ae38df5636505a0d29e af4ff7fdd7c6401fb38068e20fd7b597 679516c0bc0145cca10cdec64eadccdf RX(1.0*acos(2.0*y - 1.0)) df50ea63f5b04ac5ae29a736cccd9be0--679516c0bc0145cca10cdec64eadccdf b8c9771d0c364ad7acfd5dd7782eccdb 3 c50e4000e1734fd7ade1fdd12aef47a5 RX(theta\u2082) 679516c0bc0145cca10cdec64eadccdf--c50e4000e1734fd7ade1fdd12aef47a5 1103a56fcbc54060b52a7a771e7c5a38 RY(theta\u2086) c50e4000e1734fd7ade1fdd12aef47a5--1103a56fcbc54060b52a7a771e7c5a38 fa696b5022ed4129a36f2f589d7b7d87 RX(theta\u2081\u2080) 1103a56fcbc54060b52a7a771e7c5a38--fa696b5022ed4129a36f2f589d7b7d87 e67d24559ced4ee9afaafc9be71b33ae fa696b5022ed4129a36f2f589d7b7d87--e67d24559ced4ee9afaafc9be71b33ae 3bc346eb30ff471abca54818d8c0127a X e67d24559ced4ee9afaafc9be71b33ae--3bc346eb30ff471abca54818d8c0127a 3bc346eb30ff471abca54818d8c0127a--33d6cf01b1de4409badb2d6f3dbcaadc b5936ec0fff341129eaa587f336db76f RX(theta\u2081\u2084) 3bc346eb30ff471abca54818d8c0127a--b5936ec0fff341129eaa587f336db76f ac3c185746f2461cafe33dc1c6519f66 RY(theta\u2081\u2088) b5936ec0fff341129eaa587f336db76f--ac3c185746f2461cafe33dc1c6519f66 fbbbad14af7141d1ad37ba139e2fe93f RX(theta\u2082\u2082) ac3c185746f2461cafe33dc1c6519f66--fbbbad14af7141d1ad37ba139e2fe93f fb276b95606640b1b00aa58881fb7923 fbbbad14af7141d1ad37ba139e2fe93f--fb276b95606640b1b00aa58881fb7923 7d9a6e9d7761469eb5fbb70cc6facbaa X fb276b95606640b1b00aa58881fb7923--7d9a6e9d7761469eb5fbb70cc6facbaa 7d9a6e9d7761469eb5fbb70cc6facbaa--821e8ec3ab304898bf97cf64328ba9ca d87061a701504d1487003036d68e63c2 7d9a6e9d7761469eb5fbb70cc6facbaa--d87061a701504d1487003036d68e63c2 d87061a701504d1487003036d68e63c2--af4ff7fdd7c6401fb38068e20fd7b597 23e2f1cfecb449bfbc15eb3217f61876 56184cc0a3d347aa851ba646b4c84f2c RX(2.0*acos(2.0*y - 1.0)) b8c9771d0c364ad7acfd5dd7782eccdb--56184cc0a3d347aa851ba646b4c84f2c e2143b186911444fae6e7570733606e1 RX(theta\u2083) 56184cc0a3d347aa851ba646b4c84f2c--e2143b186911444fae6e7570733606e1 23199f90aaae4740b7c5626e95599800 RY(theta\u2087) e2143b186911444fae6e7570733606e1--23199f90aaae4740b7c5626e95599800 88bb6d304819449e8f5c1e2b6f2ee61b RX(theta\u2081\u2081) 23199f90aaae4740b7c5626e95599800--88bb6d304819449e8f5c1e2b6f2ee61b a8b1b9272e174205ae45179856214d22 X 88bb6d304819449e8f5c1e2b6f2ee61b--a8b1b9272e174205ae45179856214d22 a8b1b9272e174205ae45179856214d22--e67d24559ced4ee9afaafc9be71b33ae eda426e7cee34a1bb41c97a52087208b a8b1b9272e174205ae45179856214d22--eda426e7cee34a1bb41c97a52087208b 55a3c30eebe242f9b894e7dcc9d72d6e RX(theta\u2081\u2085) eda426e7cee34a1bb41c97a52087208b--55a3c30eebe242f9b894e7dcc9d72d6e f4007a4aa4244364a987194b0acf9dba RY(theta\u2081\u2089) 55a3c30eebe242f9b894e7dcc9d72d6e--f4007a4aa4244364a987194b0acf9dba ec27b92d8f3a432c82443b7c32714f20 RX(theta\u2082\u2083) f4007a4aa4244364a987194b0acf9dba--ec27b92d8f3a432c82443b7c32714f20 c1e1d3fe36ff4282b4bdf6f09956206a X ec27b92d8f3a432c82443b7c32714f20--c1e1d3fe36ff4282b4bdf6f09956206a c1e1d3fe36ff4282b4bdf6f09956206a--fb276b95606640b1b00aa58881fb7923 1b4dd61767b44697aa08670864b73480 c1e1d3fe36ff4282b4bdf6f09956206a--1b4dd61767b44697aa08670864b73480 6f8958c04261452f8567d93b45ab9991 1b4dd61767b44697aa08670864b73480--6f8958c04261452f8567d93b45ab9991 6f8958c04261452f8567d93b45ab9991--23e2f1cfecb449bfbc15eb3217f61876"}]}