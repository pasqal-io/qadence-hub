{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Qadence Model","text":"<p>Qadence Model is a collection of features to enhance Qadence quantum machine learning features</p>"},{"location":"CODE_OF_CONDUCT/","title":"CODE OF CONDUCT","text":"<p>Code of Conduct</p>"},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"CONTRIBUTING/","title":"How to contribute","text":"<p>We're grateful for your interest in participating in qadence-model. Please follow our guidelines to ensure a smooth contribution process.</p>"},{"location":"CONTRIBUTING/#contribution-guide-for-developers","title":"Contribution Guide for Developers","text":"<ul> <li>Submitting Issues: To submit bug reports or feature requests, please use our issue tracker.</li> </ul>"},{"location":"CONTRIBUTING/#reporting-an-issue-or-proposing-a-feature","title":"Reporting an issue or proposing a feature","text":"<p>Your course of action will depend on your objective, but generally, you should start by creating an issue. If you've discovered a bug or have a feature you'd like to see added to qadence-model, feel free to create an issue on qadence-hubs's GitHub issue tracker. Here are some steps to take:</p> <ol> <li>Quickly search the existing issues using relevant keywords to ensure your issue hasn't been addressed already.</li> <li> <p>If your issue is not listed, create a new one. Try to be as detailed and clear as possible in your description.</p> </li> <li> <p>If you're merely suggesting an improvement or reporting a bug, that's already excellent! We thank you for it. Your issue will be listed and, hopefully, addressed at some point.</p> </li> </ol>"},{"location":"CONTRIBUTING/#setup-with-downloading-the-whole-git-repository","title":"Setup with downloading the whole git repository","text":"<p>To work with <code>qadence-model</code>, you should clone the entire GitHub repository and then access the individual projects. This approach is recommended for easier branch management, and cloning only a specific project is discouraged. After cloning the full repository, navigate to the desired project folder to run the Hatch environment or make code modifications. The example code snippet is like below:</p> <pre><code>git clone https://github.com/pasqal-io/qadence-hub.git\ncd qadence-hub/qadence-model\n</code></pre>"},{"location":"CONTRIBUTING/#making-pull-request","title":"Making Pull Request","text":"<p>If you\u2019ve modified the code of a <code>qadence-model</code> package, you should create a pull request targeting the <code>main-model</code> branch. Our branch structure manages each package through its corresponding <code>sub-main branch</code> before anything is merged into the <code>main branch</code>. Therefore, after cloning the repository, you should follow your previous workflow to create a local branch and push it\u2014but your pull request target should be your <code>main-model</code> branch, not <code>main</code>. After your branch is merged to <code>main-model</code> branch, you can initiate merge request to the <code>main</code> branch. Merging into <code>main</code> branch should be done only when a release is being prepared.</p>"},{"location":"CONTRIBUTING/#releasing-projects-and-publishing-to-pypi","title":"Releasing Projects and Publishing to PyPI","text":"<p>After you merge your <code>main-model</code> branch to <code>main</code> branch, you can publish your documents and Python package through release. To do this, you need to update the version number in the package's <code>pyproject.toml</code>. Then, you create a release with the format of <code>package_name-v.x.y.z,</code> where x, y, and z are for version numbers. For example, if you want to publish <code>qadence-model</code> with version 1.2.5, you must put <code>model-v1.2.5</code> as your release name.</p>"},{"location":"CONTRIBUTING/#setting-up-your-development-environment","title":"Setting up your development environment","text":"<p>We recommended to use <code>hatch</code> for managing environments.</p> <p>To develop within qadence-hub packages, use: <pre><code>cd qadence-model\npip install hatch\nhatch -v shell\n</code></pre></p>"},{"location":"CONTRIBUTING/#useful-thing-for-your-workflow-linting","title":"Useful thing for your workflow: linting","text":"<p>Use <code>pre-commit</code> to lint your code and run the unit tests before pushing a new commit.</p> <p>Using <code>hatch</code>, it's simply:</p> <pre><code>pre-commit install\nhatch -e tests run pre-commit run --all-files\n</code></pre> <p>Our CI/CD pipeline will also test if the documentation can be built correctly. To test it locally, please run:</p> <pre><code>hatch -e docs run mkdocs build --clean --strict\n</code></pre> <p>Without <code>hatch</code>, <code>pip</code> install those libraries first: \"mkdocs\", \"mkdocs-material\", \"mkdocstrings\", \"mkdocstrings-python\", \"mkdocs-section-index\", \"mkdocs-jupyter\", \"mkdocs-exclude\", \"markdown-exec\"</p> <p>And then:</p> <pre><code> mkdocs build --clean --strict\n</code></pre>"},{"location":"docsutils/","title":"Docsutils","text":"In\u00a0[\u00a0]: Copied! <pre>from __future__ import annotations\n</pre> from __future__ import annotations In\u00a0[\u00a0]: Copied! <pre>import itertools\nfrom io import StringIO\nfrom typing import Callable\n</pre> import itertools from io import StringIO from typing import Callable In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport torch\nfrom matplotlib.figure import Figure\n</pre> import numpy as np import torch from matplotlib.figure import Figure In\u00a0[\u00a0]: Copied! <pre>from qadence import (\n    QNN,\n    RX,\n    RY,\n    HamEvo,\n    Parameter,\n    QuantumCircuit,\n    Z,\n    add,\n    chain,\n    hea,\n    kron,\n    tag,\n)\nfrom qadence.blocks import AbstractBlock\n</pre> from qadence import (     QNN,     RX,     RY,     HamEvo,     Parameter,     QuantumCircuit,     Z,     add,     chain,     hea,     kron,     tag, ) from qadence.blocks import AbstractBlock In\u00a0[\u00a0]: Copied! <pre>def fig_to_html(fig: Figure) -&gt; str:\n    buffer = StringIO()\n    fig.savefig(buffer, format=\"svg\")\n    return buffer.getvalue()\n</pre> def fig_to_html(fig: Figure) -&gt; str:     buffer = StringIO()     fig.savefig(buffer, format=\"svg\")     return buffer.getvalue() In\u00a0[\u00a0]: Copied! <pre>def hardware_efficient_ansatz(n_qubits: int = 2, depth: int = 1) -&gt; AbstractBlock:\n    return hea(n_qubits=n_qubits, depth=depth)\n</pre> def hardware_efficient_ansatz(n_qubits: int = 2, depth: int = 1) -&gt; AbstractBlock:     return hea(n_qubits=n_qubits, depth=depth) In\u00a0[\u00a0]: Copied! <pre>def digital_analog_ansatz(\n    h_generator: AbstractBlock, n_qubits: int = 2, depth: int = 1, t_evo: float = 1.0\n) -&gt; AbstractBlock:\n    time_evolution = HamEvo(h_generator, t_evo)\n\n    it = itertools.count()\n    ops = []\n    for _ in range(depth):\n        layer = kron(\n            *[\n                chain(*(gate(n, f\"theta{next(it)}\") for gate in [RX, RY, RX]))\n                for n in range(n_qubits)\n            ]\n        )\n        ops.append(chain(layer, time_evolution))\n    return chain(*ops)\n</pre> def digital_analog_ansatz(     h_generator: AbstractBlock, n_qubits: int = 2, depth: int = 1, t_evo: float = 1.0 ) -&gt; AbstractBlock:     time_evolution = HamEvo(h_generator, t_evo)      it = itertools.count()     ops = []     for _ in range(depth):         layer = kron(             *[                 chain(*(gate(n, f\"theta{next(it)}\") for gate in [RX, RY, RX]))                 for n in range(n_qubits)             ]         )         ops.append(chain(layer, time_evolution))     return chain(*ops) In\u00a0[\u00a0]: Copied! <pre>def qcl_circuit(n_qubits: int = 2, depth: int = 1, use_digital_analog: bool = False):\n    # Chebyshev feature map with input parameter defined as non trainable\n    phi = Parameter(\"phi\", trainable=False)\n    fm = chain(*[RY(i, phi) for i in range(n_qubits)])\n    tag(fm, \"feature_map\")\n\n    if not use_digital_analog:\n        # hardware-efficient ansatz\n        ansatz = hardware_efficient_ansatz(n_qubits=n_qubits, depth=depth)\n    else:\n        # Hamiltonian evolution ansatz (digital-analog)\n        t_evo = 3.0  # length of the time evolution\n        h_generator = add(\n            *[Z(i) for i in range(n_qubits)]\n        )  # use total magnetization as Hamiltonian\n        ansatz = digital_analog_ansatz(h_generator, n_qubits=n_qubits, depth=depth, t_evo=t_evo)\n\n    tag(ansatz, \"ansatz\")\n\n    # add a final fixed layer or rotations\n    fixed_layer = chain(*[RY(i, np.pi / 2) for i in range(n_qubits)])\n    tag(fixed_layer, \"fixed\")\n\n    blocks = [fm, ansatz, fixed_layer]\n    return QuantumCircuit(n_qubits, *blocks)\n</pre> def qcl_circuit(n_qubits: int = 2, depth: int = 1, use_digital_analog: bool = False):     # Chebyshev feature map with input parameter defined as non trainable     phi = Parameter(\"phi\", trainable=False)     fm = chain(*[RY(i, phi) for i in range(n_qubits)])     tag(fm, \"feature_map\")      if not use_digital_analog:         # hardware-efficient ansatz         ansatz = hardware_efficient_ansatz(n_qubits=n_qubits, depth=depth)     else:         # Hamiltonian evolution ansatz (digital-analog)         t_evo = 3.0  # length of the time evolution         h_generator = add(             *[Z(i) for i in range(n_qubits)]         )  # use total magnetization as Hamiltonian         ansatz = digital_analog_ansatz(h_generator, n_qubits=n_qubits, depth=depth, t_evo=t_evo)      tag(ansatz, \"ansatz\")      # add a final fixed layer or rotations     fixed_layer = chain(*[RY(i, np.pi / 2) for i in range(n_qubits)])     tag(fixed_layer, \"fixed\")      blocks = [fm, ansatz, fixed_layer]     return QuantumCircuit(n_qubits, *blocks) In\u00a0[\u00a0]: Copied! <pre>def qcl_training_data(\n    fn: Callable, domain: tuple = (0, 2 * np.pi), n_teacher: int = 100\n) -&gt; tuple[torch.tensor, torch.tensor]:\n    start, end = domain\n    x_rand_np = np.sort(np.random.uniform(low=start, high=end, size=n_teacher))\n    y_rand_np = fn(x_rand_np)\n\n    x_rand = torch.tensor(x_rand_np)\n    y_rand = torch.tensor(y_rand_np)\n\n    return x_rand, y_rand\n</pre> def qcl_training_data(     fn: Callable, domain: tuple = (0, 2 * np.pi), n_teacher: int = 100 ) -&gt; tuple[torch.tensor, torch.tensor]:     start, end = domain     x_rand_np = np.sort(np.random.uniform(low=start, high=end, size=n_teacher))     y_rand_np = fn(x_rand_np)      x_rand = torch.tensor(x_rand_np)     y_rand = torch.tensor(y_rand_np)      return x_rand, y_rand In\u00a0[\u00a0]: Copied! <pre>def qcl_train_model(\n    model: QNN, x_train: torch.Tensor, y_train: torch.Tensor, n_epochs: int = 50, lr: float = 1.0\n) -&gt; QNN:\n    mse_loss = torch.nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    print(f\"Initial loss: {mse_loss(model(x_train), y_train)}\")\n\n    for i in range(n_epochs):\n        optimizer.zero_grad()\n\n        loss = mse_loss(model(x_train), y_train)\n        loss.backward()\n        optimizer.step()\n\n        if (i + 1) % 10 == 0:\n            print(f\"Epoch {i+1} training - Loss: {loss.item()}\")\n\n    return model\n</pre> def qcl_train_model(     model: QNN, x_train: torch.Tensor, y_train: torch.Tensor, n_epochs: int = 50, lr: float = 1.0 ) -&gt; QNN:     mse_loss = torch.nn.MSELoss()     optimizer = torch.optim.Adam(model.parameters(), lr=lr)      print(f\"Initial loss: {mse_loss(model(x_train), y_train)}\")      for i in range(n_epochs):         optimizer.zero_grad()          loss = mse_loss(model(x_train), y_train)         loss.backward()         optimizer.step()          if (i + 1) % 10 == 0:             print(f\"Epoch {i+1} training - Loss: {loss.item()}\")      return model"},{"location":"api/constructor/","title":"Constructors","text":"<p>This module implements the constructor class.</p>"},{"location":"api/constructor/#qadence_model.models.qnn_constructors.build_qnn_from_configs","title":"<code>build_qnn_from_configs(register, observable_config, fm_config=FeatureMapConfig(), ansatz_config=AnsatzConfig(), backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, measurement=None, noise=None, configuration=None, input_diff_mode=InputDiffMode.AD)</code>","text":"<p>Build a QNN model.</p> PARAMETER DESCRIPTION <code>register</code> <p>Number of qubits or a register object.</p> <p> TYPE: <code>int | Register</code> </p> <code>observable_config</code> <p>Observable configuration(s).</p> <p> TYPE: <code>ObservableConfig | list[ObservableConfig]</code> </p> <code>fm_config</code> <p>Feature map configuration.</p> <p> TYPE: <code>FeatureMapConfig</code> DEFAULT: <code>FeatureMapConfig()</code> </p> <code>ansatz_config</code> <p>Ansatz configuration.</p> <p> TYPE: <code>AnsatzConfig</code> DEFAULT: <code>AnsatzConfig()</code> </p> <code>backend</code> <p>The chosen quantum backend.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>The differentiation engine to use. Choices are 'gpsr' or 'ad'.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>Optional backend configuration.</p> <p> TYPE: <code>BackendConfiguration | dict</code> DEFAULT: <code>None</code> </p> <code>input_diff_mode</code> <p>The differentiation mode for the input tensor.</p> <p> TYPE: <code>InputDiffMode</code> DEFAULT: <code>AD</code> </p> RETURNS DESCRIPTION <code>QNN</code> <p>A QNN model.</p> <p> TYPE: <code>QNN</code> </p> Source code in <code>qadence_model/models/qnn_constructors.py</code> <pre><code>def build_qnn_from_configs(\n    register: int | Register,\n    observable_config: ObservableConfig | list[ObservableConfig],\n    fm_config: FeatureMapConfig = FeatureMapConfig(),\n    ansatz_config: AnsatzConfig = AnsatzConfig(),\n    backend: BackendName = BackendName.PYQTORCH,\n    diff_mode: DiffMode = DiffMode.AD,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    configuration: BackendConfiguration | dict | None = None,\n    input_diff_mode: InputDiffMode | str = InputDiffMode.AD,\n) -&gt; QNN:\n    \"\"\"\n    Build a QNN model.\n\n    Args:\n        register (int | Register): Number of qubits or a register object.\n        observable_config (ObservableConfig | list[ObservableConfig]): Observable configuration(s).\n        fm_config (FeatureMapConfig): Feature map configuration.\n        ansatz_config (AnsatzConfig): Ansatz configuration.\n        backend (BackendName): The chosen quantum backend.\n        diff_mode (DiffMode): The differentiation engine to use. Choices are\n            'gpsr' or 'ad'.\n        measurement (Measurements): Optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator.\n        noise (Noise): A noise model to use.\n        configuration (BackendConfiguration | dict): Optional backend configuration.\n        input_diff_mode (InputDiffMode): The differentiation mode for the input tensor.\n\n    Returns:\n        QNN: A QNN model.\n    \"\"\"\n    blocks: list[AbstractBlock] = []\n    inputs: list[Basic | str] | None = None\n\n    if fm_config.num_features &gt; 0:\n        fm_blocks = create_fm_blocks(register=register, config=fm_config)\n        full_fm = _interleave_ansatz_in_fm(\n            register=register,\n            fm_blocks=fm_blocks,\n            ansatz_config=ansatz_config,\n        )\n        if isinstance(fm_config.tag, str):\n            tag(full_fm, fm_config.tag)\n        inputs = fm_config.inputs\n        blocks.append(full_fm)\n\n    ansatz = create_ansatz(register=register, config=ansatz_config)\n    if isinstance(ansatz_config.tag, str):\n        tag(ansatz, ansatz_config.tag)\n    blocks.append(ansatz)\n\n    circ = QuantumCircuit(register, *blocks)\n\n    observable: AbstractBlock | list[AbstractBlock] = (\n        [create_observable(register=register, config=cfg) for cfg in observable_config]\n        if isinstance(observable_config, list)\n        else create_observable(register=register, config=observable_config)\n    )\n\n    ufa = QNN(\n        circ,\n        observable,\n        inputs=inputs,\n        backend=backend,\n        diff_mode=diff_mode,\n        measurement=measurement,\n        noise=noise,\n        configuration=configuration,\n        input_diff_mode=input_diff_mode,\n    )\n\n    return ufa\n</code></pre>"},{"location":"api/constructor/#qadence_model.models.qnn_constructors.create_ansatz","title":"<code>create_ansatz(register, config)</code>","text":"<p>Create the ansatz based on the configuration.</p> PARAMETER DESCRIPTION <code>register</code> <p>Number of qubits or a register object.</p> <p> TYPE: <code>int | Register</code> </p> <code>config</code> <p>Configuration for the ansatz.</p> <p> TYPE: <code>AnsatzConfig</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>The ansatz block.</p> <p> TYPE: <code>AbstractBlock</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>If the ansatz type is not implemented.</p> Source code in <code>qadence_model/models/qnn_constructors.py</code> <pre><code>def create_ansatz(\n    register: int | Register,\n    config: AnsatzConfig,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Create the ansatz based on the configuration.\n\n    Args:\n        register (int | Register): Number of qubits or a register object.\n        config (AnsatzConfig): Configuration for the ansatz.\n\n    Returns:\n        AbstractBlock: The ansatz block.\n\n    Raises:\n        NotImplementedError: If the ansatz type is not implemented.\n    \"\"\"\n    num_qubits = register if isinstance(register, int) else register.n_qubits\n\n    if config.ansatz_type == AnsatzType.IIA:\n        return _create_iia(num_qubits=num_qubits, config=config)\n    elif config.ansatz_type == AnsatzType.HEA:\n        return _create_hea(register=register, config=config)\n    elif config.ansatz_type == AnsatzType.ALA:\n        return _create_ala(num_qubits=num_qubits, config=config)\n    else:\n        raise NotImplementedError(\n            f\"Ansatz of type {config.ansatz_type} not implemented yet. Only `AnsatzType.HEA` and\\\n                `AnsatzType.IIA` available.\"\n        )\n</code></pre>"},{"location":"api/constructor/#qadence_model.models.qnn_constructors.create_fm_blocks","title":"<code>create_fm_blocks(register, config)</code>","text":"<p>Create a list of feature map blocks based on the given configuration.</p> <p>In case of series encoding or even parallel encoding with data reuploads, the outputs is a list of blocks that still need to be interleaved with non commuting blocks.</p> PARAMETER DESCRIPTION <code>register</code> <p>The number of qubits or the register.</p> <p> TYPE: <code>int | Register</code> </p> <code>config</code> <p>The configuration for the feature map.</p> <p> TYPE: <code>FeatureMapConfig</code> </p> RETURNS DESCRIPTION <code>list[AbstractBlock]</code> <p>list[AbstractBlock]: A list of feature map blocks.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the feature map strategy is not <code>Strategy.DIGITAL</code>, <code>Strategy.ANALOG</code> or <code>Strategy.RYDBERG</code>.</p> Source code in <code>qadence_model/models/qnn_constructors.py</code> <pre><code>def create_fm_blocks(\n    register: int | Register,\n    config: FeatureMapConfig,\n) -&gt; list[AbstractBlock]:\n    \"\"\"\n    Create a list of feature map blocks based on the given configuration.\n\n    In case of series encoding or even parallel encoding with data reuploads,\n    the outputs is a list of blocks that still need to be interleaved with non\n    commuting blocks.\n\n    Args:\n        register (int | Register): The number of qubits or the register.\n        config (FeatureMapConfig): The configuration for the feature map.\n\n    Returns:\n        list[AbstractBlock]: A list of feature map blocks.\n\n    Raises:\n        ValueError: If the feature map strategy is not `Strategy.DIGITAL`, `Strategy.ANALOG` or\n            `Strategy.RYDBERG`.\n    \"\"\"\n    if config.feature_map_strategy == Strategy.DIGITAL:\n        return _create_digital_fm(register=register, config=config)\n    elif config.feature_map_strategy == Strategy.ANALOG:\n        return _create_analog_fm(register=register, config=config)\n    elif config.feature_map_strategy == Strategy.RYDBERG:\n        return _create_rydberg_fm(register=register, config=config)\n    else:\n        raise NotImplementedError(\n            f\"Feature map not implemented for strategy {config.feature_map_strategy}. \\\n            Only `Strategy.DIGITAL`, `Strategy.ANALOG` or `Strategy.RYDBERG` allowed.\"\n        )\n</code></pre>"},{"location":"api/constructor/#qadence_model.models.qnn_constructors.create_observable","title":"<code>create_observable(register, config)</code>","text":"<p>Create an observable block.</p> PARAMETER DESCRIPTION <code>register</code> <p>Number of qubits or a register object.</p> <p> TYPE: <code>int | Register</code> </p> <code>config</code> <p>Observable configuration.</p> <p> TYPE: <code>ObservableConfig</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>The observable block.</p> <p> TYPE: <code>AbstractBlock</code> </p> Source code in <code>qadence_model/models/qnn_constructors.py</code> <pre><code>def create_observable(\n    register: int | Register,\n    config: ObservableConfig,\n) -&gt; AbstractBlock:\n    \"\"\"\n    Create an observable block.\n\n    Args:\n        register (int | Register): Number of qubits or a register object.\n        config (ObservableConfig): Observable configuration.\n\n    Returns:\n        AbstractBlock: The observable block.\n    \"\"\"\n    shifting_term: AbstractBlock = config.shift * _global_identity(register)  # type: ignore[operator]\n    detuning_hamiltonian: AbstractBlock = config.scale * hamiltonian_factory(  # type: ignore[operator]\n        register=register,\n        interaction=config.interaction,\n        detuning=config.detuning,\n    )\n    obs: AbstractBlock = add(shifting_term, detuning_hamiltonian)\n\n    if isinstance(config.tag, str):\n        tag(obs, config.tag)\n\n    return obs\n</code></pre>"},{"location":"api/parameter/","title":"Parameters","text":"<p>This module implements the parameter class.</p>"},{"location":"api/parameter/#qadence_model.models.parameters.get_parameters","title":"<code>get_parameters(model)</code>","text":"<p>Retrieve all trainable model parameters in a single vector.</p> PARAMETER DESCRIPTION <code>model</code> <p>the input PyTorch model</p> <p> TYPE: <code>Module</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>a 1-dimensional tensor with the parameters</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence_model/models/parameters.py</code> <pre><code>def get_parameters(model: Module) -&gt; Tensor:\n    \"\"\"Retrieve all trainable model parameters in a single vector.\n\n    Args:\n        model (Module): the input PyTorch model\n\n    Returns:\n        Tensor: a 1-dimensional tensor with the parameters\n    \"\"\"\n    ps = [p.reshape(-1) for p in model.parameters() if p.requires_grad]\n    return torch.concat(ps)\n</code></pre>"},{"location":"api/parameter/#qadence_model.models.parameters.num_parameters","title":"<code>num_parameters(model)</code>","text":"<p>Return the total number of parameters of the given model.</p> Source code in <code>qadence_model/models/parameters.py</code> <pre><code>def num_parameters(model: Module) -&gt; int:\n    \"\"\"Return the total number of parameters of the given model.\"\"\"\n    return len(get_parameters(model))\n</code></pre>"},{"location":"api/parameter/#qadence_model.models.parameters.set_parameters","title":"<code>set_parameters(model, theta)</code>","text":"<p>Set all trainable parameters of a model from a single vector.</p> <p>Notice that this function assumes prior knowledge of right number of parameters in the model</p> PARAMETER DESCRIPTION <code>model</code> <p>the input PyTorch model</p> <p> TYPE: <code>Module</code> </p> <code>theta</code> <p>the parameters to assign</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence_model/models/parameters.py</code> <pre><code>def set_parameters(model: Module, theta: Tensor) -&gt; None:\n    \"\"\"Set all trainable parameters of a model from a single vector.\n\n    Notice that this function assumes prior knowledge of right number\n    of parameters in the model\n\n    Args:\n        model (Module): the input PyTorch model\n        theta (Tensor): the parameters to assign\n    \"\"\"\n\n    with torch.no_grad():\n        idx = 0\n        for ps in model.parameters():\n            if ps.requires_grad:\n                n = torch.numel(ps)\n                if ps.ndim == 0:\n                    ps[()] = theta[idx : idx + n]\n                else:\n                    ps[:] = theta[idx : idx + n].reshape(ps.size())\n                idx += n\n</code></pre>"},{"location":"api/qcnn_model/","title":"QCNN Model","text":"<p>This module implements the <code>QCNN</code> class.</p>"},{"location":"api/qcnn_model/#qadence_model.models.qcnn_model.QCNN","title":"<code>QCNN(n_inputs, n_qubits, depth, operations, entangler=CZ, random_meas=True, fm_basis='Fourier', fm_gate=RX, is_corr=False, **kwargs)</code>","text":"<p>               Bases: <code>QNN</code></p> <p>Creates a QCNN model.</p> PARAMETER DESCRIPTION <code>n_inputs</code> <p>Number of input features.</p> <p> TYPE: <code>int</code> </p> <code>n_qubits</code> <p>Total number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>List defining the depth (repetitions) of each layer.</p> <p> TYPE: <code>list[int]</code> </p> <code>operations</code> <p>List of quantum operations to apply in the gates (e.g., [RX, RZ]).</p> <p> TYPE: <code>list[Any]</code> </p> <code>entangler</code> <p>Entangling operation, such as CZ.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>CZ</code> </p> <code>random_meas</code> <p>If True, applies random weighted measurements.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>fm_basis</code> <p>feature map basis.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'Fourier'</code> </p> <code>fm_gate</code> <p>gate employed in the fm, such as.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>RX</code> </p> <code>**kwargs</code> <p>Additional keyword arguments for the parent QNN class.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>qadence_model/models/qcnn_model.py</code> <pre><code>def __init__(\n    self,\n    n_inputs: int,\n    n_qubits: int,\n    depth: list[int],\n    operations: list[Any],\n    entangler: Any = CZ,\n    random_meas: bool = True,\n    fm_basis: str = \"Fourier\",\n    fm_gate: Any = RX,\n    is_corr: bool = False,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"\n    Creates a QCNN model.\n\n    Args:\n        n_inputs (int): Number of input features.\n        n_qubits (int): Total number of qubits.\n        depth (list[int]): List defining the depth (repetitions) of each layer.\n        operations (list[Any]): List of quantum operations to apply\n            in the gates (e.g., [RX, RZ]).\n        entangler (Any): Entangling operation, such as CZ.\n        random_meas (bool): If True, applies random weighted measurements.\n        fm_basis (str): feature map basis.\n        fm_gate (Any): gate employed in the fm, such as.\n        **kwargs (Any): Additional keyword arguments for the parent QNN class.\n    \"\"\"\n    self.n_inputs = n_inputs\n    self.n_qubits = n_qubits\n    self.depth = depth\n    self.operations = operations\n    self.entangler = entangler\n    self.random_meas = random_meas\n    self.fm_basis = fm_basis\n    self.fm_gate = fm_gate\n    self.is_corr = is_corr\n\n    circuit = self.qcnn_circuit(\n        self.n_inputs,\n        self.n_qubits,\n        self.depth,\n        self.operations,\n        self.entangler,\n        self.fm_basis,\n        self.fm_gate,\n        self.is_corr,\n    )\n\n    obs = self.qcnn_deferred_obs(self.n_qubits, self.random_meas)\n\n    super().__init__(\n        circuit=circuit,\n        observable=obs,\n        backend=BackendName.PYQTORCH,\n        diff_mode=DiffMode.AD,\n        inputs=[f\"\\u03c6_{i}\" for i in range(self.n_inputs)],\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/qcnn_model/#qadence_model.models.qcnn_model.QCNN.qcnn_circuit","title":"<code>qcnn_circuit(n_inputs, n_qubits, depth, operations, entangler, fm_basis, fm_gate, is_corr)</code>","text":"<p>Defines the QCNN circuit.</p> Source code in <code>qadence_model/models/qcnn_model.py</code> <pre><code>def qcnn_circuit(\n    self,\n    n_inputs: int,\n    n_qubits: int,\n    depth: list[int],\n    operations: list[Any],\n    entangler: AbstractBlock,\n    fm_basis: str,\n    fm_gate: AbstractBlock,\n    is_corr: bool,\n) -&gt; QuantumCircuit:\n    \"\"\"Defines the QCNN circuit.\"\"\"\n    # Validate qubit count\n    if n_qubits &lt; 4:\n        raise ValueError(\n            f\"Invalid number of qubits: {n_qubits}. \" \"At least 4 qubits are required.\"\n        )\n    if n_qubits % 2 != 0:\n        raise ValueError(\n            f\"Invalid number of qubits: {n_qubits}. \" \"The number of qubits must be even.\"\n        )\n\n    # Validate that all values in `depth` are odd\n    even_depths = [d for d in depth if d % 2 == 0]\n    if even_depths:\n        raise ValueError(\n            f\"Invalid depth values: '{even_depths[0]}'. \" \"All the conv layer 'r's must be odd.\"\n        )\n\n    # Feature map (FM)\n    fm = _create_feature_map_qcnn(n_qubits, n_inputs, fm_basis, fm_gate)\n    tag(fm, \"FM\")\n\n    # Conv and Pool layer definition\n    conv_layers = []\n    params: dict[str, Parameter] = {}\n\n    # Define layer all the 2-qubit patterns based on depth\n    layer_patterns = [(2**layer_index, depth[layer_index]) for layer_index in range(len(depth))]\n\n    # Initialize all qubits for the current layer\n    current_indices = list(range(n_qubits))\n\n    # Build the circuit layer by layer using the helper\n    for layer_index, (_, reps) in enumerate(layer_patterns):\n        if reps == 0:\n            raise ValueError(f\"Invalid layer {layer_index}: zero repetitions (reps = {reps}).\")\n        if len(current_indices) &lt; 2:\n            raise RuntimeError(\n                f\"Layer {layer_index} requires at least 2 qubits, \"\n                f\"but found {len(current_indices)}.\"\n            )\n\n        layer_block, next_indices = _create_conv_layer(\n            layer_index, reps, current_indices, params, operations, entangler, n_qubits, is_corr\n        )\n        tag(layer_block, f\"C+P layer {layer_index}\")\n        conv_layers.append(layer_block)\n\n        # Update `current_indices` for the next layer\n        current_indices = next_indices\n\n    # Combine all layers for the final ansatz\n    ansatz = chain(*conv_layers)\n\n    return QuantumCircuit(n_qubits, fm, ansatz)\n</code></pre>"},{"location":"api/qcnn_model/#qadence_model.models.qcnn_model.QCNN.qcnn_deferred_obs","title":"<code>qcnn_deferred_obs(n_qubits, random_meas)</code>","text":"<p>Defines the measurements to be performedthe traced out.</p> <p>and remaining qubits.</p> Source code in <code>qadence_model/models/qcnn_model.py</code> <pre><code>def qcnn_deferred_obs(\n    self, n_qubits: int, random_meas: bool\n) -&gt; AbstractBlock | list[AbstractBlock]:\n    \"\"\"\n    Defines the measurements to be performedthe traced out.\n\n    and remaining qubits.\n    \"\"\"\n    if random_meas:\n        w1 = [Parameter(f\"w{i}\") for i in range(n_qubits)]\n        obs = add(Z(i) * w for i, w in zip(range(n_qubits), w1))\n    else:\n        obs = add(Z(i) for i in range(n_qubits))\n\n    return obs\n</code></pre>"},{"location":"api/qnn_config/","title":"QNN Config","text":"<p>This module implements the <code>QNN config</code> class.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.AnsatzConfig","title":"<code>AnsatzConfig(depth=1, ansatz_type=AnsatzType.HEA, ansatz_strategy=Strategy.DIGITAL, strategy_args=dict(), m_block_qubits=None, param_prefix='theta', tag=None)</code>  <code>dataclass</code>","text":""},{"location":"api/qnn_config/#qadence_model.models.qnn_config.AnsatzConfig.ansatz_strategy","title":"<code>ansatz_strategy = Strategy.DIGITAL</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Ansatz strategy.</p> <p><code>Strategy.DIGITAL</code> for fully digital ansatz. Required if <code>ansatz_type</code> is <code>AnsatzType.ALA</code>. <code>Strategy.SDAQC</code> for analog entangling block. Only available for <code>AnsatzType.HEA</code> or <code>AnsatzType.ALA</code>. <code>Strategy.RYDBERG</code> for fully rydberg hea ansatz. Only available for <code>AnsatzType.HEA</code>.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.AnsatzConfig.ansatz_type","title":"<code>ansatz_type = AnsatzType.HEA</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>What type of ansatz.</p> <p><code>AnsatzType.HEA</code> for Hardware Efficient Ansatz. <code>AnsatzType.IIA</code> for Identity Intialized Ansatz. <code>AnsatzType.ALA</code> for Alternating Layer Ansatz.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.AnsatzConfig.depth","title":"<code>depth = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of layers of the ansatz.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.AnsatzConfig.m_block_qubits","title":"<code>m_block_qubits = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The number of qubits in the local entangling block of an Alternating Layer Ansatz (ALA).</p> <p>Only used when <code>ansatz_type</code> is <code>AnsatzType.ALA</code>.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.AnsatzConfig.param_prefix","title":"<code>param_prefix = 'theta'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The base bame of the variational parameter.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.AnsatzConfig.strategy_args","title":"<code>strategy_args = field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A dictionary containing keyword arguments to the function creating the ansatz.</p> <p>Details about each below.</p> <p>For <code>Strategy.DIGITAL</code> strategy, accepts the following:     periodic (bool): if the qubits should be linked periodically.         periodic=False is not supported in emu-c.     operations (list): list of operations to cycle through in the         digital single-qubit rotations of each layer.         Defaults to  [RX, RY, RX] for hea and [RX, RY] for iia.     entangler (AbstractBlock): 2-qubit entangling operation.         Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE. Controlld rotations         will have variational parameters on the rotation angles.         Defaults to CNOT</p> <p>For <code>Strategy.SDAQC</code> strategy, accepts the following:     operations (list): list of operations to cycle through in the         digital single-qubit rotations of each layer.         Defaults to  [RX, RY, RX] for hea and [RX, RY] for iia.     entangler (AbstractBlock): Hamiltonian generator for the         analog entangling layer. Time parameter is considered variational.         Defaults to NN interaction.</p> <p>For <code>Strategy.RYDBERG</code> strategy, accepts the following:     addressable_detuning: whether to turn on the trainable semi-local addressing pattern         on the detuning (n_i terms in the Hamiltonian).         Defaults to True.     addressable_drive: whether to turn on the trainable semi-local addressing pattern         on the drive (sigma_i^x terms in the Hamiltonian).         Defaults to False.     tunable_phase: whether to have a tunable phase to get both sigma^x and sigma^y rotations         in the drive term. If False, only a sigma^x term will be included in the drive part         of the Hamiltonian generator.         Defaults to False.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.AnsatzConfig.tag","title":"<code>tag = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String to indicate the name tag of the ansatz.</p> <p>Defaults to None, in which case no tag will be applied.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.FeatureMapConfig","title":"<code>FeatureMapConfig(num_features=0, basis_set=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.CONSTANT, feature_range=None, target_range=None, multivariate_strategy=MultivariateStrategy.PARALLEL, feature_map_strategy=Strategy.DIGITAL, param_prefix=None, num_repeats=0, operation=None, inputs=None, tag=None)</code>  <code>dataclass</code>","text":""},{"location":"api/qnn_config/#qadence_model.models.qnn_config.FeatureMapConfig.basis_set","title":"<code>basis_set = BasisSet.FOURIER</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Basis set for feature encoding.</p> <p>Takes qadence.BasisSet. Give a single BasisSet to use the same for all features. Give a dict of (str, BasisSet) where the key is the name of the variable and the value is the BasisSet to use for encoding that feature. BasisSet.FOURIER for Fourier encoding. BasisSet.CHEBYSHEV for Chebyshev encoding.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.FeatureMapConfig.feature_map_strategy","title":"<code>feature_map_strategy = Strategy.DIGITAL</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Strategy for feature map.</p> <p>Accepts DIGITAL, ANALOG or RYDBERG. Defaults to DIGITAL. If the strategy is incompatible with the <code>operation</code> chosen, then <code>operation</code> gets preference and the given strategy is ignored.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.FeatureMapConfig.feature_range","title":"<code>feature_range = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Range of data that the input data is assumed to come from.</p> <p>Give a single tuple to use the same range for all features. Give a dict of (str, tuple) where the key is the name of the variable and the value is the feature range to use for that feature.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.FeatureMapConfig.inputs","title":"<code>inputs = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List that indicates the order of variables of the tensors that are passed.</p> <p>Optional if a single feature is being encoded, required otherwise. Given input tensors <code>xs = torch.rand(batch_size, input_size:=2)</code> a QNN with <code>inputs=[\"t\", \"x\"]</code> will assign <code>t, x = xs[:,0], xs[:,1]</code>.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.FeatureMapConfig.multivariate_strategy","title":"<code>multivariate_strategy = MultivariateStrategy.PARALLEL</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The encoding strategy in case of multi-variate function.</p> <p>Takes qadence.MultivariateStrategy. If PARALLEL, the features are encoded in one block of rotation gates with the register being split in sub-registers for each feature. If SERIES, the features are encoded sequentially using the full register for each feature, with an ansatz block between them. PARALLEL is allowed only for DIGITAL <code>feature_map_strategy</code>.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.FeatureMapConfig.num_features","title":"<code>num_features = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of feature parameters to be encoded.</p> <p>Defaults to 0. Thus, no feature parameters are encoded.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.FeatureMapConfig.num_repeats","title":"<code>num_repeats = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of feature map layers repeated in the data reuploading step.</p> <p>If all features are to be repeated the same number of times, then can give a single <code>int</code>. For different number of repetitions for each feature, provide a dict of (str, int) where the key is the name of the variable and the value is the number of repetitions for that feature. This amounts to the number of additional reuploads. So if <code>num_repeats</code> is N, the data gets uploaded N+1 times. Defaults to no repetition.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.FeatureMapConfig.operation","title":"<code>operation = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Type of operation.</p> <p>Choose among the analog or digital rotations or a custom callable function returning an AnalogBlock instance. If the type of operation is incompatible with the <code>strategy</code> chosen, then <code>operation</code> gets preference and the given strategy is ignored.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.FeatureMapConfig.param_prefix","title":"<code>param_prefix = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String prefix to create trainable parameters in Feature Map.</p> <p>A string prefix to create trainable parameters multiplying the feature parameter inside the feature-encoding function. Note that currently this does not take into account the domain of the feature-encoding function. Defaults to <code>None</code> and thus, the feature map is not trainable. Note that this is separate from the name of the parameter. The user can provide a single prefix for all features, and it will be appended by appropriate feature name automatically.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.FeatureMapConfig.reupload_scaling","title":"<code>reupload_scaling = ReuploadScaling.CONSTANT</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Scaling for encoding the same feature on different qubits.</p> <p>Scaling used to encode the same feature on different qubits in the same layer of the feature maps. Takes qadence.ReuploadScaling. Give a single ReuploadScaling to use the same for all features. Give a dict of (str, ReuploadScaling) where the key is the name of the variable and the value is the ReuploadScaling to use for encoding that feature. ReuploadScaling.CONSTANT for constant scaling. ReuploadScaling.TOWER for linearly increasing scaling. ReuploadScaling.EXP for exponentially increasing scaling.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.FeatureMapConfig.tag","title":"<code>tag = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String to indicate the name tag of the feature map.</p> <p>Defaults to None, in which case no tag will be applied.</p>"},{"location":"api/qnn_config/#qadence_model.models.qnn_config.FeatureMapConfig.target_range","title":"<code>target_range = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Range of data the data encoder assumes as natural range.</p> <p>Give a single tuple to use the same range for all features. Give a dict of (str, tuple) where the key is the name of the variable and the value is the target range to use for that feature.</p>"},{"location":"api/qnn_model/","title":"QNN Model","text":"<p>This module implements the QNN models.</p>"},{"location":"api/qnn_model/#qadence_model.models.qnn_model.QNN","title":"<code>QNN(circuit, observable, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, measurement=None, noise=None, configuration=None, inputs=None, input_diff_mode=InputDiffMode.AD)</code>","text":"<p>               Bases: <code>QuantumModel</code></p> <p>Quantum neural network model for n-dimensional inputs.</p> <p>Examples: <pre><code>import torch\nfrom qadence import QuantumCircuit, QNN, Z\nfrom qadence import hea, feature_map, hamiltonian_factory, kron\n\n# create the circuit\nn_qubits, depth = 2, 4\nfm = kron(\n    feature_map(1, support=(0,), param=\"x\"),\n    feature_map(1, support=(1,), param=\"y\")\n)\nansatz = hea(n_qubits=n_qubits, depth=depth)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nobs_base = hamiltonian_factory(n_qubits, detuning=Z)\n\n# the QNN will yield two outputs\nobs = [2.0 * obs_base, 4.0 * obs_base]\n\n# initialize and use the model\nqnn = QNN(circuit, obs, inputs=[\"x\", \"y\"])\ny = qnn(torch.rand(3, 2))\n</code></pre> <pre><code>tensor([[-0.4382, -0.8764],\n        [-0.0576, -0.1152],\n        [ 0.1768,  0.3535]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> </p> <p>Initialize the QNN.</p> <p>The number of inputs is determined by the feature parameters in the input quantum circuit while the number of outputs is determined by how many observables are provided as input</p> PARAMETER DESCRIPTION <code>circuit</code> <p>The quantum circuit to use for the QNN.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>observable</code> <p>The observable.</p> <p> TYPE: <code>list[AbstractBlock] | AbstractBlock</code> </p> <code>backend</code> <p>The chosen quantum backend.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>The differentiation engine to use. Choices 'gpsr' or 'ad'.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>measurement</code> <p>optional measurement protocol. If None, use exact expectation value with a statevector simulator</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>optional configuration for the backend</p> <p> TYPE: <code>BackendConfiguration | dict | None</code> DEFAULT: <code>None</code> </p> <code>inputs</code> <p>List that indicates the order of variables of the tensors that are passed to the model. Given input tensors <code>xs = torch.rand(batch_size, input_size:=2)</code> a QNN with <code>inputs=[\"t\", \"x\"]</code> will assign <code>t, x = xs[:,0], xs[:,1]</code>.</p> <p> TYPE: <code>list[Basic | str] | None</code> DEFAULT: <code>None</code> </p> <code>input_diff_mode</code> <p>The differentiation mode for the input tensor.</p> <p> TYPE: <code>InputDiffMode | str</code> DEFAULT: <code>AD</code> </p> Source code in <code>qadence_model/models/qnn_model.py</code> <pre><code>def __init__(\n    self,\n    circuit: QuantumCircuit,\n    observable: list[AbstractBlock] | AbstractBlock,\n    backend: BackendName = BackendName.PYQTORCH,\n    diff_mode: DiffMode = DiffMode.AD,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    configuration: BackendConfiguration | dict | None = None,\n    inputs: list[sympy.Basic | str] | None = None,\n    input_diff_mode: InputDiffMode | str = InputDiffMode.AD,\n):\n    \"\"\"Initialize the QNN.\n\n    The number of inputs is determined by the feature parameters in the input\n    quantum circuit while the number of outputs is determined by how many\n    observables are provided as input\n\n    Args:\n        circuit: The quantum circuit to use for the QNN.\n        observable: The observable.\n        backend: The chosen quantum backend.\n        diff_mode: The differentiation engine to use. Choices 'gpsr' or 'ad'.\n        measurement: optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator\n        noise: A noise model to use.\n        configuration: optional configuration for the backend\n        inputs: List that indicates the order of variables of the tensors that are passed\n            to the model. Given input tensors `xs = torch.rand(batch_size, input_size:=2)` a QNN\n            with `inputs=[\"t\", \"x\"]` will assign `t, x = xs[:,0], xs[:,1]`.\n        input_diff_mode: The differentiation mode for the input tensor.\n    \"\"\"\n    super().__init__(\n        circuit,\n        observable=observable,\n        backend=backend,\n        diff_mode=diff_mode,\n        measurement=measurement,\n        configuration=configuration,\n        noise=noise,\n    )\n    if self._observable is None:\n        raise ValueError(\"You need to provide at least one observable in the QNN constructor\")\n    if (inputs is not None) and (len(self.inputs) == len(inputs)):\n        self.inputs = [sympy.symbols(x) if isinstance(x, str) else x for x in inputs]  # type: ignore[union-attr]\n    elif (inputs is None) and len(self.inputs) &lt;= 1:\n        self.inputs = [sympy.symbols(x) if isinstance(x, str) else x for x in self.inputs]  # type: ignore[union-attr]\n    else:\n        raise ValueError(\n            \"\"\"\n            Your QNN has more than one input. Please provide a list of inputs in the order of\n            your tensor domain. For example, if you want to pass\n            `xs = torch.rand(batch_size, input_size:=3)` to you QNN, where\n            ```\n            t = x[:,0]\n            x = x[:,1]\n            y = x[:,2]\n            ```\n            you have to specify\n            ```\n            QNN(circuit, observable, inputs=[\"t\", \"x\", \"y\"])\n            ```\n            You can also pass a list of sympy symbols.\n        \"\"\"\n        )\n    self.format_to_dict = format_to_dict_fn(self.inputs)  # type: ignore[arg-type]\n    self.input_diff_mode = InputDiffMode(input_diff_mode)\n    if self.input_diff_mode == InputDiffMode.FD:\n        from qadence.backends.utils import finitediff\n\n        self.__derivative = finitediff\n    elif self.input_diff_mode == InputDiffMode.AD:\n        self.__derivative = _torch_derivative  # type: ignore[assignment]\n    else:\n        raise ValueError(f\"Unkown forward diff mode: {self.input_diff_mode}\")\n\n    self._model_configs: dict = dict()\n</code></pre>"},{"location":"api/qnn_model/#qadence_model.models.qnn_model.QNN.__str__","title":"<code>__str__()</code>","text":"<p>Return a string representation of a QNN.</p> <p>When creating a QNN from a set of configurations, we print the configurations used. Otherwise, we use the default printing.</p> RETURNS DESCRIPTION <code>str | Any</code> <p>str | Any: A string representation of a QNN.</p> <p>Example: <pre><code>from qadence import QNN\nfrom qadence.constructors.hamiltonians import Interaction\nfrom qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\nfrom qadence.ml_tools.constructors import (\n    ObservableConfig,\n)\nfrom qadence.operations import Z\nfrom qadence.types import BackendName\n\nbackend = BackendName.PYQTORCH\nfm_config = FeatureMapConfig(num_features=1)\nansatz_config = AnsatzConfig()\nobservable_config = ObservableConfig(detuning=Z, interaction=Interaction.ZZ, scale=2)\n\nqnn = QNN.from_configs(\n    register=2,\n    obs_config=observable_config,\n    fm_config=fm_config,\n    ansatz_config=ansatz_config,\n    backend=backend,\n)\n</code></pre> <pre><code>QNN(\nansatz_config = AnsatzConfig(depth=1, ansatz_type=&lt;AnsatzType.HEA: 'hea'&gt;, ansatz_strategy=&lt;Strategy.DIGITAL: 'Digital'&gt;, strategy_args={}, m_block_qubits=None, param_prefix='theta', tag=None)\nfm_config = FeatureMapConfig(num_features=1, basis_set={'x': &lt;BasisSet.FOURIER: 'Fourier'&gt;}, reupload_scaling={'x': &lt;ReuploadScaling.CONSTANT: 'Constant'&gt;}, feature_range={'x': None}, target_range={'x': None}, multivariate_strategy=&lt;MultivariateStrategy.PARALLEL: 'Parallel'&gt;, feature_map_strategy=&lt;Strategy.DIGITAL: 'Digital'&gt;, param_prefix=None, num_repeats={'x': 0}, operation=&lt;class 'qadence.operations.parametric.RX'&gt;, inputs=['x'], tag=None)\nregister = 2\nobservable_config = {'Obs.': '(2 * (Z(0) + Z(1) + (Z(0) \u2297 Z(1))))'}\n)\n</code></pre> </p> Source code in <code>qadence_model/models/qnn_model.py</code> <pre><code>def __str__(self) -&gt; str | Any:\n    \"\"\"Return a string representation of a QNN.\n\n    When creating a QNN from a set of configurations,\n    we print the configurations used. Otherwise, we use the default printing.\n\n    Returns:\n        str | Any: A string representation of a QNN.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import QNN\n    from qadence.constructors.hamiltonians import Interaction\n    from qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\n    from qadence.ml_tools.constructors import (\n        ObservableConfig,\n    )\n    from qadence.operations import Z\n    from qadence.types import BackendName\n\n    backend = BackendName.PYQTORCH\n    fm_config = FeatureMapConfig(num_features=1)\n    ansatz_config = AnsatzConfig()\n    observable_config = ObservableConfig(detuning=Z, interaction=Interaction.ZZ, scale=2)\n\n    qnn = QNN.from_configs(\n        register=2,\n        obs_config=observable_config,\n        fm_config=fm_config,\n        ansatz_config=ansatz_config,\n        backend=backend,\n    )\n    print(qnn) # markdown-exec: hide\n    ```\n    \"\"\"\n    if bool(self._model_configs):\n        configs_str = \"\\n\".join(\n            (\n                k + \" = \" + str(self._model_configs[k])\n                for k in sorted(self._model_configs.keys())\n                if k != \"observable_config\"\n            )\n        )\n        observable_str = \"\"\n        if self._observable:\n            observable_str = f\"observable_config = {self.observables_to_expression()}\"\n\n        return f\"{type(self).__name__}(\\n{configs_str}\\n{observable_str}\\n)\"\n\n    return super().__str__()\n</code></pre>"},{"location":"api/qnn_model/#qadence_model.models.qnn_model.QNN.forward","title":"<code>forward(values=None, state=None, measurement=None, noise=None, endianness=Endianness.BIG)</code>","text":"<p>Forward pass of the model.</p> <p>This returns the (differentiable) expectation value of the given observable operator defined in the constructor. Differently from the base QuantumModel class, the QNN accepts also a tensor as input for the forward pass. The tensor is expected to have shape: <code>n_batches x in_features</code> where <code>n_batches</code> is the number of data points and <code>in_features</code> is the dimensionality of the problem</p> <p>The output of the forward pass is the expectation value of the input observable(s). If a single observable is given, the output shape is <code>n_batches</code> while if multiple observables are given the output shape is instead <code>n_batches x n_observables</code></p> PARAMETER DESCRIPTION <code>values</code> <p>the values of the feature parameters</p> <p> TYPE: <code>dict[str, Tensor] | Tensor</code> DEFAULT: <code>None</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>measurement</code> <p>optional measurement protocol. If None, use exact expectation value with a statevector simulator</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>NoiseHandler | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bit strings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>a tensor with the expectation value of the observables passed in the constructor of the model</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence_model/models/qnn_model.py</code> <pre><code>def forward(\n    self,\n    values: dict[str, Tensor] | Tensor = None,\n    state: Tensor | None = None,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    endianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n    \"\"\"Forward pass of the model.\n\n    This returns the (differentiable) expectation value of the given observable\n    operator defined in the constructor. Differently from the base QuantumModel\n    class, the QNN accepts also a tensor as input for the forward pass. The\n    tensor is expected to have shape: `n_batches x in_features` where `n_batches`\n    is the number of data points and `in_features` is the dimensionality of the problem\n\n    The output of the forward pass is the expectation value of the input\n    observable(s). If a single observable is given, the output shape is\n    `n_batches` while if multiple observables are given the output shape\n    is instead `n_batches x n_observables`\n\n    Args:\n        values: the values of the feature parameters\n        state: Initial state.\n        measurement: optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator\n        noise: A noise model to use.\n        endianness: Endianness of the resulting bit strings.\n\n    Returns:\n        Tensor: a tensor with the expectation value of the observables passed\n            in the constructor of the model\n    \"\"\"\n    return self.expectation(\n        values, state=state, measurement=measurement, noise=noise, endianness=endianness\n    )\n</code></pre>"},{"location":"api/qnn_model/#qadence_model.models.qnn_model.QNN.from_configs","title":"<code>from_configs(register, obs_config, fm_config=FeatureMapConfig(), ansatz_config=AnsatzConfig(), backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, measurement=None, noise=None, configuration=None, input_diff_mode=InputDiffMode.AD)</code>  <code>classmethod</code>","text":"<p>Create a QNN from a set of configurations.</p> PARAMETER DESCRIPTION <code>register</code> <p>The number of qubits or a register object.</p> <p> TYPE: <code>int | Register</code> </p> <code>obs_config</code> <p>The configuration(s) for the observable(s).</p> <p> TYPE: <code>list[ObservableConfig] | ObservableConfig</code> </p> <code>fm_config</code> <p>The configuration for the feature map. Defaults to no feature encoding block.</p> <p> TYPE: <code>FeatureMapConfig</code> DEFAULT: <code>FeatureMapConfig()</code> </p> <code>ansatz_config</code> <p>The configuration for the ansatz. Defaults to a single layer of hardware efficient ansatz.</p> <p> TYPE: <code>AnsatzConfig</code> DEFAULT: <code>AnsatzConfig()</code> </p> <code>backend</code> <p>The chosen quantum backend.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>The differentiation engine to use. Choices are 'gpsr' or 'ad'.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>measurement</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements</code> DEFAULT: <code>None</code> </p> <code>noise</code> <p>A noise model to use.</p> <p> TYPE: <code>Noise</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>Optional backend configuration.</p> <p> TYPE: <code>BackendConfiguration | dict</code> DEFAULT: <code>None</code> </p> <code>input_diff_mode</code> <p>The differentiation mode for the input tensor.</p> <p> TYPE: <code>InputDiffMode</code> DEFAULT: <code>AD</code> </p> RETURNS DESCRIPTION <code>QNN</code> <p>A QNN object.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the observable configuration is not provided.</p> <p>Example: <pre><code>import torch\nfrom qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\nfrom qadence.ml_tools import QNN\nfrom qadence.constructors import ObservableConfig\nfrom qadence.operations import Z\nfrom qadence.types import (\n    AnsatzType, BackendName, BasisSet, ReuploadScaling, Strategy\n)\n\nregister = 4\nobs_config = ObservableConfig(\n    detuning=Z,\n    scale=5.0,\n    shift=0.0,\n    trainable_transform=None,\n)\nfm_config = FeatureMapConfig(\n    num_features=2,\n    inputs=[\"x\", \"y\"],\n    basis_set=BasisSet.FOURIER,\n    reupload_scaling=ReuploadScaling.CONSTANT,\n    feature_range={\n        \"x\": (-1.0, 1.0),\n        \"y\": (0.0, 1.0),\n    },\n)\nansatz_config = AnsatzConfig(\n    depth=2,\n    ansatz_type=AnsatzType.HEA,\n    ansatz_strategy=Strategy.DIGITAL,\n)\n\nqnn = QNN.from_configs(\n    register, obs_config, fm_config, ansatz_config, backend=BackendName.PYQTORCH\n)\n\nx = torch.rand(2, 2)\ny = qnn(x)\n</code></pre> <pre><code>tensor([[-0.7876],\n        [-0.4665]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> </p> Source code in <code>qadence_model/models/qnn_model.py</code> <pre><code>@classmethod\ndef from_configs(\n    cls,\n    register: int | Register,\n    obs_config: Any,\n    fm_config: Any = FeatureMapConfig(),\n    ansatz_config: Any = AnsatzConfig(),\n    backend: BackendName = BackendName.PYQTORCH,\n    diff_mode: DiffMode = DiffMode.AD,\n    measurement: Measurements | None = None,\n    noise: NoiseHandler | None = None,\n    configuration: BackendConfiguration | dict | None = None,\n    input_diff_mode: InputDiffMode | str = InputDiffMode.AD,\n) -&gt; QNN:\n    \"\"\"Create a QNN from a set of configurations.\n\n    Args:\n        register (int | Register): The number of qubits or a register object.\n        obs_config (list[ObservableConfig] | ObservableConfig): The configuration(s)\n            for the observable(s).\n        fm_config (FeatureMapConfig): The configuration for the feature map.\n            Defaults to no feature encoding block.\n        ansatz_config (AnsatzConfig): The configuration for the ansatz.\n            Defaults to a single layer of hardware efficient ansatz.\n        backend (BackendName): The chosen quantum backend.\n        diff_mode (DiffMode): The differentiation engine to use. Choices are\n            'gpsr' or 'ad'.\n        measurement (Measurements): Optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator.\n        noise (Noise): A noise model to use.\n        configuration (BackendConfiguration | dict): Optional backend configuration.\n        input_diff_mode (InputDiffMode): The differentiation mode for the input tensor.\n\n    Returns:\n        A QNN object.\n\n    Raises:\n        ValueError: If the observable configuration is not provided.\n\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence.ml_tools.config import AnsatzConfig, FeatureMapConfig\n    from qadence.ml_tools import QNN\n    from qadence.constructors import ObservableConfig\n    from qadence.operations import Z\n    from qadence.types import (\n        AnsatzType, BackendName, BasisSet, ReuploadScaling, Strategy\n    )\n\n    register = 4\n    obs_config = ObservableConfig(\n        detuning=Z,\n        scale=5.0,\n        shift=0.0,\n        trainable_transform=None,\n    )\n    fm_config = FeatureMapConfig(\n        num_features=2,\n        inputs=[\"x\", \"y\"],\n        basis_set=BasisSet.FOURIER,\n        reupload_scaling=ReuploadScaling.CONSTANT,\n        feature_range={\n            \"x\": (-1.0, 1.0),\n            \"y\": (0.0, 1.0),\n        },\n    )\n    ansatz_config = AnsatzConfig(\n        depth=2,\n        ansatz_type=AnsatzType.HEA,\n        ansatz_strategy=Strategy.DIGITAL,\n    )\n\n    qnn = QNN.from_configs(\n        register, obs_config, fm_config, ansatz_config, backend=BackendName.PYQTORCH\n    )\n\n    x = torch.rand(2, 2)\n    y = qnn(x)\n    print(str(y)) # markdown-exec: hide\n    ```\n    \"\"\"\n    from .qnn_constructors import build_qnn_from_configs\n\n    qnn = build_qnn_from_configs(\n        register=register,\n        observable_config=obs_config,\n        fm_config=fm_config,\n        ansatz_config=ansatz_config,\n        backend=backend,\n        diff_mode=diff_mode,\n        measurement=measurement,\n        noise=noise,\n        configuration=configuration,\n        input_diff_mode=input_diff_mode,\n    )\n    qnn._model_configs = {\n        \"register\": register,\n        \"observable_config\": obs_config,\n        \"fm_config\": fm_config,\n        \"ansatz_config\": ansatz_config,\n    }\n    return qnn\n</code></pre>"},{"location":"api/qnn_model/#qadence_model.models.qnn_model.derivative","title":"<code>derivative(ufa, x, derivative_indices)</code>","text":"<p>Compute derivatives w.r.t.</p> <p>inputs of a UFA with a single output. The <code>derivative_indices</code> specify which derivative(s) are computed.  E.g. <code>derivative_indices=(1,2)</code> would compute the a second order derivative w.r.t to the indices <code>1</code> and <code>2</code> of the input tensor.</p> PARAMETER DESCRIPTION <code>ufa</code> <p>The model for which we want to compute the derivative.</p> <p> TYPE: <code>Module</code> </p> <code>x</code> <p>(batch_size, input_size) input tensor.</p> <p> TYPE: <code>Tensor</code> </p> <code>derivative_indices</code> <p>Define which derivatives to compute.</p> <p> TYPE: <code>tuple</code> </p> <p>Examples: If we create a UFA with three inputs and denote the first, second, and third input with <code>x</code>, <code>y</code>, and <code>z</code> we can compute the following derivatives w.r.t to those inputs: <pre><code>import torch\nfrom qadence.ml_tools.models import derivative, QNN\nfrom qadence.ml_tools.config import FeatureMapConfig, AnsatzConfig\nfrom qadence.constructors.hamiltonians import ObservableConfig\nfrom qadence.operations import Z\n\nfm_config = FeatureMapConfig(num_features=3, inputs=[\"x\", \"y\", \"z\"])\nansatz_config = AnsatzConfig()\nobs_config = ObservableConfig(detuning=Z)\n\nf = QNN.from_configs(\n    register=3, obs_config=obs_config, fm_config=fm_config, ansatz_config=ansatz_config,\n)\ninputs = torch.rand(5,3,requires_grad=True)\n\n# df_dx\nderivative(f, inputs, (0,))\n\n# d2f_dydz\nderivative(f, inputs, (1,2))\n\n# d3fdy2dx\nderivative(f, inputs, (1,1,0))\n</code></pre> </p> Source code in <code>qadence_model/models/qnn_model.py</code> <pre><code>def derivative(ufa: torch.nn.Module, x: Tensor, derivative_indices: tuple[int, ...]) -&gt; Tensor:\n    \"\"\"Compute derivatives w.r.t.\n\n    inputs of a UFA with a single output. The\n    `derivative_indices` specify which derivative(s) are computed.  E.g.\n    `derivative_indices=(1,2)` would compute the a second order derivative w.r.t\n    to the indices `1` and `2` of the input tensor.\n\n    Arguments:\n        ufa: The model for which we want to compute the derivative.\n        x (Tensor): (batch_size, input_size) input tensor.\n        derivative_indices (tuple): Define which derivatives to compute.\n\n    Examples:\n    If we create a UFA with three inputs and denote the first, second, and third\n    input with `x`, `y`, and `z` we can compute the following derivatives w.r.t\n    to those inputs:\n    ```py exec=\"on\" source=\"material-block\"\n    import torch\n    from qadence.ml_tools.models import derivative, QNN\n    from qadence.ml_tools.config import FeatureMapConfig, AnsatzConfig\n    from qadence.constructors.hamiltonians import ObservableConfig\n    from qadence.operations import Z\n\n    fm_config = FeatureMapConfig(num_features=3, inputs=[\"x\", \"y\", \"z\"])\n    ansatz_config = AnsatzConfig()\n    obs_config = ObservableConfig(detuning=Z)\n\n    f = QNN.from_configs(\n        register=3, obs_config=obs_config, fm_config=fm_config, ansatz_config=ansatz_config,\n    )\n    inputs = torch.rand(5,3,requires_grad=True)\n\n    # df_dx\n    derivative(f, inputs, (0,))\n\n    # d2f_dydz\n    derivative(f, inputs, (1,2))\n\n    # d3fdy2dx\n    derivative(f, inputs, (1,1,0))\n    ```\n    \"\"\"\n    assert ufa.out_features == 1, \"Can only call `derivative` on models with 1D output.\"\n    return ufa._derivative(x, derivative_indices)\n</code></pre>"},{"location":"api/qnn_model/#qadence_model.models.qnn_model.format_to_dict_fn","title":"<code>format_to_dict_fn(inputs=[])</code>","text":"<p>Format an input tensor into the format required by the forward pass.</p> <p>The tensor is assumed to have dimensions: n_batches x in_features where in_features corresponds to the number of input features of the QNN</p> Source code in <code>qadence_model/models/qnn_model.py</code> <pre><code>def format_to_dict_fn(\n    inputs: list[sympy.Symbol | str] = [],\n) -&gt; Callable[[Tensor | ParamDictType], ParamDictType]:\n    \"\"\"Format an input tensor into the format required by the forward pass.\n\n    The tensor is assumed to have dimensions: n_batches x in_features where in_features\n    corresponds to the number of input features of the QNN\n    \"\"\"\n    in_features = len(inputs)\n\n    def tensor_to_dict(values: Tensor | ParamDictType) -&gt; ParamDictType:\n        if isinstance(values, Tensor):\n            values = values.reshape(-1, 1) if len(values.size()) == 1 else values\n            if not values.shape[1] == in_features:\n                raise ValueError(\n                    f\"Model expects in_features={in_features} but got {values.shape[1]}.\"\n                )\n            values = {fparam.name: values[:, inputs.index(fparam)] for fparam in inputs}  # type: ignore[union-attr]\n        return values\n\n    return tensor_to_dict\n</code></pre>"},{"location":"model/start/","title":"Getting Started","text":""},{"location":"model/start/#pre-requisites","title":"Pre-requisites","text":"<p>The library uses the following tools:</p> <ul> <li>hatch for managing virtual environment and dependencies</li> <li>pytest for building the unit tests suite</li> <li>black, isort and flake8 for code formatting and linting</li> <li>mypy for static type checking</li> <li>pre-commit for applying linting and formatting automatically before committing new code</li> </ul> <p>We recommend to use <code>pyenv</code> for managing python versions for managing python versions both globally and locally:</p> <pre><code># System-wide install of a python version.\npyenv install 3.10\n\n# Use 3.10 everywhere.\npyenv global 3.10\n\n# Or locally in the current directory.\npyenv local 3.10\n</code></pre>"},{"location":"model/start/#install-from-pypi","title":"Install from PyPi","text":"<p><code>qadence-model</code> is available on PyPi through <code>pip</code>.</p> <pre><code>pip install qadence-model\n</code></pre>"},{"location":"model/start/#install-from-source","title":"Install from source","text":"<p>All Pasqal quantum libraries require Python &gt;=3.9. For development, the preferred method to install this package is to use <code>hatch</code>. You can install from source by cloning this repository and run:</p> <pre><code>python -m pip install hatch\npython -m hatch -v shell\n\n# execute any script using the library\npython my_script.py\n</code></pre> <p>Alternatively, you can also:</p> <ul> <li>install with <code>pip</code> in development mode by simply running <code>pip install -e .</code>. Notice that in this way   you will install all the dependencies, including extras.</li> <li>install it with <code>conda</code> by simply using <code>pip</code> inside the Conda environment.</li> </ul>"},{"location":"model/start/#develop","title":"Develop","text":"<p>When developing the package, the recommended way is to create a virtual environment with <code>hatch</code> as shown above:</p> <pre><code>python -m pip install hatch\npython -m hatch -v shell\n</code></pre> <p>When inside the shell with development dependencies, install first the pre-commit hook: <pre><code>pre-commit install\n</code></pre></p> <p>In this way, you will get automatic linting and formatting every time you commit new code. Do not forget to run the unit test suite by simply running the <code>pytest</code> command.</p> <p>If you do not want to get into the Hatch shell, you can alternatively do the following:</p> <pre><code>python -m pip install hatch\npython -m hatch -v shell\n\n# install the pre-commit\npython -m hatch run pre-commit install\n\n# commit some code\npython -m hatch run git commit -m \"My awesome commit\"\n\n# run the unit tests suite\npython -m hatch run pytest\n</code></pre>"},{"location":"model/start/#document","title":"Document","text":"<p>You can improve the documentation of the package by editing this file for the landing page or adding new markdown or Jupyter notebooks to the <code>docs/</code> folder in the root of the project. In order to modify the table of contents, edit the <code>mkdocs.yml</code> file in the root of the project.</p> <p>In order to build and serve the documentation locally, you can use <code>hatch</code> with the right environment:</p> <pre><code>python -m hatch -v run docs:build\npython -m hatch -v run docs:serve\n</code></pre> <p>If you don't want to use <code>hatch</code>, just check into your favorite virtual environment and execute the following commands:</p> <pre><code>python -m pip install -r docs/requirements.txt\nmkdocs build\nmkdocs serve\n</code></pre>"},{"location":"model/contents/content/","title":"Variational quantum algorithms","text":"<p>Variational algorithms on noisy devices and quantum machine learning (QML)<sup>1</sup> in particular are one of the main target applications for Qadence. For this purpose, the library offers both flexible symbolic expressions for the quantum circuit parameters via <code>sympy</code> for more details and native automatic differentiation via integration with PyTorch deep learning framework.</p> <p>Furthermore, Qadence-Model offers a wide range of utilities for helping building and researching quantum machine learning algorithms.</p>"},{"location":"model/contents/content/#some-simple-examples","title":"Some simple examples","text":"<p>Qadence-Model symbolic parameter interface allows to create arbitrary feature maps to encode classical data into quantum circuits with an arbitrary non-linear function embedding for the input values:</p> <pre><code>import qadence as qd\nimport qadence_model as qdm\nfrom qadence.operations import *\nimport torch\nfrom sympy import acos\n\nn_qubits = 4\n\n# Example feature map, also directly available with the `feature_map` function\nfp = qd.FeatureParameter(\"phi\")\nfm = qd.kron(RX(i, acos(fp)) for i in range(n_qubits))\n\n# the key in the dictionary must correspond to\n# the name of the assigned to the feature parameter\ninputs = {\"phi\": torch.rand(3)}\nsamples = qd.sample(fm, values=inputs)\n</code></pre> <pre><code>samples = OrderedCounter({'0001': 14, '1000': 14, '0000': 13, '0101': 11, '0010': 7, '0100': 6, '1011': 5, '1100': 5, '1101': 5, '0011': 4, '0110': 4, '1010': 4, '1001': 3, '0111': 2, '1111': 2, '1110': 1})\n</code></pre> <p>The <code>constructors.feature_map</code> module provides convenience functions to build commonly used feature maps where the input parameter is encoded in the single-qubit gates rotation angle.</p> <p>Furthermore, Qadence-Model is natively integrated with PyTorch automatic differentiation engine thus Qadence-Model quantum models can be used seamlessly in a PyTorch workflow.</p> <p>Let's create a quantum neural network model using the feature map just defined, a digital-analog variational ansatz and a simple observable \\(X(0) \\otimes X(1)\\). We use the convenience <code>QNN</code> quantum model abstraction.</p> <pre><code>ansatz = qd.hea(n_qubits, strategy=\"sDAQC\")\ncircuit = qd.QuantumCircuit(n_qubits, fm, ansatz)\nobservable = qd.kron(X(0), X(1))\n\nmodel = qdm.models.QNN(circuit, observable)\n\n# NOTE: the `QNN` is a torch.nn.Module\nassert isinstance(model, torch.nn.Module)\n</code></pre> <pre><code>True\n</code></pre> <p>Differentiation works the same way as any other PyTorch module:</p> <pre><code>values = {\"phi\": torch.rand(10, requires_grad=True)}\n\n# the forward pass of the quantum model returns the expectation\n# value of the input observable\nout = model(values)\n\n# you can compute the gradient with respect to inputs using\n# PyTorch autograd differentiation engine\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: \\n{dout}\")\n\n# you can also call directly a backward pass to compute derivatives with respect\n# to the variational parameters and use it for implementing variational\n# optimization\nout.sum().backward()\n</code></pre> <pre><code>Quantum model output: \ntensor([[0.1476],\n        [0.0929],\n        [0.1187],\n        [0.1544],\n        [0.1126],\n        [0.1519],\n        [0.1489],\n        [0.1533],\n        [0.0739],\n        [0.1443]], grad_fn=&lt;CatBackward0&gt;)\n\nFirst-order derivative w.r.t. the feature parameter: \ntensor([-0.1055,  0.1833, -0.2827,  0.0014,  0.1695,  0.0541,  0.0775,  0.0360,\n        -0.5541, -0.1321], grad_fn=&lt;MulBackward0&gt;)\n</code></pre> <p>To run QML on real devices, Qadence-Model offers generalized parameter shift rules (GPSR) <sup>2</sup> for arbitrary quantum operations which can be selected when constructing the <code>QNN</code> model:</p> <pre><code>model = qdm.models.QNN(circuit, observable, diff_mode=\"gpsr\")\nout = model(values)\n\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: \\n{dout}\")\n</code></pre> <pre><code>First-order derivative w.r.t. the feature parameter: \ntensor([-0.1055,  0.1833, -0.2827,  0.0014,  0.1695,  0.0541,  0.0775,  0.0360,\n        -0.5541, -0.1321], grad_fn=&lt;MulBackward0&gt;)\n</code></pre>"},{"location":"model/contents/content/#references","title":"References","text":"<ol> <li> <p>Schuld, Petruccione, Machine learning on Quantum Computers, Springer Nature (2021)\u00a0\u21a9</p> </li> <li> <p>Kyriienko et al., General quantum circuit differentiation rules \u21a9</p> </li> </ol>"},{"location":"model/contents/qcnn/","title":"QCNN model","text":""},{"location":"model/contents/qcnn/#introduction","title":"Introduction","text":"<p>In this tutorial, we\u2019ll explore how to train a Quantum Convolutional Neural Network (QCNN) using Qadence, demonstrating its application on a simple yet insightful data structure. The tutorial begins by detailing the construction of the quantum circuit and the synthetic data generation process. Convolutional architectures excel at capturing spatial relationships in grid-like structures, so we design our data to emulate a system of five interconnected grid elements, where the collective behavior produces a single continuous output value. The key idea is to aggregate features from four neighboring elements into a fifth central node, generating a compact embedding that encodes structural information. By training the QCNN to predict the global property from this localized representation, we effectively enable the model to infer system-wide behavior from a single node\u2019s contextual features\u2014showcasing the potential of quantum machine learning for relational reasoning tasks.</p>"},{"location":"model/contents/qcnn/#qcnn-circuitry","title":"QCNN circuitry","text":"<p>A generic QCNN is described as \\(\\Phi_{{\\theta},{\\lambda}} =\\bigcirc_{l=1}^{L} \\big(\\text{P}_{l}^{{\\lambda}_{l}} \\circ \\text{C}_{l}^{{\\theta}_{l}}\\big)\\)</p> <p>where \\(\\circ\\) denotes a single function composition, and \\(\\bigcirc_{l=1}^L\\) represents the composition of \\(L\\) functions applied sequentially. Each QGCN layer \\(l\\) comprises a quatnum convolutional layer \\(\\text{C}_l^{{\\theta}_{l}}\\) followed by a quantum pooling layer \\(\\text{P}_{l}^{{\\lambda}_{l}}\\), with \\({\\theta}_{l}\\) and \\({\\lambda}_{l}\\) being the convolution and pooling parameters, respectively. The alternating structure of the QGNN circuit processes and simplifies the input quantum state, starting with \\(\\text{C}_1\\) and ending with \\(\\text{P}_{L}\\).</p> <p>The convolutional layer \\(\\text{C}_l^{{\\theta}_l}: \\mathcal{S}(\\mathcal{H}_l) \\rightarrow \\mathcal{S}(\\mathcal{H}_l)\\) preserves the size of the quantum register. It reads \\(\\text{C}_l^{{\\theta}_l}(\\cdot) = \\bigcirc_{j=1}^{r}  \\left(\\bigotimes_{i \\in \\text{S}(j)} W_l^{(i, i+1)}\\left({\\theta}_l\\right)\\right)(\\cdot)\\)</p> <p>Each convolutional layer acts on an even number of qubits, since the unitary \\(W_l\\)<sup>1</sup> convolves a pairs of neighboring qubits \\((i, i+1)\\).  In general, the operator \\(W\\) acts on pairs of adjacent qubits defined by the set \\(S(j) = \\{(i, i+1) \\mid i \\equiv j \\!\\!\\!\\mod 2, \\ 0 \\leq i \\leq N-2\\}\\), where \\(N\\) denotes the total number of qubits<sup>2</sup>. This construction ensures an alternating nearest-neighbor interaction pattern. The alternation is determined by the parity of \\(j\\): for even \\(j\\), \\(W\\) acts on even-indexed pairs \\((0,1)\\), \\((2,3)\\), etc.; similarly, for odd values of \\(j\\), the same operation is performed on odd-indexed pairs in an analogous manner. Each convolutional layer \\(\\text{C}_l^{{\\theta}_l}\\) has an associated parameter \\(r\\), representing its depth. For example, in a two-layer QGCN architecture, the depths of \\(\\text{C}_1\\) and \\(\\text{C}_2\\) are denoted as \\(r_1\\) and \\(r_2\\), respectively.</p> <p>The pooling layer \\(\\text{P}_{l}^{{\\lambda}_l}: \\mathcal{S}(\\mathcal{H}_l) \\rightarrow \\mathcal{S}(\\mathcal{H}_{l+1})\\) reduces the size of the quantum register by tracing out specific qubits, such that \\(\\dim(\\mathcal{H}_{l+1}) &lt; \\dim(\\mathcal{H}_l)\\), and is defined as \\(\\text{P}_{l}^{{\\lambda}_l}(\\cdot) = Tr_{i}[(\\cdot)]\\)</p> <p>where the \\(i\\)-qubit is traced out in the \\(l\\)-th layer. The pooling layers typically discard half of the qubits at each step.</p> <p>We adopt a simple architecture for \\(\\text{C}_l^{{\\theta}_l}\\) and \\(\\text{P}_{l}^{{\\lambda}_l}\\). The unitary \\(W\\) is defined as in Ref. vatan_2004_optimal, where the \\(A\\) gates are defined similarly in terms of \\(R_G({\\theta}_l) = e^{-iX\\theta^1_{l}/2}e^{-iZ\\theta^2_{l}/2}e^{-iX\\theta^3_{l}/2}\\). Entanglement is achieved applying non-parametrized CZ gates. In the pooling layers, entanglement is followed by local measurements on \\(\\mathcal{O}\\), enabled by the deferred measurement principle as in Ref. Nielsen. The chosen design reduces the complexity of the QGCN circuit by \\(\\Phi_{{\\theta}, {\\lambda}} \\to \\Phi_{{\\theta}}\\)</p> <p>A schematic illustration of the full circuit can be found in our work on QGNNs which shares a similar circuit design</p>"},{"location":"model/contents/qcnn/#dummy-data-description","title":"Dummy Data Description","text":"<ol> <li>4 grid elements (each with <code>n_qubits</code> features) influence a 5th element</li> <li>The relationship is encoded in a single continuous target value</li> </ol>"},{"location":"model/contents/qcnn/#input-and-target-tensors-dummy_input-and-dummy_target","title":"Input and Target Tensors (<code>dummy_input</code> and <code>dummy_target</code>)","text":"<ol> <li>Input<ul> <li>Shape: <code>(4, n_qubits)</code>: 4 samples representing 4 grid elements with <code>n_qubits</code> features per grid element. Random values between [0, 1)</li> </ul> </li> <li>Target<ul> <li>Shape: <code>(1, 1)</code>: Single scalar value representing the aggregated property of the 5th connected grid element. Random value between [0, 1)</li> </ul> </li> </ol> <pre><code>import torch\nn_features = 8\ndummy_input = torch.rand(4, n_features).float()\ndummy_target = torch.rand(1, 1).float()\n</code></pre>"},{"location":"model/contents/qcnn/#training-a-qcnn","title":"Training a QCNN","text":"<p>Now we perform the training of the QCNN on the dummy data generated earlier.</p>"},{"location":"model/contents/qcnn/#define-the-qcnn-circuit-with-qadence","title":"Define the QCNN circuit with Qadence","text":"<p>First we define a class with mean pooling on the QCNN output to match target value <pre><code>class qcnn_msg_passing(torch.nn.Module):\n    def __init__(self, qcnn: torch.nn.Module, output_size: int = 1):\n        super(qcnn_msg_passing, self).__init__()\n        self.qcnn = qcnn\n        self.output_size = output_size\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        x = x.float()\n        x = self.qcnn(x).float().view(-1, self.output_size)\n        return torch.mean(x, dim=0, keepdim=True)\n</code></pre> </p> <p>The model is hence defined as <pre><code># QCNN model\nfrom qadence import RX, RZ, CZ, QCNN\n\nn_qubits = n_features\nhidden_depth = [1,1,1]\noperations = [RX, RZ, RX]\nentangler = CZ\nrandom_meas = True\n\nqcnn_circuit = QCNN(\n    n_inputs=n_qubits,\n    n_qubits=n_qubits,\n    depth=hidden_depth,\n    operations=operations,\n    entangler=entangler,\n    random_meas=random_meas,\n    is_corr=False,\n)\n\nmodel = qcnn_msg_passing(qcnn_circuit, dummy_target.shape[1])\n</code></pre> </p>"},{"location":"model/contents/qcnn/#training-loop","title":"Training loop:","text":"<p>The training is performed as follows:</p> <pre><code>from qadence import RX, RZ, CZ, QCNN\n\nn_qubits = n_features\nhidden_depth = [1,1,1]\noperations = [RX, RZ, RX]\nentangler = CZ\nrandom_meas = True\n\nqcnn_circuit = QCNN(\n    n_inputs=n_qubits,\n    n_qubits=n_qubits,\n    depth=hidden_depth,\n    operations=operations,\n    entangler=entangler,\n    random_meas=random_meas,\n    is_corr=False,\n)\n\nmodel = qcnn_msg_passing(qcnn_circuit, dummy_target.shape[1])\n\n\nn_epochs = 100\nlr = 0.01\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n# Training loop\nfor epoch in range(n_epochs + 1):\n    optimizer.zero_grad()\n    output = model(dummy_input)\n    loss = torch.nn.functional.mse_loss(output, dummy_target)\n    loss.backward()\n    optimizer.step()\n\n    if epoch % 10 == 0:\n        print(f\"Epoch={epoch:&gt;4d} | Loss={loss.item():&gt;10.6f}\")\n</code></pre>   Epoch=   0 | Loss=  0.011257 Epoch=  10 | Loss=  0.001466 Epoch=  20 | Loss=  0.000094 Epoch=  30 | Loss=  0.000231 Epoch=  40 | Loss=  0.000004 Epoch=  50 | Loss=  0.000028 Epoch=  60 | Loss=  0.000000 Epoch=  70 | Loss=  0.000004 Epoch=  80 | Loss=  0.000000 Epoch=  90 | Loss=  0.000000 Epoch= 100 | Loss=  0.000000    <ol> <li> <p>We also refer to \\(W\\) as convolutional cell.\u00a0\u21a9</p> </li> <li> <p>Qubit indexing is 0-based, i.e., \\(0, 1, \\dots, N-1\\).\u00a0\u21a9</p> </li> </ol>"},{"location":"model/contents/qnn_config/","title":"Configuring a QNN","text":"<p>In <code>qadence-model</code>, the <code>QNN</code> is a variational quantum model that can potentially take multi-dimensional input.</p> <p>The <code>QNN</code> class needs a circuit and a list of observables; the number of feature parameters in the input circuit determines the number of input features (i.e. the dimensionality of the classical data given as input) whereas the number of observables determines the number of outputs of the quantum neural network.</p> <p>The circuit has two parts, the feature map and the ansatz. The feature map is responsible for encoding the input data into the quantum state, while the ansatz is responsible for the variational part of the model. In addition, a third part of the QNN is the observables, which is (a list of) operators that are measured at the end of the circuit. In this tutorial, we will see how to do the same using configs.</p> <p>One convenient way to construct these two parts of the model is to use the config classes, namely, <code>FeatureMapConfig</code> and <code>AnsatzConfig</code>. These classes allow you to specify the type of circuit and the parameters of the circuit in a structured way.</p>"},{"location":"model/contents/qnn_config/#defining-the-observable","title":"Defining the Observable","text":"<p>The model output is the expectation value of the defined observable(s). We use the <code>ObservableConfig</code> class to specify the observable.</p> <p>It can be used to create Hamiltonians with 2-qubit interactions and single-qubit detunings. Any Hamiltonian supported by <code>hamiltonian_factory</code> can be specified as an observable. For example, suppose we want to measure the Z operator:</p> <pre><code>from qadence import ObservableConfig, Z\nfrom qadence_model.models import create_observable\n\nobservable_config = ObservableConfig(\n    detuning=Z,\n    interaction = None,\n    scale = 2.0,\n    shift=-1.0,\n)\n\nobservable = create_observable(register=4, config=observable_config)\n</code></pre> %3 cluster_62950d01a50e42f698672894c7c43cbd a947f466e7ba4d4f920ad3d43b7be589 0 d1842f9a80d84da3974dc9c1459be743 a947f466e7ba4d4f920ad3d43b7be589--d1842f9a80d84da3974dc9c1459be743 7f7fe2e030354f9c95dc99d1474dcbc0 1 bcb4dc2113d84788a9137666201be8b0 d1842f9a80d84da3974dc9c1459be743--bcb4dc2113d84788a9137666201be8b0 9b2a9af5869a47b7b81a6a54fa71e509 634dc739884e40a9bcdf4b04d8a6bed8 AddBlock 7f7fe2e030354f9c95dc99d1474dcbc0--634dc739884e40a9bcdf4b04d8a6bed8 e5fec2babd174ed489e3990bb00f753c 2 634dc739884e40a9bcdf4b04d8a6bed8--9b2a9af5869a47b7b81a6a54fa71e509 a5c3e69ea3a342789647e6e8cc63c944 88eb25d7238f4cbf8cad24ff0a37a830 e5fec2babd174ed489e3990bb00f753c--88eb25d7238f4cbf8cad24ff0a37a830 4576f8f0b4ea42baaf83adb811c3c0bc 3 88eb25d7238f4cbf8cad24ff0a37a830--a5c3e69ea3a342789647e6e8cc63c944 1d9d1de0b3d64982b7d650ea3433923c 2e7c559e4646410a957d91879c3ce02c 4576f8f0b4ea42baaf83adb811c3c0bc--2e7c559e4646410a957d91879c3ce02c 2e7c559e4646410a957d91879c3ce02c--1d9d1de0b3d64982b7d650ea3433923c"},{"location":"model/contents/qnn_config/#defining-the-feature-map","title":"Defining the Feature Map","text":"<p>Let us say we want to build a 4-qubit QNN that takes two inputs, namely, the \\(x\\) and the \\(y\\) coordinates of a point in the plane. We can use the <code>FeatureMapConfig</code> class to specify the feature map.</p> <pre><code>from qadence import BasisSet, chain, ReuploadScaling\nfrom qadence_model.models import create_fm_blocks, FeatureMapConfig\n\nfm_config = FeatureMapConfig(\n    num_features=2,\n    inputs = [\"x\", \"y\"],\n    basis_set=BasisSet.CHEBYSHEV,\n    reupload_scaling=ReuploadScaling.TOWER,\n    feature_range={\n        \"x\": (-1.0, 1.0),\n        \"y\": (0.0, 1.0),\n    },\n)\n\nfm_blocks = create_fm_blocks(register=4, config=fm_config)\nfeature_map = chain(*fm_blocks)\n</code></pre> %3 cluster_97a12310b8fd468883f1fe7a84ffb774 Tower Chebyshev FM cluster_d2b176f61ca246239a7d964ff13e45eb Tower Chebyshev FM aab27b6a4b1f4e2b93386c2d19a5afd2 0 1b721c70f32c44d2ae04fc7a760971e3 RX(1.0*acos(x)) aab27b6a4b1f4e2b93386c2d19a5afd2--1b721c70f32c44d2ae04fc7a760971e3 d645f82330604deea50314a271b5c800 1 e51e05803579439b9dc7b43b2ca9a1ca 1b721c70f32c44d2ae04fc7a760971e3--e51e05803579439b9dc7b43b2ca9a1ca 068ced4d66054198b72c159b54959d9c a88e4019010a46dc8557cbe848cdd343 RX(2.0*acos(x)) d645f82330604deea50314a271b5c800--a88e4019010a46dc8557cbe848cdd343 60866e5e31e044ae9830216c03ee1e84 2 a88e4019010a46dc8557cbe848cdd343--068ced4d66054198b72c159b54959d9c cfc7a5d94a464da4baf9999ba47fc715 23cb09e600eb4281842a78ad696f19f4 RX(1.0*acos(2.0*y - 1.0)) 60866e5e31e044ae9830216c03ee1e84--23cb09e600eb4281842a78ad696f19f4 feaab0277c964dcc958e5dabffd61ddc 3 23cb09e600eb4281842a78ad696f19f4--cfc7a5d94a464da4baf9999ba47fc715 be6b7ca111234217b8304f27be483d2d 7284c7be0d2342c494d4c12e9cf59f13 RX(2.0*acos(2.0*y - 1.0)) feaab0277c964dcc958e5dabffd61ddc--7284c7be0d2342c494d4c12e9cf59f13 7284c7be0d2342c494d4c12e9cf59f13--be6b7ca111234217b8304f27be483d2d <p>We have specified that the feature map should take two features, and have named the <code>FeatureParameter</code> \"x\" and \"y\" respectively. Both these parameters are encoded using the Chebyshev basis set, and the reupload scaling is set to <code>ReuploadScaling.TOWER</code>. One can optionally add the basis and the reupload scaling for each parameter separately.</p> <p>The <code>feature_range</code> parameter is a dictionary that specifies the range of values that each feature comes from. This is useful for scaling the input data to the range that the encoding function can handle. In default case, this range is mapped to the target range of the Chebyshev basis set which is \\([-1, 1]\\). One can also specify the target range for each feature separately..</p>"},{"location":"model/contents/qnn_config/#defining-the-ansatz","title":"Defining the Ansatz","text":"<p>The next part of the QNN is the ansatz. We use <code>AnsatzConfig</code> class to specify the type of ansatz.</p> <p>Let us say, we want to follow this feature map with 2 layers of hardware efficient ansatz.</p> <pre><code>from qadence import AnsatzType, Strategy\nfrom qadence_model.models import AnsatzConfig, create_ansatz\n\nansatz_config = AnsatzConfig(\n    depth=2,\n    ansatz_type=AnsatzType.HEA,\n    ansatz_strategy=Strategy.DIGITAL,\n)\n\nansatz = create_ansatz(register=4, config=ansatz_config)\n</code></pre> %3 6f46f8fc0c8a48709182e74e47fc2d86 0 751710ce76a4459ca2f211f8a5a80966 RX(theta\u2080) 6f46f8fc0c8a48709182e74e47fc2d86--751710ce76a4459ca2f211f8a5a80966 2c04bc536b1f42c9b9b982caeb4793cb 1 99637433cb8d427ba086ee510c3ae7d2 RY(theta\u2084) 751710ce76a4459ca2f211f8a5a80966--99637433cb8d427ba086ee510c3ae7d2 d227982fbc59487a9824af5513ddef59 RX(theta\u2088) 99637433cb8d427ba086ee510c3ae7d2--d227982fbc59487a9824af5513ddef59 1f2dee88870b4deab012c43edf76d1e6 d227982fbc59487a9824af5513ddef59--1f2dee88870b4deab012c43edf76d1e6 ac1c9710cde24fceb00217850406541e 1f2dee88870b4deab012c43edf76d1e6--ac1c9710cde24fceb00217850406541e d8aa7aca365645f49b9c3ddff2e92391 RX(theta\u2081\u2082) ac1c9710cde24fceb00217850406541e--d8aa7aca365645f49b9c3ddff2e92391 094cd6de496749aab9410783bfb7e0c9 RY(theta\u2081\u2086) d8aa7aca365645f49b9c3ddff2e92391--094cd6de496749aab9410783bfb7e0c9 2a23d508c1e2433aa893ac7c8bca76fc RX(theta\u2082\u2080) 094cd6de496749aab9410783bfb7e0c9--2a23d508c1e2433aa893ac7c8bca76fc a1de4976b4aa4d399954146eaaea2528 2a23d508c1e2433aa893ac7c8bca76fc--a1de4976b4aa4d399954146eaaea2528 6ec6657fcf474f72a97c78813e9b2420 a1de4976b4aa4d399954146eaaea2528--6ec6657fcf474f72a97c78813e9b2420 9ca0dc23319c470680b026e7ee82afec 6ec6657fcf474f72a97c78813e9b2420--9ca0dc23319c470680b026e7ee82afec 6a18bc19b4e8440c9243631604b8e7d5 9352f30b339b42e2aa1661762ec1238a RX(theta\u2081) 2c04bc536b1f42c9b9b982caeb4793cb--9352f30b339b42e2aa1661762ec1238a 49960b5890b64e709f094544f8aaf22c 2 d1ca09b6a90f49f088436e1645b25bea RY(theta\u2085) 9352f30b339b42e2aa1661762ec1238a--d1ca09b6a90f49f088436e1645b25bea 49e60282e0a64d7fb0708fa703c59552 RX(theta\u2089) d1ca09b6a90f49f088436e1645b25bea--49e60282e0a64d7fb0708fa703c59552 c3dff0e424fc4071bb25fab9468fc04e X 49e60282e0a64d7fb0708fa703c59552--c3dff0e424fc4071bb25fab9468fc04e c3dff0e424fc4071bb25fab9468fc04e--1f2dee88870b4deab012c43edf76d1e6 1f7ed5d3f76d436dabb64b02d136f787 c3dff0e424fc4071bb25fab9468fc04e--1f7ed5d3f76d436dabb64b02d136f787 d36a9650b08848eab17f9a1cd99130ef RX(theta\u2081\u2083) 1f7ed5d3f76d436dabb64b02d136f787--d36a9650b08848eab17f9a1cd99130ef cedddd5c05964aa8a7bea5c5519f5e52 RY(theta\u2081\u2087) d36a9650b08848eab17f9a1cd99130ef--cedddd5c05964aa8a7bea5c5519f5e52 41c3bbf1540e4985b9cc238570bdda4a RX(theta\u2082\u2081) cedddd5c05964aa8a7bea5c5519f5e52--41c3bbf1540e4985b9cc238570bdda4a 300c8dd82fbf442ab455b2ffe780c797 X 41c3bbf1540e4985b9cc238570bdda4a--300c8dd82fbf442ab455b2ffe780c797 300c8dd82fbf442ab455b2ffe780c797--a1de4976b4aa4d399954146eaaea2528 4bd53928e4c44c428ec6909718910514 300c8dd82fbf442ab455b2ffe780c797--4bd53928e4c44c428ec6909718910514 4bd53928e4c44c428ec6909718910514--6a18bc19b4e8440c9243631604b8e7d5 9a5e4563f50e4ded850b4f21d372219f 1da10e1e810b4a879c49e75d86c1478c RX(theta\u2082) 49960b5890b64e709f094544f8aaf22c--1da10e1e810b4a879c49e75d86c1478c 866637acc22745a78ebcd25591109af1 3 b1887cdda6164aa184f6e7334ca116c7 RY(theta\u2086) 1da10e1e810b4a879c49e75d86c1478c--b1887cdda6164aa184f6e7334ca116c7 c5588b9e54474c13bd8c74966cde65a5 RX(theta\u2081\u2080) b1887cdda6164aa184f6e7334ca116c7--c5588b9e54474c13bd8c74966cde65a5 5f3654ab8d42412cac41adcdf2189e73 c5588b9e54474c13bd8c74966cde65a5--5f3654ab8d42412cac41adcdf2189e73 64fe382c57f1402d91c2648b1911308c X 5f3654ab8d42412cac41adcdf2189e73--64fe382c57f1402d91c2648b1911308c 64fe382c57f1402d91c2648b1911308c--1f7ed5d3f76d436dabb64b02d136f787 4763095afacb41968a7e34f2d5d58012 RX(theta\u2081\u2084) 64fe382c57f1402d91c2648b1911308c--4763095afacb41968a7e34f2d5d58012 712d6bc14a4b4e5a8ea1e4c5cbba646e RY(theta\u2081\u2088) 4763095afacb41968a7e34f2d5d58012--712d6bc14a4b4e5a8ea1e4c5cbba646e 3b5e97ec9d5b49a89007acf72b233121 RX(theta\u2082\u2082) 712d6bc14a4b4e5a8ea1e4c5cbba646e--3b5e97ec9d5b49a89007acf72b233121 9eb3e8d821574a8c95e7f5b56282a55a 3b5e97ec9d5b49a89007acf72b233121--9eb3e8d821574a8c95e7f5b56282a55a db30130a360e42e49145d4004346305a X 9eb3e8d821574a8c95e7f5b56282a55a--db30130a360e42e49145d4004346305a db30130a360e42e49145d4004346305a--4bd53928e4c44c428ec6909718910514 db30130a360e42e49145d4004346305a--9a5e4563f50e4ded850b4f21d372219f af182989d9184247bb87671450007aee fcca0d0b411646d9821029807f3738de RX(theta\u2083) 866637acc22745a78ebcd25591109af1--fcca0d0b411646d9821029807f3738de becf536bd4314929ac16dd7983d47c4f RY(theta\u2087) fcca0d0b411646d9821029807f3738de--becf536bd4314929ac16dd7983d47c4f 3d95579e20ee4f0b8fa4fea4a410b2f6 RX(theta\u2081\u2081) becf536bd4314929ac16dd7983d47c4f--3d95579e20ee4f0b8fa4fea4a410b2f6 22c641bb30df4551b3f4c8fa67d945ef X 3d95579e20ee4f0b8fa4fea4a410b2f6--22c641bb30df4551b3f4c8fa67d945ef 22c641bb30df4551b3f4c8fa67d945ef--5f3654ab8d42412cac41adcdf2189e73 633dc9d2d8a642f7baad809eaac7b644 22c641bb30df4551b3f4c8fa67d945ef--633dc9d2d8a642f7baad809eaac7b644 22c7750d43b345b9be8c81a60a0732f7 RX(theta\u2081\u2085) 633dc9d2d8a642f7baad809eaac7b644--22c7750d43b345b9be8c81a60a0732f7 c76d0947ef2e40729bb7de93234db9cb RY(theta\u2081\u2089) 22c7750d43b345b9be8c81a60a0732f7--c76d0947ef2e40729bb7de93234db9cb a5085eda2d744a438f0509f2d2df99da RX(theta\u2082\u2083) c76d0947ef2e40729bb7de93234db9cb--a5085eda2d744a438f0509f2d2df99da afa3c3d01b0e460ab6c114e1d4ce18c3 X a5085eda2d744a438f0509f2d2df99da--afa3c3d01b0e460ab6c114e1d4ce18c3 afa3c3d01b0e460ab6c114e1d4ce18c3--9eb3e8d821574a8c95e7f5b56282a55a 691a4795c60d47d9b8b3c3c8f842309c afa3c3d01b0e460ab6c114e1d4ce18c3--691a4795c60d47d9b8b3c3c8f842309c 691a4795c60d47d9b8b3c3c8f842309c--af182989d9184247bb87671450007aee <p>We have specified that the ansatz should have a depth of 2, and the ansatz type is \"hea\" (Hardware Efficient Ansatz). The ansatz strategy is set to \"digital\", which means digital gates are being used. One could alternatively use \"analog\" or \"rydberg\" as the ansatz strategy.</p>"},{"location":"model/contents/qnn_config/#defining-the-qnn-from-the-configs","title":"Defining the QNN from the Configs","text":"<p>To build the QNN, we can now use the <code>QNN</code> class as a <code>QuantumModel</code> subtype. In addition to the feature map, ansatz and the observable configs, we can also specify options such as the <code>backend</code>, <code>diff_mode</code>, etc.</p> <pre><code>from qadence import BackendName, DiffMode, ObservableConfig, Z\nfrom qadence_model.models import QNN\n\nobservable_config = ObservableConfig(\n    detuning=Z,\n    interaction = None,\n    scale = 2.0,\n    shift=-1.0,\n)\n\nqnn = QNN.from_configs(\n    register=4,\n    obs_config=observable_config,\n    fm_config=fm_config,\n    ansatz_config=ansatz_config,\n    backend=BackendName.PYQTORCH,\n    diff_mode=DiffMode.AD,\n)\n</code></pre> %3 cluster_618f8aae4b63406d883f44098f67e7a9 Obs. cluster_547d9c2693874dcb9f374b5ba0daffd4 cluster_e4cf0a5b2bf14767ac9a014b2f5db0b4 Tower Chebyshev FM cluster_ceea6e2cd18442a184aae6b8107a01a8 Tower Chebyshev FM cluster_580bff45b65348a0ac159095a1c96349 HEA 33d24976b2b04100bb4d591663ae41a6 0 dae4b97cb8014b3bb8970b0a43474bcb RX(1.0*acos(x)) 33d24976b2b04100bb4d591663ae41a6--dae4b97cb8014b3bb8970b0a43474bcb 8153fe6c6dcc4fa9b9abbce55688c535 1 8552b39ef9b84323a74c7a20e400d997 RX(theta\u2080) dae4b97cb8014b3bb8970b0a43474bcb--8552b39ef9b84323a74c7a20e400d997 7f61298120af4d07a731f7f05de2ded5 RY(theta\u2084) 8552b39ef9b84323a74c7a20e400d997--7f61298120af4d07a731f7f05de2ded5 329ebbec8f5e4643b1bde4d523ee261d RX(theta\u2088) 7f61298120af4d07a731f7f05de2ded5--329ebbec8f5e4643b1bde4d523ee261d 9c2e77305bab41a6b9e12fe525701a6e 329ebbec8f5e4643b1bde4d523ee261d--9c2e77305bab41a6b9e12fe525701a6e 823a1f38f7124b3783ba381a0ef041a9 9c2e77305bab41a6b9e12fe525701a6e--823a1f38f7124b3783ba381a0ef041a9 4e3a0090f38f4ac29e954b001d566da5 RX(theta\u2081\u2082) 823a1f38f7124b3783ba381a0ef041a9--4e3a0090f38f4ac29e954b001d566da5 8a611490056e4592baea0a22aa183fff RY(theta\u2081\u2086) 4e3a0090f38f4ac29e954b001d566da5--8a611490056e4592baea0a22aa183fff ad1dbcbc93164eaf9370d9013e8dd964 RX(theta\u2082\u2080) 8a611490056e4592baea0a22aa183fff--ad1dbcbc93164eaf9370d9013e8dd964 6fff92b735b2490f88f9a8d1d44143a7 ad1dbcbc93164eaf9370d9013e8dd964--6fff92b735b2490f88f9a8d1d44143a7 d68a952570394bc4b8fd2fad7b1841a3 6fff92b735b2490f88f9a8d1d44143a7--d68a952570394bc4b8fd2fad7b1841a3 bc4852ee99af4011a8e3c240421dc1b5 d68a952570394bc4b8fd2fad7b1841a3--bc4852ee99af4011a8e3c240421dc1b5 3895d4edc4e446b0996a2f6cafae50b3 bc4852ee99af4011a8e3c240421dc1b5--3895d4edc4e446b0996a2f6cafae50b3 2dc85d674ba24aa6b7cb531031814468 1984581fcbfe41178ab50df3c64c31f2 RX(2.0*acos(x)) 8153fe6c6dcc4fa9b9abbce55688c535--1984581fcbfe41178ab50df3c64c31f2 3b765b665475410c86e5e10b4ee73966 2 5b12be4679cd480e93dd3495fc487990 RX(theta\u2081) 1984581fcbfe41178ab50df3c64c31f2--5b12be4679cd480e93dd3495fc487990 71506f44b3b54c5094393910db44a12f RY(theta\u2085) 5b12be4679cd480e93dd3495fc487990--71506f44b3b54c5094393910db44a12f 8a2e691097054b46acea237156412373 RX(theta\u2089) 71506f44b3b54c5094393910db44a12f--8a2e691097054b46acea237156412373 a927da5823774281b5bf20dbe4f95bec X 8a2e691097054b46acea237156412373--a927da5823774281b5bf20dbe4f95bec a927da5823774281b5bf20dbe4f95bec--9c2e77305bab41a6b9e12fe525701a6e eecfd7b47bc245cfb6b0fc80a4fcfc60 a927da5823774281b5bf20dbe4f95bec--eecfd7b47bc245cfb6b0fc80a4fcfc60 e85c3dd45c344856a110011e469b3913 RX(theta\u2081\u2083) eecfd7b47bc245cfb6b0fc80a4fcfc60--e85c3dd45c344856a110011e469b3913 05cdbe1fee94429f9211738db4ede964 RY(theta\u2081\u2087) e85c3dd45c344856a110011e469b3913--05cdbe1fee94429f9211738db4ede964 66e917205d6f45198f6aa8c0c2366643 RX(theta\u2082\u2081) 05cdbe1fee94429f9211738db4ede964--66e917205d6f45198f6aa8c0c2366643 4e9b7e08eaa14fce87bda2e2b0bfd178 X 66e917205d6f45198f6aa8c0c2366643--4e9b7e08eaa14fce87bda2e2b0bfd178 4e9b7e08eaa14fce87bda2e2b0bfd178--6fff92b735b2490f88f9a8d1d44143a7 8a81d94e7c4f4d6b9eb17e03ac5cb1c8 4e9b7e08eaa14fce87bda2e2b0bfd178--8a81d94e7c4f4d6b9eb17e03ac5cb1c8 ca78f2c42de244568bec9ead825e34e1 AddBlock 8a81d94e7c4f4d6b9eb17e03ac5cb1c8--ca78f2c42de244568bec9ead825e34e1 ca78f2c42de244568bec9ead825e34e1--2dc85d674ba24aa6b7cb531031814468 116e868932904c419ded0a5775b0e8f9 036ed6335b4b47feb07bcbee69da673d RX(1.0*acos(2.0*y - 1.0)) 3b765b665475410c86e5e10b4ee73966--036ed6335b4b47feb07bcbee69da673d b0a024e6efa444caa9073a503e102549 3 dc200b9dc7aa48f9b0b9f8ad8da43c9b RX(theta\u2082) 036ed6335b4b47feb07bcbee69da673d--dc200b9dc7aa48f9b0b9f8ad8da43c9b c71281db4e1f41fa85180d53bd11821c RY(theta\u2086) dc200b9dc7aa48f9b0b9f8ad8da43c9b--c71281db4e1f41fa85180d53bd11821c 4d633c8e927143b483ca7a36cddd29ee RX(theta\u2081\u2080) c71281db4e1f41fa85180d53bd11821c--4d633c8e927143b483ca7a36cddd29ee 2595cc315d124a14b55cbe48490ffc6f 4d633c8e927143b483ca7a36cddd29ee--2595cc315d124a14b55cbe48490ffc6f 2f54302f0fe942f9a56ff01300e31f3c X 2595cc315d124a14b55cbe48490ffc6f--2f54302f0fe942f9a56ff01300e31f3c 2f54302f0fe942f9a56ff01300e31f3c--eecfd7b47bc245cfb6b0fc80a4fcfc60 05c60b30e0964d7cbc5edeffba1464e2 RX(theta\u2081\u2084) 2f54302f0fe942f9a56ff01300e31f3c--05c60b30e0964d7cbc5edeffba1464e2 190f016b3eef4d589b07ae775bc2f403 RY(theta\u2081\u2088) 05c60b30e0964d7cbc5edeffba1464e2--190f016b3eef4d589b07ae775bc2f403 f301a7227f0b4ff992255779083e0798 RX(theta\u2082\u2082) 190f016b3eef4d589b07ae775bc2f403--f301a7227f0b4ff992255779083e0798 1357579b5f994e3a8a874f60a018c3ec f301a7227f0b4ff992255779083e0798--1357579b5f994e3a8a874f60a018c3ec 0582d5fbeed349e3a352e489adca5ab4 X 1357579b5f994e3a8a874f60a018c3ec--0582d5fbeed349e3a352e489adca5ab4 0582d5fbeed349e3a352e489adca5ab4--8a81d94e7c4f4d6b9eb17e03ac5cb1c8 abe3b42163bd4fb6ba92aaf1e2ff31f4 0582d5fbeed349e3a352e489adca5ab4--abe3b42163bd4fb6ba92aaf1e2ff31f4 abe3b42163bd4fb6ba92aaf1e2ff31f4--116e868932904c419ded0a5775b0e8f9 2edef6f2e15f4c93aa413fa8e0305de6 185d5fef7a2d49989f8c007eaab56f1a RX(2.0*acos(2.0*y - 1.0)) b0a024e6efa444caa9073a503e102549--185d5fef7a2d49989f8c007eaab56f1a b79ae3f094bc4654ad305384c00942dd RX(theta\u2083) 185d5fef7a2d49989f8c007eaab56f1a--b79ae3f094bc4654ad305384c00942dd 4c34ef72ce2f4de1831fa7d59b78334d RY(theta\u2087) b79ae3f094bc4654ad305384c00942dd--4c34ef72ce2f4de1831fa7d59b78334d 38c7524a28614efdbde89d4221309cde RX(theta\u2081\u2081) 4c34ef72ce2f4de1831fa7d59b78334d--38c7524a28614efdbde89d4221309cde c1bddd45f058466bb47b3a670c44def6 X 38c7524a28614efdbde89d4221309cde--c1bddd45f058466bb47b3a670c44def6 c1bddd45f058466bb47b3a670c44def6--2595cc315d124a14b55cbe48490ffc6f 0338e3511e7b45ca86fae75add3a0c6b c1bddd45f058466bb47b3a670c44def6--0338e3511e7b45ca86fae75add3a0c6b 2cfe0902fd7c4b9e8e00aaf7461dfb84 RX(theta\u2081\u2085) 0338e3511e7b45ca86fae75add3a0c6b--2cfe0902fd7c4b9e8e00aaf7461dfb84 a734b67e4efd4c36a74e0a6c4d2e579b RY(theta\u2081\u2089) 2cfe0902fd7c4b9e8e00aaf7461dfb84--a734b67e4efd4c36a74e0a6c4d2e579b c4d014b457864058b3325b59984e4ee8 RX(theta\u2082\u2083) a734b67e4efd4c36a74e0a6c4d2e579b--c4d014b457864058b3325b59984e4ee8 3c3236ab61fa4844a3d3c5fbd92232b4 X c4d014b457864058b3325b59984e4ee8--3c3236ab61fa4844a3d3c5fbd92232b4 3c3236ab61fa4844a3d3c5fbd92232b4--1357579b5f994e3a8a874f60a018c3ec 38047bc166c0416597202ae1c23de10f 3c3236ab61fa4844a3d3c5fbd92232b4--38047bc166c0416597202ae1c23de10f 64d40325e9dc482d8409b7bd23f2209e 38047bc166c0416597202ae1c23de10f--64d40325e9dc482d8409b7bd23f2209e 64d40325e9dc482d8409b7bd23f2209e--2edef6f2e15f4c93aa413fa8e0305de6"},{"location":"model/tutorials/dqc_1d/","title":"Solving a 1D ODE","text":"<p>In this tutorial we will show how to use Qadence-Model to solve a basic 1D Ordinary Differential Equation (ODE) with a QNN using Differentiable Quantum Circuits (DQC) <sup>1</sup>.</p> <p>Consider the following non-linear ODE and boundary condition:</p> \\[ \\frac{df}{dx}= 5\\times(4x^3+x^2-2x-\\frac12), \\qquad f(0)=0 \\] <p>It admits an exact solution:</p> \\[ f(x)=5\\times(x^4+\\frac13x^3-x^2-\\frac12x) \\] <p>Our goal will be to find this solution for \\(x\\in[-1, 1]\\).</p> <pre><code>import torch\n\ndef dfdx_equation(x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Derivative as per the equation.\"\"\"\n    return 5*(4*x**3 + x**2 - 2*x - 0.5)\n</code></pre> <p>For the purpose of this tutorial, we will compute the derivative of the circuit using <code>torch.autograd</code>. The point of the DQC algorithm is to use differentiable circuits with parameter shift rules. In Qadence, PSR is implemented directly as custom overrides of the derivative function in the autograd engine, and thus we can later change the derivative method for the model itself if we wish.</p> <pre><code>def calc_deriv(outputs: torch.Tensor, inputs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Compute a derivative of model that learns f(x), computes df/dx using torch.autograd.\"\"\"\n    grad = torch.autograd.grad(\n        outputs=outputs,\n        inputs=inputs,\n        grad_outputs = torch.ones_like(inputs),\n        create_graph = True,\n        retain_graph = True,\n    )[0]\n    return grad\n</code></pre>"},{"location":"model/tutorials/dqc_1d/#defining-the-loss-function","title":"Defining the loss function","text":"<p>The essential part of solving this problem is to define the right loss function to represent our goal. In this case, we want to define a model that has the capacity to learn the target solution, and we want to minimize: - The derivative of this model in comparison with the exact derivative in the equation; - The output of the model at the boundary in comparison with the value for the boundary condition;</p> <p>We can write it like so:</p> <pre><code># Mean-squared error as the comparison criterion\ncriterion = torch.nn.MSELoss()\n\ndef loss_fn(model: torch.nn.Module, inputs: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Loss function encoding the problem to solve.\"\"\"\n    # Equation loss\n    model_output = model(inputs)\n    deriv_model = calc_deriv(model_output, inputs)\n    deriv_exact = dfdx_equation(inputs)\n    ode_loss = criterion(deriv_model, deriv_exact)\n\n    # Boundary loss, f(0) = 0\n    boundary_model = model(torch.tensor([[0.0]]))\n    boundary_exact = torch.tensor([[0.0]])\n    boundary_loss = criterion(boundary_model, boundary_exact)\n\n    return ode_loss + boundary_loss\n</code></pre> <p>Different loss criterions could be considered, and we could also play with the balance between the sum of the two loss terms. For now, let's proceed with the definition above.</p> <p>Note that so far we have not used any quantum specific assumption, and we could in principle use the same loss function with a classical neural network.</p>"},{"location":"model/tutorials/dqc_1d/#defining-a-qnn-with-qadence-model","title":"Defining a QNN with Qadence-Model","text":"<p>Now, we can finally use Qadence-Model to write a QNN. We will use a feature map to encode the input values, a trainable ansatz circuit, and an observable to measure as the output.</p> <pre><code>from qadence import feature_map, hea, chain, QuantumCircuit, Z\nfrom qadence_model.models import QNN\nfrom qadence.types import BasisSet, ReuploadScaling\n\nn_qubits = 3\ndepth = 3\n\n# Feature map\nfm = feature_map(\n    n_qubits = n_qubits,\n    param = \"x\",\n    fm_type = BasisSet.CHEBYSHEV,\n    reupload_scaling = ReuploadScaling.TOWER,\n)\n\n# Ansatz\nansatz = hea(n_qubits = n_qubits, depth = depth)\n\n# Observable\nobservable = Z(0)\n\ncircuit = QuantumCircuit(n_qubits, chain(fm, ansatz))\nmodel = QNN(circuit = circuit, observable = observable, inputs = [\"x\"])\n</code></pre> <p>We used a Chebyshev feature map with a tower-like scaling of the input reupload, and a standard hardware-efficient ansatz. In the observable, for now we consider the simple case of measuring the magnetization of the first qubit.</p> <pre><code>from qadence.draw import display\n\n# display(circuit)\n</code></pre> %3 cluster_2dc9d24b76134c8b8ca948a8f7c96dde HEA cluster_0c588953958a41faa16e8c2c28d103c6 Tower Chebyshev FM 08d0816da72540edbb798d20c05c496d 0 f5e970470edb4196b3a8da6bdd01a928 RX(1.0*acos(x)) 08d0816da72540edbb798d20c05c496d--f5e970470edb4196b3a8da6bdd01a928 41eed2a162c94a60941acf1182bdd238 1 aa4735962aae44588aaee5be90f83f64 RX(theta\u2080) f5e970470edb4196b3a8da6bdd01a928--aa4735962aae44588aaee5be90f83f64 a248a7e0f7b24f57990fcdbe259446f3 RY(theta\u2083) aa4735962aae44588aaee5be90f83f64--a248a7e0f7b24f57990fcdbe259446f3 08b3f58a2cd64ff8b8d718ff68755980 RX(theta\u2086) a248a7e0f7b24f57990fcdbe259446f3--08b3f58a2cd64ff8b8d718ff68755980 628dd09428074d71af63de7f65ebceb0 08b3f58a2cd64ff8b8d718ff68755980--628dd09428074d71af63de7f65ebceb0 c802890e96d743b09110ff1cd0802b8e 628dd09428074d71af63de7f65ebceb0--c802890e96d743b09110ff1cd0802b8e 6d1ea780303c4acfaf5fbbbcf3721109 RX(theta\u2089) c802890e96d743b09110ff1cd0802b8e--6d1ea780303c4acfaf5fbbbcf3721109 db76746f2c2b44edad46b67d7f69f12f RY(theta\u2081\u2082) 6d1ea780303c4acfaf5fbbbcf3721109--db76746f2c2b44edad46b67d7f69f12f 3b589b7bc4b646f8ad2fc3e7eab92a7a RX(theta\u2081\u2085) db76746f2c2b44edad46b67d7f69f12f--3b589b7bc4b646f8ad2fc3e7eab92a7a e8e8130f844546a294870beeeb6d481e 3b589b7bc4b646f8ad2fc3e7eab92a7a--e8e8130f844546a294870beeeb6d481e 0b3efe5bb0ef48d1bcfa983bb6a80117 e8e8130f844546a294870beeeb6d481e--0b3efe5bb0ef48d1bcfa983bb6a80117 a0dbd4bc000a4f28b8bb755633e57f38 RX(theta\u2081\u2088) 0b3efe5bb0ef48d1bcfa983bb6a80117--a0dbd4bc000a4f28b8bb755633e57f38 5bf93ad92d634942a9a7a6b59b8ac306 RY(theta\u2082\u2081) a0dbd4bc000a4f28b8bb755633e57f38--5bf93ad92d634942a9a7a6b59b8ac306 d1cf44d2a92d4accbfa46b3525563030 RX(theta\u2082\u2084) 5bf93ad92d634942a9a7a6b59b8ac306--d1cf44d2a92d4accbfa46b3525563030 c689ea95f3244f77903214ffc5ef7852 d1cf44d2a92d4accbfa46b3525563030--c689ea95f3244f77903214ffc5ef7852 0d6f99c554cc4c64ae5559ce36fb7246 c689ea95f3244f77903214ffc5ef7852--0d6f99c554cc4c64ae5559ce36fb7246 f5e899f208cc49c291a3664e20ec63a4 0d6f99c554cc4c64ae5559ce36fb7246--f5e899f208cc49c291a3664e20ec63a4 3ea74ac6e341470fa6716cee2b26ce9f 045f26ed9e534aa7b0c139b79cd9bead RX(2.0*acos(x)) 41eed2a162c94a60941acf1182bdd238--045f26ed9e534aa7b0c139b79cd9bead 1d04af2186474c7bb27078fa3c134f4c 2 cf62991955a24f9a8842f8de9b8548c8 RX(theta\u2081) 045f26ed9e534aa7b0c139b79cd9bead--cf62991955a24f9a8842f8de9b8548c8 0aef991e64c648d3a71d88f76650125e RY(theta\u2084) cf62991955a24f9a8842f8de9b8548c8--0aef991e64c648d3a71d88f76650125e a502313b3b1144bcbdb03d482582d28e RX(theta\u2087) 0aef991e64c648d3a71d88f76650125e--a502313b3b1144bcbdb03d482582d28e 025e9bbbcfee4973aa8161d23ca75282 X a502313b3b1144bcbdb03d482582d28e--025e9bbbcfee4973aa8161d23ca75282 025e9bbbcfee4973aa8161d23ca75282--628dd09428074d71af63de7f65ebceb0 14919d4e65694fb49314269afdd11880 025e9bbbcfee4973aa8161d23ca75282--14919d4e65694fb49314269afdd11880 ddf51b4e44e84484aaf3968712fae2c4 RX(theta\u2081\u2080) 14919d4e65694fb49314269afdd11880--ddf51b4e44e84484aaf3968712fae2c4 8ea11a9f1c584ae7ba2e13b9acea8af8 RY(theta\u2081\u2083) ddf51b4e44e84484aaf3968712fae2c4--8ea11a9f1c584ae7ba2e13b9acea8af8 fd692759db004a8c9829d2c3800c55de RX(theta\u2081\u2086) 8ea11a9f1c584ae7ba2e13b9acea8af8--fd692759db004a8c9829d2c3800c55de e4bc49faa7524cada8a3edf7bf824b29 X fd692759db004a8c9829d2c3800c55de--e4bc49faa7524cada8a3edf7bf824b29 e4bc49faa7524cada8a3edf7bf824b29--e8e8130f844546a294870beeeb6d481e aea230560aaa4fe6ac994cdce74f7f16 e4bc49faa7524cada8a3edf7bf824b29--aea230560aaa4fe6ac994cdce74f7f16 400477dd3950414f80e35719568c66f3 RX(theta\u2081\u2089) aea230560aaa4fe6ac994cdce74f7f16--400477dd3950414f80e35719568c66f3 06a4be68aafd4744a021cbc79a5f6732 RY(theta\u2082\u2082) 400477dd3950414f80e35719568c66f3--06a4be68aafd4744a021cbc79a5f6732 ee4cee3e95f84168a906bfa2af1f7183 RX(theta\u2082\u2085) 06a4be68aafd4744a021cbc79a5f6732--ee4cee3e95f84168a906bfa2af1f7183 b2e10ce845b54fd18912480ea1dbf2e9 X ee4cee3e95f84168a906bfa2af1f7183--b2e10ce845b54fd18912480ea1dbf2e9 b2e10ce845b54fd18912480ea1dbf2e9--c689ea95f3244f77903214ffc5ef7852 8aee085da9d144b5b85da41c29d6a7bc b2e10ce845b54fd18912480ea1dbf2e9--8aee085da9d144b5b85da41c29d6a7bc 8aee085da9d144b5b85da41c29d6a7bc--3ea74ac6e341470fa6716cee2b26ce9f 0f20744f4f3e4e758b72df1311152021 26379b97aea642018230e2afb15af309 RX(3.0*acos(x)) 1d04af2186474c7bb27078fa3c134f4c--26379b97aea642018230e2afb15af309 51a1a565e2a5428fb242ae1300aa96d6 RX(theta\u2082) 26379b97aea642018230e2afb15af309--51a1a565e2a5428fb242ae1300aa96d6 a3e5a78e03064abcab679c3a6b147b69 RY(theta\u2085) 51a1a565e2a5428fb242ae1300aa96d6--a3e5a78e03064abcab679c3a6b147b69 fe33fb6003b8460e90024b47f1dbdf6f RX(theta\u2088) a3e5a78e03064abcab679c3a6b147b69--fe33fb6003b8460e90024b47f1dbdf6f a40ab4dc19984bff94def6a888491619 fe33fb6003b8460e90024b47f1dbdf6f--a40ab4dc19984bff94def6a888491619 5d472b829b564ac0aa390db3d74a9377 X a40ab4dc19984bff94def6a888491619--5d472b829b564ac0aa390db3d74a9377 5d472b829b564ac0aa390db3d74a9377--14919d4e65694fb49314269afdd11880 0ba9cc495d3346888d4f4eb65c1db9fc RX(theta\u2081\u2081) 5d472b829b564ac0aa390db3d74a9377--0ba9cc495d3346888d4f4eb65c1db9fc 438267d1b6b1461388ed417f6bce15db RY(theta\u2081\u2084) 0ba9cc495d3346888d4f4eb65c1db9fc--438267d1b6b1461388ed417f6bce15db e2c7fdf9f49942cea103042d221d59fd RX(theta\u2081\u2087) 438267d1b6b1461388ed417f6bce15db--e2c7fdf9f49942cea103042d221d59fd 9caaeb5847764914a532f9fb9f81d1ac e2c7fdf9f49942cea103042d221d59fd--9caaeb5847764914a532f9fb9f81d1ac 6af0d2c56c6a4bd8b02a80e468332c2d X 9caaeb5847764914a532f9fb9f81d1ac--6af0d2c56c6a4bd8b02a80e468332c2d 6af0d2c56c6a4bd8b02a80e468332c2d--aea230560aaa4fe6ac994cdce74f7f16 dbceb9ab2a214ab8b1e1e3f0f0ee164a RX(theta\u2082\u2080) 6af0d2c56c6a4bd8b02a80e468332c2d--dbceb9ab2a214ab8b1e1e3f0f0ee164a afd5b547e071417cb135673b02762cc7 RY(theta\u2082\u2083) dbceb9ab2a214ab8b1e1e3f0f0ee164a--afd5b547e071417cb135673b02762cc7 5d954137741c464ba1aeb7b2964ee9ba RX(theta\u2082\u2086) afd5b547e071417cb135673b02762cc7--5d954137741c464ba1aeb7b2964ee9ba f4d704eafd664c2882490bdd08e527c5 5d954137741c464ba1aeb7b2964ee9ba--f4d704eafd664c2882490bdd08e527c5 116241e2ccbc41e8951eef639d1f12e6 X f4d704eafd664c2882490bdd08e527c5--116241e2ccbc41e8951eef639d1f12e6 116241e2ccbc41e8951eef639d1f12e6--8aee085da9d144b5b85da41c29d6a7bc 116241e2ccbc41e8951eef639d1f12e6--0f20744f4f3e4e758b72df1311152021"},{"location":"model/tutorials/dqc_1d/#training-the-model","title":"Training the model","text":"<p>Now that the model is defined we can proceed with the training. the <code>QNN</code> class can be used like any other <code>torch.nn.Module</code>.</p> <p>To train the model, we will select a random set of collocation points uniformly distributed within \\(-1.0&lt; x &lt;1.0\\) and compute the loss function for those points.</p> <pre><code>n_epochs = 200\nn_points = 10\n\nxmin = -0.99\nxmax = 0.99\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n\nfor epoch in range(n_epochs):\n    optimizer.zero_grad()\n\n    # Training data. We unsqueeze essentially making each batch have a single x value.\n    x_train = (xmin + (xmax-xmin)*torch.rand(n_points, requires_grad = True)).unsqueeze(1)\n\n    loss = loss_fn(inputs = x_train, model = model)\n    loss.backward()\n    optimizer.step()\n</code></pre> <p>Note the values of \\(x\\) are only picked from \\(x\\in[-0.99, 0.99]\\) since we are using a Chebyshev feature map, and derivative of \\(\\text{acos}(x)\\) diverges at \\(-1\\) and \\(1\\).</p>"},{"location":"model/tutorials/dqc_1d/#plotting-the-results","title":"Plotting the results","text":"<pre><code>import matplotlib.pyplot as plt\n\ndef f_exact(x: torch.Tensor) -&gt; torch.Tensor:\n    return 5*(x**4 + (1/3)*x**3 - x**2 - 0.5*x)\n\nx_test = torch.arange(xmin, xmax, step = 0.01).unsqueeze(1)\n\nresult_exact = f_exact(x_test).flatten()\n\nresult_model = model(x_test).flatten().detach()\n\nplt.plot(x_test, result_exact, label = \"Exact solution\")\nplt.plot(x_test, result_model, label = \" Trained model\")\n</code></pre> 2025-06-12T18:23:52.659603 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/ <p>Clearly, the result is not optimal.</p>"},{"location":"model/tutorials/dqc_1d/#improving-the-solution","title":"Improving the solution","text":"<p>One point to consider when defining the QNN is the possible output range, which is bounded by the spectrum of the chosen observable. For the magnetization of a single qubit, this means that the output is bounded between -1 and 1, which we can clearly see in the plot.</p> <p>One option would be to define the observable as the total magnetization over all qubits, which would allow a range of -3 to 3.</p> <pre><code>from qadence import add\n\nobservable = add(Z(i) for i in range(n_qubits))\n\nmodel = QNN(circuit = circuit, observable = observable, inputs = [\"x\"])\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n\nfor epoch in range(n_epochs):\n    optimizer.zero_grad()\n\n    # Training data\n    x_train = (xmin + (xmax-xmin)*torch.rand(n_points, requires_grad = True)).unsqueeze(1)\n\n    loss = loss_fn(inputs = x_train, model = model)\n    loss.backward()\n    optimizer.step()\n</code></pre> <p>And we again plot the result:</p> <pre><code>x_test = torch.arange(xmin, xmax, step = 0.01).unsqueeze(1)\n\nresult_exact = f_exact(x_test).flatten()\n\nresult_model = model(x_test).flatten().detach()\n\nplt.plot(x_test, result_exact, label = \"Exact solution\")\nplt.plot(x_test, result_model, label = \"Trained model\")\n</code></pre> 2025-06-12T18:24:00.728576 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"model/tutorials/dqc_1d/#references","title":"References","text":"<ol> <li> <p>Kyriienko et al., Solving nonlinear differential equations with differentiable quantum circuits. \u21a9</p> </li> </ol>"},{"location":"model/tutorials/perceptrain/","title":"What is Perceptrain?","text":"<p><code>Perceptrain</code> is a lightweight and flexible training framework built to simplify model training \u2014 from local CPU to multi-GPU distributed environments. It is especially suited for research and prototyping, offering modularity and plug-and-play components such as optimizers, loggers, and callbacks.</p>"},{"location":"model/tutorials/perceptrain/#what-does-perceptrain-offer","title":"What does Perceptrain offer?","text":"<p>Key Functionalities:     \u2022 Seamless multi-GPU / multi-node training via Accelerator abstraction     \u2022 Built-in support for both gradient-based and gradient-free optimization     \u2022 Easy experiment tracking with TensorBoard and MLflow     \u2022 YAML or Python-based configuration via TrainConfig     \u2022 Customizable training loop via Trainer and callback hooks</p> <p>Whether you\u2019re developing a deep learning model or experimenting with new training techniques, <code>Perceptrain</code> helps you iterate faster and more reliably.</p>"},{"location":"model/tutorials/perceptrain/#how-can-we-use-it","title":"How can we use it?","text":"<p>The detailed documentation can be (found here)[https://pasqal-io.github.io/perceptrain/latest/]. Below, we show a classification example of using <code>Trainer</code> in <code>Perceptrain</code>.</p>"},{"location":"model/tutorials/perceptrain/#quantum-classification-with-perceptrain","title":"Quantum Classification with Perceptrain","text":"<p>In this tutorial we will show how to use Qadence-Model and Perceptrain to solve a basic classification task using a hybrid quantum-classical model composed of a QNN and classical layers.</p>"},{"location":"model/tutorials/perceptrain/#dataset","title":"Dataset","text":"<p>We will use the Iris dataset separated into training and testing sets. The task is to classify iris plants presented as a multivariate dataset of 4 features into 3 labels (Iris Setosa, Iris Versicolour, or Iris Virginica). When applying machine learning models, and particularly neural networks, it is recommended to normalize the data. As such, we use a common StandardScaler (we transform the data \\(x\\) to \\(z = (x - u) / s\\) where \\(u, s\\) are respectively the mean and standard deviation of the training samples).</p> <pre><code>import random\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom torch import Tensor\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom qadence import RX, FeatureParameter, QuantumCircuit, Z, chain, hea, kron\nfrom qadence_model.models import QNN\nfrom perceptrain import TrainConfig, Trainer\n\nclass IrisDataset(Dataset):\n    \"\"\"The Iris dataset split into a training set and a test set.\n\n    A StandardScaler is applied prior to applying models.\n    \"\"\"\n\n    def __init__(self):\n        X, y = load_iris(return_X_y=True)\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n        self.scaler = StandardScaler()\n        self.scaler.fit(X_train)\n        self.X = torch.tensor(self.scaler.transform(X_train), requires_grad=False)\n        self.y = torch.tensor(y_train, requires_grad=False)\n\n        self.X_test = torch.tensor(self.scaler.transform(X_test), requires_grad=False)\n        self.y_test = torch.tensor(y_test, requires_grad=False)\n\n    def __getitem__(self, index) -&gt; tuple[Tensor, Tensor]:\n        return self.X[index], self.y[index]\n\n    def __len__(self) -&gt; int:\n        return len(self.y)\n\nn_features = 4  # sepal length, sepal width, petal length, petal width\nn_layers = 3\nn_neurons_final_linear_layer = 3\nn_epochs = 1000\nlr = 1e-1\ndataset = IrisDataset()\n\ndataloader = DataLoader(dataset, batch_size=20, shuffle=True)\n</code></pre>"},{"location":"model/tutorials/perceptrain/#hybrid-qnn","title":"Hybrid QNN","text":"<p>We set up the QNN part composed of multiple feature map layers, each followed by a variational layer. The type of variational layer we use is the hardware-efficient-ansatz (HEA). The output will be the expectation value with respect to a \\(Z\\) observable on qubit \\(0\\). Then we add a simple linear layer serving as a classification head. This is equivalent to applying a weight matrix \\(W\\) and bias vector \\(b\\) to the output of the QNN denoted \\(o\\), \\(l = W * o + b\\). To obtain probabilities, we can apply the softmax function defined as: \\(p_i = \\exp(l_i) / \\sum_{j=1}^3 \\exp(l_i)\\). Note softmax is not applied during training with the cross-entropy loss.</p> <pre><code>feature_parameters = [FeatureParameter(f\"x_{i}\") for i in range(n_features)]\nfm_layer = RX(0, feature_parameters[0])\nfor q in range(1, n_features):\n    fm_layer = kron(fm_layer, RX(q, feature_parameters[q]))\n\nansatz_layers = [\n    hea(n_qubits=n_features, depth=1, param_prefix=f\"theta_{layer}\")\n    for layer in range(n_layers)\n]\nblocks = chain(fm_layer, ansatz_layers[0])\nfor layer in range(1, n_layers):\n    blocks = chain(blocks, fm_layer, ansatz_layers[layer])\n\nqc = QuantumCircuit(n_features, blocks)\nqnn = QNN(circuit=qc, observable=Z(0), inputs=[f\"x_{i}\" for i in range(n_features)])\nmodel = nn.Sequential(qnn, nn.Linear(1, n_neurons_final_linear_layer))\n</code></pre> <p>Below is a visualization of the QNN:</p> <pre><code>\n</code></pre> %3 cluster_1c021f9a19894049bf47f6c7623ffd84 HEA cluster_33c8db5417ce428d9ebbee3e27ea5ef3 Obs. cluster_aab2cce14800400d87b9bed9388b391e HEA cluster_8979127c90ee47ce86a4845f3b021034 HEA 447cbcbc5dbd4f13a84e66d8d0189ccb 0 1989e4c053784c4ba9c83473050d9cc6 RX(x\u2080) 447cbcbc5dbd4f13a84e66d8d0189ccb--1989e4c053784c4ba9c83473050d9cc6 0b6d49fe422f4ba0b2a5b5a946f18207 1 e77c484b8d2740ea867c994b600aba5d RX(theta\u2080\u2080) 1989e4c053784c4ba9c83473050d9cc6--e77c484b8d2740ea867c994b600aba5d aef0f0e2d3034dbb8589b43a33bf9571 RY(theta\u2080\u2084) e77c484b8d2740ea867c994b600aba5d--aef0f0e2d3034dbb8589b43a33bf9571 5330c7cd9ef843dfb079562e3a1980f9 RX(theta\u2080\u2088) aef0f0e2d3034dbb8589b43a33bf9571--5330c7cd9ef843dfb079562e3a1980f9 b07e480ea7f84fddaced2b61db2f1796 5330c7cd9ef843dfb079562e3a1980f9--b07e480ea7f84fddaced2b61db2f1796 b608ff9a09794a97a1eb7d167b90fd11 b07e480ea7f84fddaced2b61db2f1796--b608ff9a09794a97a1eb7d167b90fd11 64a33aeeb7d44c6cbaf07a966654b71c RX(x\u2080) b608ff9a09794a97a1eb7d167b90fd11--64a33aeeb7d44c6cbaf07a966654b71c 07cecb58ff6c40a48ef5d63b19865aa4 RX(theta\u2081\u2080) 64a33aeeb7d44c6cbaf07a966654b71c--07cecb58ff6c40a48ef5d63b19865aa4 10248c754f24481580c8d3fcf1ae0157 RY(theta\u2081\u2084) 07cecb58ff6c40a48ef5d63b19865aa4--10248c754f24481580c8d3fcf1ae0157 24369ff13578407cb2e908e84dc6d385 RX(theta\u2081\u2088) 10248c754f24481580c8d3fcf1ae0157--24369ff13578407cb2e908e84dc6d385 4cabbfa4249a4093a87f35fbe2e19ff3 24369ff13578407cb2e908e84dc6d385--4cabbfa4249a4093a87f35fbe2e19ff3 8270f7d9d368437fb7cef7b376653841 4cabbfa4249a4093a87f35fbe2e19ff3--8270f7d9d368437fb7cef7b376653841 32c6cc2bdd0c4633a06b00d2c2aa159c RX(x\u2080) 8270f7d9d368437fb7cef7b376653841--32c6cc2bdd0c4633a06b00d2c2aa159c a77a6541c219476f93d307aeac1c2cb6 RX(theta\u2082\u2080) 32c6cc2bdd0c4633a06b00d2c2aa159c--a77a6541c219476f93d307aeac1c2cb6 e7d010e33caf402ca64fc28146c0a154 RY(theta\u2082\u2084) a77a6541c219476f93d307aeac1c2cb6--e7d010e33caf402ca64fc28146c0a154 519e81d61d2e41bdb6f3877960650bfc RX(theta\u2082\u2088) e7d010e33caf402ca64fc28146c0a154--519e81d61d2e41bdb6f3877960650bfc f8b07d51965d4b149636357e18182866 519e81d61d2e41bdb6f3877960650bfc--f8b07d51965d4b149636357e18182866 884f471d6c0443ea844400de71f28ffb f8b07d51965d4b149636357e18182866--884f471d6c0443ea844400de71f28ffb d402a58e99fe4efbbdd6d0c73c97acee Z 884f471d6c0443ea844400de71f28ffb--d402a58e99fe4efbbdd6d0c73c97acee 472d9fa05e284f97a47884a6968d7fcd d402a58e99fe4efbbdd6d0c73c97acee--472d9fa05e284f97a47884a6968d7fcd 2049c3a848374cb886afab386d4349fd ddf60a582802490c94b17402dbf7a11f RX(x\u2081) 0b6d49fe422f4ba0b2a5b5a946f18207--ddf60a582802490c94b17402dbf7a11f 6c50da56dd3446cb866aad5b2a6992b5 2 d3a71e29bc744c50b8cf8e03dc1cfabe RX(theta\u2080\u2081) ddf60a582802490c94b17402dbf7a11f--d3a71e29bc744c50b8cf8e03dc1cfabe 456b9f3468ec46df9b2b302a17f9224b RY(theta\u2080\u2085) d3a71e29bc744c50b8cf8e03dc1cfabe--456b9f3468ec46df9b2b302a17f9224b 2dc3bd8332ef4665a0b6abff98ec75c9 RX(theta\u2080\u2089) 456b9f3468ec46df9b2b302a17f9224b--2dc3bd8332ef4665a0b6abff98ec75c9 f89d59c5742f4f3c84d5d8217470c1f4 X 2dc3bd8332ef4665a0b6abff98ec75c9--f89d59c5742f4f3c84d5d8217470c1f4 f89d59c5742f4f3c84d5d8217470c1f4--b07e480ea7f84fddaced2b61db2f1796 18de95e3931943308b86f3cd505f8708 f89d59c5742f4f3c84d5d8217470c1f4--18de95e3931943308b86f3cd505f8708 d5ae0ad1f15f4d91bb667d6ad4645a3c RX(x\u2081) 18de95e3931943308b86f3cd505f8708--d5ae0ad1f15f4d91bb667d6ad4645a3c 0c20c052019e4b4ba309a231f35577b0 RX(theta\u2081\u2081) d5ae0ad1f15f4d91bb667d6ad4645a3c--0c20c052019e4b4ba309a231f35577b0 5d4d06d76ee443ae981acc9a32baaa3d RY(theta\u2081\u2085) 0c20c052019e4b4ba309a231f35577b0--5d4d06d76ee443ae981acc9a32baaa3d 1daf919e57224022b048c3881f4db0a7 RX(theta\u2081\u2089) 5d4d06d76ee443ae981acc9a32baaa3d--1daf919e57224022b048c3881f4db0a7 82ac8dfb6cbb477193fa3d97800c57d9 X 1daf919e57224022b048c3881f4db0a7--82ac8dfb6cbb477193fa3d97800c57d9 82ac8dfb6cbb477193fa3d97800c57d9--4cabbfa4249a4093a87f35fbe2e19ff3 139872877ab24ce190599859fe45f1b9 82ac8dfb6cbb477193fa3d97800c57d9--139872877ab24ce190599859fe45f1b9 f7c8525e6b234257b6600e0c8bc9a47d RX(x\u2081) 139872877ab24ce190599859fe45f1b9--f7c8525e6b234257b6600e0c8bc9a47d f79d1ab3fb404426aea4eb51767e0d6b RX(theta\u2082\u2081) f7c8525e6b234257b6600e0c8bc9a47d--f79d1ab3fb404426aea4eb51767e0d6b 9a8bce5609cb48918a5c7050843326ff RY(theta\u2082\u2085) f79d1ab3fb404426aea4eb51767e0d6b--9a8bce5609cb48918a5c7050843326ff 610d8fe721754f05bf9711c41041fb22 RX(theta\u2082\u2089) 9a8bce5609cb48918a5c7050843326ff--610d8fe721754f05bf9711c41041fb22 d24ca788f5424ca693788fd563be0b13 X 610d8fe721754f05bf9711c41041fb22--d24ca788f5424ca693788fd563be0b13 d24ca788f5424ca693788fd563be0b13--f8b07d51965d4b149636357e18182866 28d884e3ae4348e88a1347dab0c101bf d24ca788f5424ca693788fd563be0b13--28d884e3ae4348e88a1347dab0c101bf 10e2faa1819f487e868dd44fa116f36c 28d884e3ae4348e88a1347dab0c101bf--10e2faa1819f487e868dd44fa116f36c 10e2faa1819f487e868dd44fa116f36c--2049c3a848374cb886afab386d4349fd 866fa2620e8f4d249f1d3c2876d957f8 9f2a6a43aaa443e787b78a1a126c1532 RX(x\u2082) 6c50da56dd3446cb866aad5b2a6992b5--9f2a6a43aaa443e787b78a1a126c1532 34bbf7c6e8394eab8caf1309d9c976a1 3 316bc07163b34b2eabd0cc234982377d RX(theta\u2080\u2082) 9f2a6a43aaa443e787b78a1a126c1532--316bc07163b34b2eabd0cc234982377d f408342efa34476bbb4d7b26344fcf92 RY(theta\u2080\u2086) 316bc07163b34b2eabd0cc234982377d--f408342efa34476bbb4d7b26344fcf92 938967c5b8f34cc3a43cd5fe464e632c RX(theta\u2080\u2081\u2080) f408342efa34476bbb4d7b26344fcf92--938967c5b8f34cc3a43cd5fe464e632c 8690baa8caaa42c8b5c43c0ca6fe82fc 938967c5b8f34cc3a43cd5fe464e632c--8690baa8caaa42c8b5c43c0ca6fe82fc 5a2743d49da8485a94887760b44cb038 X 8690baa8caaa42c8b5c43c0ca6fe82fc--5a2743d49da8485a94887760b44cb038 5a2743d49da8485a94887760b44cb038--18de95e3931943308b86f3cd505f8708 d233f381e1c749bab1a22621941be233 RX(x\u2082) 5a2743d49da8485a94887760b44cb038--d233f381e1c749bab1a22621941be233 880c8bdbae224960a756d2f63ae08f99 RX(theta\u2081\u2082) d233f381e1c749bab1a22621941be233--880c8bdbae224960a756d2f63ae08f99 4b88d2e99545447aba12b8f2fefaade8 RY(theta\u2081\u2086) 880c8bdbae224960a756d2f63ae08f99--4b88d2e99545447aba12b8f2fefaade8 363b1ef9574946b3ad8f0f1649914065 RX(theta\u2081\u2081\u2080) 4b88d2e99545447aba12b8f2fefaade8--363b1ef9574946b3ad8f0f1649914065 bda4a46934e94760a445574934e1e35e 363b1ef9574946b3ad8f0f1649914065--bda4a46934e94760a445574934e1e35e d307ac91f1aa4656ab68da66110c4a7d X bda4a46934e94760a445574934e1e35e--d307ac91f1aa4656ab68da66110c4a7d d307ac91f1aa4656ab68da66110c4a7d--139872877ab24ce190599859fe45f1b9 648bf404e48c489d875683c1e8202dd1 RX(x\u2082) d307ac91f1aa4656ab68da66110c4a7d--648bf404e48c489d875683c1e8202dd1 1a31b2c1f334425b9ed6f065fa005eee RX(theta\u2082\u2082) 648bf404e48c489d875683c1e8202dd1--1a31b2c1f334425b9ed6f065fa005eee 3fdb39696f1140068ef23f0c8e68a34b RY(theta\u2082\u2086) 1a31b2c1f334425b9ed6f065fa005eee--3fdb39696f1140068ef23f0c8e68a34b d6e0c34925184014a6e17bfcc0c90c8d RX(theta\u2082\u2081\u2080) 3fdb39696f1140068ef23f0c8e68a34b--d6e0c34925184014a6e17bfcc0c90c8d be9982f74738491eb059fb724aa103d8 d6e0c34925184014a6e17bfcc0c90c8d--be9982f74738491eb059fb724aa103d8 bfe288174cf64bb680f254d905df2dc6 X be9982f74738491eb059fb724aa103d8--bfe288174cf64bb680f254d905df2dc6 bfe288174cf64bb680f254d905df2dc6--28d884e3ae4348e88a1347dab0c101bf a2590e29b5284bd0a514b0df0be48720 bfe288174cf64bb680f254d905df2dc6--a2590e29b5284bd0a514b0df0be48720 a2590e29b5284bd0a514b0df0be48720--866fa2620e8f4d249f1d3c2876d957f8 0e84c156bc5f4725bb1470f9347abb24 9f99700ed52c4deba4de9ff9ee02a3ca RX(x\u2083) 34bbf7c6e8394eab8caf1309d9c976a1--9f99700ed52c4deba4de9ff9ee02a3ca 46d78d03166c45c8845872fd81a21a68 RX(theta\u2080\u2083) 9f99700ed52c4deba4de9ff9ee02a3ca--46d78d03166c45c8845872fd81a21a68 521cb03b2861402ea9550f7c84e3c32f RY(theta\u2080\u2087) 46d78d03166c45c8845872fd81a21a68--521cb03b2861402ea9550f7c84e3c32f 7890a5c82b7d470bbebf5e61450c32c2 RX(theta\u2080\u2081\u2081) 521cb03b2861402ea9550f7c84e3c32f--7890a5c82b7d470bbebf5e61450c32c2 c8bdb9de9dc04241bb071dbb7e475ce3 X 7890a5c82b7d470bbebf5e61450c32c2--c8bdb9de9dc04241bb071dbb7e475ce3 c8bdb9de9dc04241bb071dbb7e475ce3--8690baa8caaa42c8b5c43c0ca6fe82fc 65acfe0ac88d4c02946ad3dc73e3230e c8bdb9de9dc04241bb071dbb7e475ce3--65acfe0ac88d4c02946ad3dc73e3230e 3b80f0c7c90b49ee94e26684ec63cdaf RX(x\u2083) 65acfe0ac88d4c02946ad3dc73e3230e--3b80f0c7c90b49ee94e26684ec63cdaf 3bf2719e6e034b24a5b0da41e4b94a40 RX(theta\u2081\u2083) 3b80f0c7c90b49ee94e26684ec63cdaf--3bf2719e6e034b24a5b0da41e4b94a40 094b9317ac1945e9805c6e421ad0bdc2 RY(theta\u2081\u2087) 3bf2719e6e034b24a5b0da41e4b94a40--094b9317ac1945e9805c6e421ad0bdc2 890e2d93d55a43d09c276809d0b8f3e4 RX(theta\u2081\u2081\u2081) 094b9317ac1945e9805c6e421ad0bdc2--890e2d93d55a43d09c276809d0b8f3e4 f937e59bc5df4496b3716178bf31a0c2 X 890e2d93d55a43d09c276809d0b8f3e4--f937e59bc5df4496b3716178bf31a0c2 f937e59bc5df4496b3716178bf31a0c2--bda4a46934e94760a445574934e1e35e fc2fee6a832e40c09c208a4608c91e84 f937e59bc5df4496b3716178bf31a0c2--fc2fee6a832e40c09c208a4608c91e84 e9baf067160944cea4ab6700e27735b7 RX(x\u2083) fc2fee6a832e40c09c208a4608c91e84--e9baf067160944cea4ab6700e27735b7 2b018ffa85c041f0b0220dbc0ca9cb00 RX(theta\u2082\u2083) e9baf067160944cea4ab6700e27735b7--2b018ffa85c041f0b0220dbc0ca9cb00 afb1dc0df96645f687616bbc07f1172d RY(theta\u2082\u2087) 2b018ffa85c041f0b0220dbc0ca9cb00--afb1dc0df96645f687616bbc07f1172d b587c06955ed4438a95cfbe3a74b2570 RX(theta\u2082\u2081\u2081) afb1dc0df96645f687616bbc07f1172d--b587c06955ed4438a95cfbe3a74b2570 9a7c9b1cb8ff4d869c6ca3d18b63efa4 X b587c06955ed4438a95cfbe3a74b2570--9a7c9b1cb8ff4d869c6ca3d18b63efa4 9a7c9b1cb8ff4d869c6ca3d18b63efa4--be9982f74738491eb059fb724aa103d8 0dfa7e342e8044a29eda182d8c009dbd 9a7c9b1cb8ff4d869c6ca3d18b63efa4--0dfa7e342e8044a29eda182d8c009dbd 84f3b6365ccf42a0bfda03ca4cadb1d4 0dfa7e342e8044a29eda182d8c009dbd--84f3b6365ccf42a0bfda03ca4cadb1d4 84f3b6365ccf42a0bfda03ca4cadb1d4--0e84c156bc5f4725bb1470f9347abb24"},{"location":"model/tutorials/perceptrain/#training","title":"Training","text":"<p>Then we can set up the training part:</p> <pre><code>opt = torch.optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()\n\ndef cross_entropy(model: nn.Module, data: Tensor) -&gt; tuple[Tensor, dict]:\n    x, y = data\n    out = model(x)\n    loss = criterion(out, y)\n    return loss, {}\n\ntrain_config = TrainConfig(max_iter=n_epochs, print_every=10, create_subfolder_per_run=True)\nTrainer.set_use_grad(True)\ntrainer = Trainer(model=model, optimizer=opt, config=train_config, loss_fn=cross_entropy)\n\n\nres_train = trainer.fit(dataloader)\n</code></pre>"},{"location":"model/tutorials/perceptrain/#inference","title":"Inference","text":"<p>Finally, we can apply our model on the test set and check the score.</p> <pre><code>X_test, y_test = dataset.X_test, dataset.y_test\npreds_test = torch.argmax(torch.softmax(model(X_test), dim=1), dim=1)\naccuracy_test = (preds_test == y_test).type(torch.float32).mean()\n## Should reach higher than 0.9\n</code></pre>   Test Accuracy: 0.9399999976158142"},{"location":"model/tutorials/qaoa/","title":"Solving MaxCut with QAOA","text":"<p>This tutorial shows how to solve the maximum cut (MaxCut) combinatorial optimization problem on a graph using the Quantum Approximate Optimization Algorithm (QAOA), first introduced by Farhi et al. in 2014 <sup>1</sup>.</p> <p>Given an arbitrary graph, the MaxCut problem consists in finding a graph cut which partitions the nodes into two disjoint sets, such that the number of edges in the cut is maximized. This is a very common combinatorial optimization problem known to be computationally hard (NP-hard).</p> <p>The graph used for this tutorial is an unweighted graph randomly generated using the <code>networkx</code> library with a certain probability \\(p\\) of having an edge between two arbitrary nodes (known as Erd\u0151s\u2013R\u00e9nyi graph).</p> <pre><code>import numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport random\n\n# ensure reproducibility\nseed = 42\nnp.random.seed(seed)\nrandom.seed(seed)\n\n# Create random graph\nn_nodes = 4\nedge_prob = 0.8\ngraph = nx.gnp_random_graph(n_nodes, edge_prob)\n\nnx.draw(graph)\n</code></pre> 2025-06-12T18:24:27.763686 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/ <p>The goal of the MaxCut algorithm is to maximize the following cost function:</p> \\[\\mathcal{C}(p) = \\sum_{\\alpha}^m \\mathcal{C}_{\\alpha}(p)\\] <p>where \\(p\\) is a given cut of the graph, \\(\\alpha\\) is an index over the edges and \\(\\mathcal{C}_{\\alpha}(p)\\) is written such that if the nodes connected by the \\(\\alpha\\) edge are in the same set, it returns \\(0\\), otherwise it returns \\(1\\). We will represent a cut \\(p\\) as a bitstring of length \\(N\\), where \\(N\\) is the number of nodes, and where the bit in position \\(i\\) shows to which partition node \\(i\\) belongs. We assign value 0 to one of the partitions defined by the cut and 1 to the other. Since this choice is arbitrary, every cut is represented by two bitstrings, e.g. \"0011\" and \"1100\" are equivalent.</p> <p>Since in this tutorial we are only dealing with small graphs, we can find the maximum cut by brute force to make sure QAOA works as intended. <pre><code># Function to calculate the cost associated with a cut\ndef calculate_cost(cut: str, graph: nx.graph) -&gt; float:\n    \"\"\"Returns the cost of a given cut (represented by a bitstring)\"\"\"\n    cost = 0\n    for edge in graph.edges():\n        (i, j) = edge\n        if cut[i] != cut[j]:\n            cost += 1\n    return cost\n\n\n# Function to get a binary representation of an int\nget_binary = lambda x, n: format(x, \"b\").zfill(n)\n\n# List of all possible cuts\nall_possible_cuts = [bin(k)[2:].rjust(n_nodes, \"0\") for k in range(2**n_nodes)]\n\n# List with the costs associated to each cut\nall_costs = [calculate_cost(cut, graph) for cut in all_possible_cuts]\n\n# Get the maximum cost\nmaxcost = max(all_costs)\n\n# Get all cuts that correspond to the maximum cost\nmaxcuts = [get_binary(i, n_nodes) for i, j in enumerate(all_costs) if j == maxcost]\nprint(f\"The maximum cut is represented by the bitstrings {maxcuts}, with a cost of {maxcost}\")\n</code></pre> <pre><code>The maximum cut is represented by the bitstrings ['0011', '0101', '0110', '1001', '1010', '1100'], with a cost of 4\n</code></pre> </p>"},{"location":"model/tutorials/qaoa/#the-qaoa-quantum-circuit","title":"The QAOA quantum circuit","text":"<p>The Max-Cut problem can be solved by using the QAOA algorithm. QAOA belongs to the class of Variational Quantum Algorithms (VQAs), which means that its quantum circuit contains a certain number of parametrized quantum gates that need to be optimized with a classical optimizer. The QAOA circuit is composed of two operators:</p> <ul> <li>The cost operator \\(U_c\\): a circuit generated by the cost Hamiltonian which encodes the cost function described above into a quantum circuit. The solution to the optimization problem is encoded in the ground state of the cost Hamiltonian \\(H_c\\). The cost operator  is simply the evolution of the cost Hamiltonian parametrized by a variational parameter \\(\\gamma\\) so that \\(U_c = e^{i\\gamma H_c}.\\)</li> <li>The mixing operator \\(U_b\\): a simple set of single-qubit rotations with adjustable   angles which are tuned during the classical optimization loop to minimize the cost</li> </ul> <p>The cost Hamiltonian of the MaxCut problem can be written as:</p> \\[H_c = \\frac12 \\sum_{\\langle i,j\\rangle} (\\mathbb{1} - Z_iZ_j)\\] <p>where \\(\\langle i,j\\rangle\\) represents the edge between nodes \\(i\\) and \\(j\\). The solution of the MaxCut problem is encoded in the ground state of the above Hamiltonian.</p> <p>The QAOA quantum circuit consists of a number of layers, each layer containing a cost and a mixing operator. Below, the QAOA quantum circuit is defined using <code>qadence</code> operations. First, a layer of Hadamard gates is applied to all qubits to prepare the initial state \\(|+\\rangle ^{\\otimes n}\\). The cost operator of each layer can be built \"manually\", implementing the \\(e^{iZZ\\gamma}\\) terms with CNOTs and a \\(\\rm{RZ}(2\\gamma)\\) rotation, or it can also be automatically decomposed into digital single and two-qubits operations via the <code>.digital_decomposition()</code> method. The decomposition is exact since the Hamiltonian generator is diagonal.</p> <pre><code>from qadence import tag, kron, chain, RX, RZ, Z, H, CNOT, I, add\nfrom qadence import HamEvo, QuantumCircuit, Parameter\n\nn_qubits = graph.number_of_nodes()\nn_edges = graph.number_of_edges()\nn_layers = 6\n\n# Generate the cost Hamiltonian\nzz_ops = add(Z(edge[0]) @ Z(edge[1]) for edge in graph.edges)\ncost_ham = 0.5 * (n_edges * kron(I(i) for i in range(n_qubits)) - zz_ops)\n\n\n# QAOA circuit\ndef build_qaoa_circuit(n_qubits, n_layers, graph):\n    layers = []\n    # Layer of Hadamards\n    initial_layer = kron(H(i) for i in range(n_qubits))\n    layers.append(initial_layer)\n    for layer in range(n_layers):\n\n        # cost layer with digital decomposition\n        # cost_layer = HamEvo(cost_ham, f\"g{layer}\").digital_decomposition(approximation=\"basic\")\n        cost_layer = []\n        for edge in graph.edges():\n            (q0, q1) = edge\n            zz_term = chain(\n                CNOT(q0, q1),\n                RZ(q1, Parameter(f\"g{layer}\")),\n                CNOT(q0, q1),\n            )\n            cost_layer.append(zz_term)\n        cost_layer = chain(*cost_layer)\n        cost_layer = tag(cost_layer, \"cost\")\n\n        # mixing layer with single qubit rotations\n        mixing_layer = kron(RX(i, f\"b{layer}\") for i in range(n_qubits))\n        mixing_layer = tag(mixing_layer, \"mixing\")\n\n        # putting all together in a single ChainBlock\n        layers.append(chain(cost_layer, mixing_layer))\n\n    final_b = chain(*layers)\n    return QuantumCircuit(n_qubits, final_b)\n\n\ncircuit = build_qaoa_circuit(n_qubits, n_layers, graph)\n\n# Print a single layer of the circuit\n</code></pre> %3 cluster_08af060e37794488a21e0b7395d5f7c8 mixing cluster_29bfcddb5b764c38adda8d19ec0dfbed cost 328512db9c104d5794b4ef3f33445346 0 c336b9e2773741d19613437d031a4a20 H 328512db9c104d5794b4ef3f33445346--c336b9e2773741d19613437d031a4a20 90348cf8427543f4b37fd55442de12b2 1 f2a485f0654840489be78fb87dcbeb02 c336b9e2773741d19613437d031a4a20--f2a485f0654840489be78fb87dcbeb02 4d4e6c56c85f497fa96002493f0c1d4a f2a485f0654840489be78fb87dcbeb02--4d4e6c56c85f497fa96002493f0c1d4a 1b7b0cf9b85d44d3baaed709f9367e12 4d4e6c56c85f497fa96002493f0c1d4a--1b7b0cf9b85d44d3baaed709f9367e12 5b954357e35d4912996004fa631f003e 1b7b0cf9b85d44d3baaed709f9367e12--5b954357e35d4912996004fa631f003e be4f5c5733c6479eb7268ea36435f2e3 5b954357e35d4912996004fa631f003e--be4f5c5733c6479eb7268ea36435f2e3 b141dbda3f4a4976b5e270784227cf36 be4f5c5733c6479eb7268ea36435f2e3--b141dbda3f4a4976b5e270784227cf36 f54328cfdfc147f8a82163039661f8e1 b141dbda3f4a4976b5e270784227cf36--f54328cfdfc147f8a82163039661f8e1 fcfd50668ce844578267c6b1632fdf8f f54328cfdfc147f8a82163039661f8e1--fcfd50668ce844578267c6b1632fdf8f ea29676722af4f2aab9565cbf656fb84 fcfd50668ce844578267c6b1632fdf8f--ea29676722af4f2aab9565cbf656fb84 9bfa79f800e84871a5416d0113824078 ea29676722af4f2aab9565cbf656fb84--9bfa79f800e84871a5416d0113824078 eb24a6d538f5474a830a5d6a89f8a453 9bfa79f800e84871a5416d0113824078--eb24a6d538f5474a830a5d6a89f8a453 5af7d3deb9b2470b9aa5a381fd7cbfb7 eb24a6d538f5474a830a5d6a89f8a453--5af7d3deb9b2470b9aa5a381fd7cbfb7 06a009e99eb645a99f92f804de224f14 5af7d3deb9b2470b9aa5a381fd7cbfb7--06a009e99eb645a99f92f804de224f14 429ea28f78f14862bbe828caa3f44e10 06a009e99eb645a99f92f804de224f14--429ea28f78f14862bbe828caa3f44e10 fa5bfb277fc64b13b474b9f0051e4d07 429ea28f78f14862bbe828caa3f44e10--fa5bfb277fc64b13b474b9f0051e4d07 6eecd7eb9fec4e48ba0921f55f6689fd fa5bfb277fc64b13b474b9f0051e4d07--6eecd7eb9fec4e48ba0921f55f6689fd 81f00e0e01374dc4b64fcbc364de595e 6eecd7eb9fec4e48ba0921f55f6689fd--81f00e0e01374dc4b64fcbc364de595e b3cb9563718847e09f5d46079bf75fbb 81f00e0e01374dc4b64fcbc364de595e--b3cb9563718847e09f5d46079bf75fbb 9e3dc53fa257441488e1b192da30d7b4 RX(b0) b3cb9563718847e09f5d46079bf75fbb--9e3dc53fa257441488e1b192da30d7b4 c5e66879321343428f7a93faa90e0789 9e3dc53fa257441488e1b192da30d7b4--c5e66879321343428f7a93faa90e0789 7a362d6bcb5748a0859391f4b619ce60 22833dbc9c874eceb63f44e1d72fd0a7 H 90348cf8427543f4b37fd55442de12b2--22833dbc9c874eceb63f44e1d72fd0a7 1b463e216bab40fea23c28e6ddd80110 2 99150a5ffeef4cb3a5bd80e66113857c X 22833dbc9c874eceb63f44e1d72fd0a7--99150a5ffeef4cb3a5bd80e66113857c 99150a5ffeef4cb3a5bd80e66113857c--f2a485f0654840489be78fb87dcbeb02 f1bf89ad43b647b496ff45fe8bd9b692 RZ(g0) 99150a5ffeef4cb3a5bd80e66113857c--f1bf89ad43b647b496ff45fe8bd9b692 3c589cd781e34dd1bd1bca065f393071 X f1bf89ad43b647b496ff45fe8bd9b692--3c589cd781e34dd1bd1bca065f393071 3c589cd781e34dd1bd1bca065f393071--1b7b0cf9b85d44d3baaed709f9367e12 ca199762ab0542aeb7da57823d46fd3e 3c589cd781e34dd1bd1bca065f393071--ca199762ab0542aeb7da57823d46fd3e fa1a79806781483583a5eeb9ed2ed894 ca199762ab0542aeb7da57823d46fd3e--fa1a79806781483583a5eeb9ed2ed894 fee9edc3c018428097fef741ea933603 fa1a79806781483583a5eeb9ed2ed894--fee9edc3c018428097fef741ea933603 a030c12fb3ed4a97ae123a203058e6bd fee9edc3c018428097fef741ea933603--a030c12fb3ed4a97ae123a203058e6bd 4b05fa633981430eb58f37a1941ece76 a030c12fb3ed4a97ae123a203058e6bd--4b05fa633981430eb58f37a1941ece76 4c2a836617d04aee9d232a7565084186 4b05fa633981430eb58f37a1941ece76--4c2a836617d04aee9d232a7565084186 bcb48bc8304245e8895c52e6e2f3dfcd 4c2a836617d04aee9d232a7565084186--bcb48bc8304245e8895c52e6e2f3dfcd a8764edef91447d2959f4f5fbee2ed68 bcb48bc8304245e8895c52e6e2f3dfcd--a8764edef91447d2959f4f5fbee2ed68 2f27f00f6b4845929c97ca182de10315 a8764edef91447d2959f4f5fbee2ed68--2f27f00f6b4845929c97ca182de10315 e30dc3ab4d3b4f718e91cd2b7baab42c 2f27f00f6b4845929c97ca182de10315--e30dc3ab4d3b4f718e91cd2b7baab42c 304aff35d7684241a7ad5acfbee08114 e30dc3ab4d3b4f718e91cd2b7baab42c--304aff35d7684241a7ad5acfbee08114 448b0894b7df42048fb5b691dcdf8c3f 304aff35d7684241a7ad5acfbee08114--448b0894b7df42048fb5b691dcdf8c3f 24d2d397169944599a9f127e949a2150 448b0894b7df42048fb5b691dcdf8c3f--24d2d397169944599a9f127e949a2150 8e321842ae3849ff9a654254833cf2cb 24d2d397169944599a9f127e949a2150--8e321842ae3849ff9a654254833cf2cb 22495d0d41484237aa59d7a18a0e1ec5 8e321842ae3849ff9a654254833cf2cb--22495d0d41484237aa59d7a18a0e1ec5 581284bb46904fc284bdcc3655ee0a0e RX(b0) 22495d0d41484237aa59d7a18a0e1ec5--581284bb46904fc284bdcc3655ee0a0e 581284bb46904fc284bdcc3655ee0a0e--7a362d6bcb5748a0859391f4b619ce60 0c66d4a8e11d439d9a670b3a361e0674 e8fd63db5b6b42e994df68d5fcff48f0 H 1b463e216bab40fea23c28e6ddd80110--e8fd63db5b6b42e994df68d5fcff48f0 24a6cf549e724adb8c1cd985e9a17b5b 3 cf088c73b999479db6e5fdb0e8a189d5 e8fd63db5b6b42e994df68d5fcff48f0--cf088c73b999479db6e5fdb0e8a189d5 53a6470bc49b469a890c6ae063ff703b cf088c73b999479db6e5fdb0e8a189d5--53a6470bc49b469a890c6ae063ff703b 647f928b5f23403ea5090fdd366ffae6 53a6470bc49b469a890c6ae063ff703b--647f928b5f23403ea5090fdd366ffae6 c1b717c14a654aedb4e6c3f27d7b1d02 X 647f928b5f23403ea5090fdd366ffae6--c1b717c14a654aedb4e6c3f27d7b1d02 c1b717c14a654aedb4e6c3f27d7b1d02--5b954357e35d4912996004fa631f003e fa3da9052e45488da59ea1c11dfca297 RZ(g0) c1b717c14a654aedb4e6c3f27d7b1d02--fa3da9052e45488da59ea1c11dfca297 f762c9a0a8f94a89a5494300faf570d1 X fa3da9052e45488da59ea1c11dfca297--f762c9a0a8f94a89a5494300faf570d1 f762c9a0a8f94a89a5494300faf570d1--b141dbda3f4a4976b5e270784227cf36 966ea16edd1c4bbc96d43099c6612a41 f762c9a0a8f94a89a5494300faf570d1--966ea16edd1c4bbc96d43099c6612a41 34ab3bf16b1a493393e2550e64ed0949 966ea16edd1c4bbc96d43099c6612a41--34ab3bf16b1a493393e2550e64ed0949 ae28a3b3634c48ab8b920f8475ec9017 34ab3bf16b1a493393e2550e64ed0949--ae28a3b3634c48ab8b920f8475ec9017 08e84cc38cd541f8a65c1dd1a69af248 X ae28a3b3634c48ab8b920f8475ec9017--08e84cc38cd541f8a65c1dd1a69af248 08e84cc38cd541f8a65c1dd1a69af248--bcb48bc8304245e8895c52e6e2f3dfcd bbe305027a354e70930b706d96bba223 RZ(g0) 08e84cc38cd541f8a65c1dd1a69af248--bbe305027a354e70930b706d96bba223 79d68781febb4875935f969c226cee23 X bbe305027a354e70930b706d96bba223--79d68781febb4875935f969c226cee23 79d68781febb4875935f969c226cee23--2f27f00f6b4845929c97ca182de10315 4ebc8e1315094f2b8fccb6fd794ee72b 79d68781febb4875935f969c226cee23--4ebc8e1315094f2b8fccb6fd794ee72b 154986c85295475d8d3b29c3c5d74c5d 4ebc8e1315094f2b8fccb6fd794ee72b--154986c85295475d8d3b29c3c5d74c5d dd01b7200d654792ac289f9f5a3ba260 154986c85295475d8d3b29c3c5d74c5d--dd01b7200d654792ac289f9f5a3ba260 99efebcab4cc486a9e38fe85af28ae54 dd01b7200d654792ac289f9f5a3ba260--99efebcab4cc486a9e38fe85af28ae54 2db9f66e1db64f2eb0d2b04e705451f6 99efebcab4cc486a9e38fe85af28ae54--2db9f66e1db64f2eb0d2b04e705451f6 f026d920b22544d3aa1a91508ce0bb7d 2db9f66e1db64f2eb0d2b04e705451f6--f026d920b22544d3aa1a91508ce0bb7d c5cce78b1a7448a285e9be07237d5ce6 RX(b0) f026d920b22544d3aa1a91508ce0bb7d--c5cce78b1a7448a285e9be07237d5ce6 c5cce78b1a7448a285e9be07237d5ce6--0c66d4a8e11d439d9a670b3a361e0674 545ecc28ed234e1bbbb0a4ed10ce14d4 d1c3525a9082441dbee0abe4d7f9e6d6 H 24a6cf549e724adb8c1cd985e9a17b5b--d1c3525a9082441dbee0abe4d7f9e6d6 b7124347160d4a8e9fdad274baa2f118 d1c3525a9082441dbee0abe4d7f9e6d6--b7124347160d4a8e9fdad274baa2f118 131139fc84e746ec9ac8758e7c6059ee b7124347160d4a8e9fdad274baa2f118--131139fc84e746ec9ac8758e7c6059ee d29b8607ec164041937a52ca756c646a 131139fc84e746ec9ac8758e7c6059ee--d29b8607ec164041937a52ca756c646a 304b5b7fc0504a2898ba51f3eddfed15 d29b8607ec164041937a52ca756c646a--304b5b7fc0504a2898ba51f3eddfed15 87d882535d2e43db81186ed99f93a06b 304b5b7fc0504a2898ba51f3eddfed15--87d882535d2e43db81186ed99f93a06b 0d24f48cb9774f66bac0f51667afbd46 87d882535d2e43db81186ed99f93a06b--0d24f48cb9774f66bac0f51667afbd46 8a3f60fe5dce4816be3c241272e0b8ab X 0d24f48cb9774f66bac0f51667afbd46--8a3f60fe5dce4816be3c241272e0b8ab 8a3f60fe5dce4816be3c241272e0b8ab--f54328cfdfc147f8a82163039661f8e1 e532b570406b4f529d01c624b2f84a32 RZ(g0) 8a3f60fe5dce4816be3c241272e0b8ab--e532b570406b4f529d01c624b2f84a32 cc659f39dd2548cc8b18984d588fb770 X e532b570406b4f529d01c624b2f84a32--cc659f39dd2548cc8b18984d588fb770 cc659f39dd2548cc8b18984d588fb770--ea29676722af4f2aab9565cbf656fb84 d9736accaa0f4384b8d62d6b7a3ab15b cc659f39dd2548cc8b18984d588fb770--d9736accaa0f4384b8d62d6b7a3ab15b 726b466527a747e3815128cf7bb7cf38 d9736accaa0f4384b8d62d6b7a3ab15b--726b466527a747e3815128cf7bb7cf38 a00c1c9a92324012bbbf2e7f982fb9b7 726b466527a747e3815128cf7bb7cf38--a00c1c9a92324012bbbf2e7f982fb9b7 cca199513c6943b3a3b68e2d50855623 X a00c1c9a92324012bbbf2e7f982fb9b7--cca199513c6943b3a3b68e2d50855623 cca199513c6943b3a3b68e2d50855623--e30dc3ab4d3b4f718e91cd2b7baab42c e828ec80d5534dfa9154ec69071e9788 RZ(g0) cca199513c6943b3a3b68e2d50855623--e828ec80d5534dfa9154ec69071e9788 4d3cc2db046f4854b32f4bf1a1d58244 X e828ec80d5534dfa9154ec69071e9788--4d3cc2db046f4854b32f4bf1a1d58244 4d3cc2db046f4854b32f4bf1a1d58244--448b0894b7df42048fb5b691dcdf8c3f ad73d6e3e64b43858ebadfaeccb42242 X 4d3cc2db046f4854b32f4bf1a1d58244--ad73d6e3e64b43858ebadfaeccb42242 ad73d6e3e64b43858ebadfaeccb42242--99efebcab4cc486a9e38fe85af28ae54 4cecf252c18e47aa869e661d2666da5b RZ(g0) ad73d6e3e64b43858ebadfaeccb42242--4cecf252c18e47aa869e661d2666da5b 4d791c7e447c4d47be85a00bf0165024 X 4cecf252c18e47aa869e661d2666da5b--4d791c7e447c4d47be85a00bf0165024 4d791c7e447c4d47be85a00bf0165024--f026d920b22544d3aa1a91508ce0bb7d 32fc169a9f1d4f089b1acda85acaf3fc RX(b0) 4d791c7e447c4d47be85a00bf0165024--32fc169a9f1d4f089b1acda85acaf3fc 32fc169a9f1d4f089b1acda85acaf3fc--545ecc28ed234e1bbbb0a4ed10ce14d4"},{"location":"model/tutorials/qaoa/#train-the-qaoa-circuit-to-solve-maxcut","title":"Train the QAOA circuit to solve MaxCut","text":"<p>Given the QAOA circuit above, one can construct the associated Qadence <code>QuantumModel</code> and train it using standard gradient based optimization.</p> <p>The loss function to be minimized reads:</p> \\[\\mathcal{L} =-\\langle \\psi | H_c| \\psi \\rangle= -\\frac12 \\sum_{\\langle i,j\\rangle}  \\left(1 - \\langle \\psi | Z_i Z_j | \\psi \\rangle \\right)\\] <p>where \\(|\\psi\\rangle(\\beta, \\gamma)\\) is the wavefunction obtained by running the QAQA quantum circuit and the sum runs over the edges of the graph \\(\\langle i,j\\rangle\\).</p> <pre><code>import torch\nfrom qadence import QuantumModel\n\ntorch.manual_seed(seed)\n\n\ndef loss_function(model: QuantumModel):\n    # The loss corresponds to the expectation\n    # value of the cost Hamiltonian\n    return -1.0 * model.expectation().squeeze()\n\n\n# initialize the parameters to random values\nmodel = QuantumModel(circuit, observable=cost_ham)\nmodel.reset_vparams(torch.rand(model.num_vparams))\ninitial_loss = loss_function(model)\nprint(f\"Initial loss: {initial_loss}\")\n\n# train the model\nn_epochs = 100\nlr = 0.1\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\nfor i in range(n_epochs):\n    optimizer.zero_grad()\n    loss = loss_function(model)\n    loss.backward()\n    optimizer.step()\n    if (i + 1) % (n_epochs // 10) == 0:\n        print(f\"MaxCut cost at iteration {i+1}: {-loss.item()}\")\n</code></pre> <pre><code>Initial loss: -2.1782381363858794\nMaxCut cost at iteration 10: 3.7470706807026417\nMaxCut cost at iteration 20: 3.8378810288930216\nMaxCut cost at iteration 30: 3.9424197899236133\nMaxCut cost at iteration 40: 3.9981256255766002\nMaxCut cost at iteration 50: 3.996470528508214\nMaxCut cost at iteration 60: 3.9991374608876606\nMaxCut cost at iteration 70: 3.9994678542919555\nMaxCut cost at iteration 80: 3.999872558672829\nMaxCut cost at iteration 90: 3.9999475834121063\nMaxCut cost at iteration 100: 3.9999793311641003\n</code></pre> <p>Qadence offers some convenience functions to implement this training loop with advanced logging and metrics track features.</p>"},{"location":"model/tutorials/qaoa/#results","title":"Results","text":"<p>Given the trained quantum model, one needs to sample the resulting quantum state to recover the bitstring with the highest probability which corresponds to the maximum cut of the graph.</p> <pre><code>samples = model.sample(n_shots=100)[0]\nmost_frequent = max(samples, key=samples.get)\n\nprint(f\"Most frequently sampled bitstring corresponding to the maximum cut: {most_frequent}\")\n\n# let's now draw the cut obtained with the QAOA procedure\ncolors = []\nlabels = {}\nfor node, b in zip(graph.nodes(), most_frequent):\n    colors.append(\"green\") if int(b) == 0 else colors.append(\"red\")\n    labels[node] = \"A\" if int(b) == 0 else \"B\"\n\nnx.draw_networkx(graph, node_color=colors, with_labels=True, labels=labels)\n</code></pre>   Most frequently sampled bitstring corresponding to the maximum cut: 1001  2025-06-12T18:24:32.168988 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"model/tutorials/qaoa/#references","title":"References","text":"<ol> <li> <p>Farhi et al. - A Quantum Approximate Optimization Algorithm\u00a0\u21a9</p> </li> </ol>"},{"location":"model/tutorials/qcl/","title":"Quantum Circuit Learning","text":"<p>This tutorial shows how to apply <code>qadenc-model</code> for solving a basic quantum machine learning application: fitting a simple function with the quantum circuit learning<sup>1</sup> (QCL) algorithm.</p> <p>QCL is a supervised quantum machine learning algorithm that uses a parametrized quantum neural network to learn the behavior of an arbitrary mathematical function using a set of function values as training data. This tutorial shows how to fit the \\(\\sin(x)\\) function in the \\([-1, 1]\\) domain.</p> <p>In the following, train and test data are defined.</p> <pre><code>import torch\nfrom torch.utils.data import random_split\n\n# make sure all tensors are kept on the same device\n# only available from PyTorch 2.0\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch.set_default_device(device)\n\ndef qcl_training_data(\n    domain: tuple = (0, 2*torch.pi), n_points: int = 200\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n\n    start, end = domain\n\n    x_rand, _ = torch.sort(torch.DoubleTensor(n_points).uniform_(start, end))\n    y_rand = torch.sin(x_rand)\n\n    return x_rand, y_rand\n\nx, y = qcl_training_data()\n\n# random train/test split of the dataset\ntrain_subset, test_subset = random_split(x, [0.75, 0.25])\ntrain_ind = sorted(train_subset.indices)\ntest_ind = sorted(test_subset.indices)\n\nx_train, y_train = x[train_ind], y[train_ind]\nx_test, y_test = x[test_ind], y[test_ind]\n</code></pre>"},{"location":"model/tutorials/qcl/#train-the-qcl-model","title":"Train the QCL model","text":"<p>Qadence-model provides the <code>QNN</code> convenience constructor to build a quantum neural network. The <code>QNN</code> class needs a circuit and a list of observables; the number of feature parameters in the input circuit determines the number of input features (i.e. the dimensionality of the classical data given as input) whereas the number of observables determines the number of outputs of the quantum neural network.</p> <p>Total qubit magnetization is used as observable:</p> \\[ \\hat{O} = \\sum_i^N \\hat{\\sigma}_i^z \\] <p>In the following the observable, quantum circuit and corresponding QNN model are constructed.</p> <pre><code>import qadence as qd\nimport qadence_model as qdm\n\nn_qubits = 4\n\n# create a simple feature map to encode the input data\nfeature_param = qd.FeatureParameter(\"phi\")\nfeature_map = qd.kron(qd.RX(i, feature_param) for i in range(n_qubits))\nfeature_map = qd.tag(feature_map, \"feature_map\")\n\n# create a digital-analog variational ansatz using Qadence convenience constructors\nansatz = qd.hea(n_qubits, depth=n_qubits)\nansatz = qd.tag(ansatz, \"ansatz\")\n\n# total qubit magnetization observable\nobservable = qd.hamiltonian_factory(n_qubits, detuning=qd.Z)\n\ncircuit = qd.QuantumCircuit(n_qubits, feature_map, ansatz)\nmodel = qdm.models.QNN(circuit, [observable])\nexpval = model(values=torch.rand(10))\n</code></pre> <pre><code>tensor([[ 0.0092],\n        [-0.0207],\n        [-0.4616],\n        [-0.1845],\n        [-0.3761],\n        [-0.1463],\n        [-0.4563],\n        [-0.0016],\n        [-0.3436],\n        [-0.4252]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> <p>The QCL algorithm uses the output of the quantum neural network as a tunable universal function approximator. Standard PyTorch code is used for training the QNN using a mean-square error loss, Adam optimizer. Training is performend on the GPU if available:</p> <pre><code>n_epochs = 100\nlr = 0.25\n\ninput_values = {\"phi\": x_train}\nmse_loss = torch.nn.MSELoss()  # standard PyTorch loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)  # standard PyTorch Adam optimizer\n\nprint(f\"Initial loss: {mse_loss(model(values=x_train), y_train)}\")\ny_pred_initial = model(values=x_test)\n\nfor i in range(n_epochs):\n\n    optimizer.zero_grad()\n\n    # given a `n_batch` number of input points and a `n_observables`\n    # number of input observables to measure, the QNN returns\n    # an output of the following shape: [n_batch x n_observables]\n    # given that there is only one observable, a squeeze is applied to get\n    # a 1-dimensional tensor\n    loss = mse_loss(model(values=x_train).squeeze(), y_train)\n    loss.backward()\n    optimizer.step()\n\n    if (i+1) % 20 == 0:\n        print(f\"Epoch {i+1} - Loss: {loss.item()}\")\n\nassert loss.item() &lt; 1e-3\n</code></pre> <pre><code>Initial loss: 0.6272721767455237\nEpoch 20 - Loss: 0.008173087377230498\nEpoch 40 - Loss: 0.0011247726222838813\nEpoch 60 - Loss: 0.0001415308609619855\nEpoch 80 - Loss: 2.3606578815826947e-05\nEpoch 100 - Loss: 2.503287372853267e-06\n</code></pre> <p>Qadence-model offers some convenience functions to implement this training loop with advanced logging and metrics track features.</p> <p>The quantum model is now trained on the training data points. To determine the quality of the results, one can check to see how well it fits the function on the test set.</p> <pre><code>import matplotlib.pyplot as plt\n\ny_pred = model({\"phi\": x_test})\n\n# convert all the results to numpy arrays for plotting\nx_train_np = x_train.cpu().detach().numpy().flatten()\ny_train_np = y_train.cpu().detach().numpy().flatten()\nx_test_np = x_test.cpu().detach().numpy().flatten()\ny_test_np = y_test.cpu().detach().numpy().flatten()\ny_pred_initial_np = y_pred_initial.cpu().detach().numpy().flatten()\ny_pred_np = y_pred.cpu().detach().numpy().flatten()\n\nfig, _ = plt.subplots()\nplt.scatter(x_test_np, y_test_np, label=\"Test points\", marker=\"o\", color=\"orange\")\nplt.plot(x_test_np, y_pred_initial_np, label=\"Initial prediction\", color=\"green\", alpha=0.5)\nplt.plot(x_test_np, y_pred_np, label=\"Final prediction\")\nplt.legend()\n</code></pre> 2025-06-12T18:24:36.639430 image/svg+xml Matplotlib v3.10.3, https://matplotlib.org/"},{"location":"model/tutorials/qcl/#references","title":"References","text":"<ol> <li> <p>Mitarai et al., Quantum Circuit Learning \u21a9</p> </li> </ol>"},{"location":"model/tutorials/qng/","title":"The Quantum Natural Gradient optimizer","text":"<p>Qadence-Model provides a set of optimizers based on quantum information tools, in particular based on the Quantum Fisher Information<sup>1</sup> (QFI). The Quantum Natural Gradient <sup>2</sup> (QNG) is a gradient-based optimizer which uses the QFI matrix to better navigate the optimizer's descent to the minimum. The parameter update rule for the QNG optimizer is written as:</p> \\[ \\theta_{t+1} = \\theta_t - \\eta g^{-1}(\\theta_t)\\nabla \\mathcal{L}(\\theta_t) \\] <p>where \\(g(\\theta)\\) is the Fubiny-Study metric tensor (aka Quantum Geometric Tensor), which is equivalent to the Quantum Fisher Information matrix \\(F(\\theta)\\) up to a constant factor \\(F(\\theta)= 4 g(\\theta)\\). The Quantum Fisher Information can be written as the Hessian of the fidelity of a quantum state:</p> \\[   F_{i j}(\\theta)=-\\left.2 \\frac{\\partial}{\\partial \\theta_i} \\frac{\\partial}{\\partial \\theta_j}\\left|\\left\\langle\\psi\\left(\\theta^{\\prime}\\right) \\mid \\psi(\\theta)\\right\\rangle\\right|^2\\right|_{{\\theta}^{\\prime}=\\theta} \\] <p>However, computing the above expression is a costly operation scaling quadratically with the number of parameters in the variational quantum circuit. It is thus usual to use approximate methods when dealing with the QFI matrix. Qadence-Model provides a SPSA-based implementation of the Quantum Natural Gradient<sup>3</sup>. The SPSA (Simultaneous Perturbation Stochastic Approximation) algorithm is a well known finite differences-based algorithm. QNG-SPSA constructs an iterative approximation to the QFI matrix with a constant number of circuit evaluations that does not scale with the number of parameters. Although the SPSA algorithm outputs a rough approximation of the QFI matrix, the QNG-SPSA has been proven to work well while being a very efficient method due to the constant overhead in circuit evaluations (only 6 extra evaluations per iteration).</p> <p>In this tutorial, we use the QNG and QNG-SPSA optimizers with the Quantum Circuit Learning algorithm, a variational quantum algorithm which uses Quantum Neural Networks as universal function approximators.</p> <p>Keep in mind that only circuit parameters can be optimized with the QNG optimizer, since we can only calculate the QFI matrix of parameters contained in the circuit. If your model holds other trainable, non-circuit parameters, such as scaling or shifting of the input/output, another optimizer must be used for to optimize those parameters. <pre><code>import torch\nfrom torch.utils.data import random_split\nimport random\nimport matplotlib.pyplot as plt\n\nfrom qadence import QuantumCircuit, FeatureParameter\nfrom qadence import kron, tag, hea, RX, Z, hamiltonian_factory\n\nfrom qadence_model.models import QNN\nfrom qadence_model.optimizers import QuantumNaturalGradient\nfrom qadence_model.types import FisherApproximation\n</code></pre> </p> <p>First, we prepare the Quantum Circuit Learning data. In this case we will fit a simple one-dimensional sin(\\(x\\)) function: <pre><code># Ensure reproducibility\nseed = 0\ntorch.manual_seed(seed)\nrandom.seed(seed)\n\n# Create dataset\ndef qcl_training_data(\n    domain: tuple = (0, 2 * torch.pi), n_points: int = 200\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    start, end = domain\n\n    x_rand, _ = torch.sort(torch.DoubleTensor(n_points).uniform_(start, end))\n    y_rand = torch.sin(x_rand)\n\n    return x_rand, y_rand\n\n\nx, y = qcl_training_data()\n\n# random train/test split of the dataset\ntrain_subset, test_subset = random_split(x, [0.75, 0.25])\ntrain_ind = sorted(train_subset.indices)\ntest_ind = sorted(test_subset.indices)\n\nx_train, y_train = x[train_ind], y[train_ind]\nx_test, y_test = x[test_ind], y[test_ind]\n</code></pre> </p> <p>We now create the base Quantum Circuit that we will use with all the optimizers: <pre><code>n_qubits = 3\n\n# create a simple feature map to encode the input data\nfeature_param = FeatureParameter(\"phi\")\nfeature_map = kron(RX(i, feature_param) for i in range(n_qubits))\nfeature_map = tag(feature_map, \"feature_map\")\n\n# create a digital-analog variational ansatz using Qadence convenience constructors\nansatz = hea(n_qubits, depth=n_qubits)\nansatz = tag(ansatz, \"ansatz\")\n\n# Observable\nobservable = hamiltonian_factory(n_qubits, detuning= Z)\n</code></pre> </p>"},{"location":"model/tutorials/qng/#optimizers","title":"Optimizers","text":"<p>We will experiment with three different optimizers: ADAM, QNG and QNG-SPSA. To train a model with the different optimizers we will create a <code>QuantumModel</code> and reset the values of their variational parameters before each training loop so that all of them have the same starting point.</p> <pre><code># Build circuit and model\ncircuit = QuantumCircuit(n_qubits, feature_map, ansatz)\nmodel = QNN(circuit, [observable])\n\n# Loss function\nmse_loss = torch.nn.MSELoss()\n\n# Initial parameter values\ninitial_params = torch.rand(model.num_vparams)\n</code></pre> <p>We can now train the model with the different corresponding optimizers:</p>"},{"location":"model/tutorials/qng/#adam","title":"ADAM","text":"<pre><code># Train with ADAM\nn_epochs_adam = 20\nlr_adam = 0.1\n\nmodel.reset_vparams(initial_params)\noptimizer = torch.optim.Adam(model.parameters(), lr=lr_adam)\n\nloss_adam = []\nfor i in range(n_epochs_adam):\n    optimizer.zero_grad()\n    loss = mse_loss(model(values=x_train).squeeze(), y_train.squeeze())\n    loss_adam.append(float(loss))\n    loss.backward()\n    optimizer.step()\n</code></pre>"},{"location":"model/tutorials/qng/#qng","title":"QNG","text":"<p>The way to initialize the <code>QuantumNaturalGradient</code> optimizer in <code>qadence-model</code> is slightly different from other usual Torch optimizers. Normally, one needs to pass a <code>params</code> argument to the optimizer to specify which parameters of the model should be optimized. In the <code>QuantumNaturalGradient</code>, it is assumed that all circuit parameters are to be optimized, whereas the non-circuit parameters will not be optimized. By circuit parameters, we mean parameters that somehow affect the quantum gates of the circuit and therefore influence the final quantum state. Any parameters affecting the observable (such as ouput scaling or shifting) are not considered circuit parameters, as those parameters will not be included in the QFI matrix as they don't affect the final state of the circuit.</p> <p>The <code>QuantumNaturalGradient</code> constructor takes a qadence's <code>QuantumModel</code> as the <code>model</code>, and it will automatically identify its circuit and non-circuit parameters. The <code>approximation</code> argument defaults to the SPSA method, however the exact version of the QNG is also implemented and can be used for small circuits (beware of using the exact version for large circuits, as it scales badly). \\(\\beta\\) is a small constant added to the QFI matrix before inversion to ensure numerical stability,</p> \\[(F_{ij} + \\beta \\mathbb{I})^{-1}\\] <p>where \\(\\mathbb{I}\\) is the identify matrix. It is always a good idea to try out different values of \\(\\beta\\) if the training is not converging, which might be due to a too small \\(\\beta\\).</p> <pre><code># Train with QNG\nn_epochs_qng = 20\nlr_qng = 0.1\n\nmodel.reset_vparams(initial_params)\noptimizer = QuantumNaturalGradient(\n    model=model,\n    lr=lr_qng,\n    approximation=FisherApproximation.EXACT,\n    beta=0.1,\n)\n\nloss_qng = []\nfor i in range(n_epochs_qng):\n    optimizer.zero_grad()\n    loss = mse_loss(model(values=x_train).squeeze(), y_train.squeeze())\n    loss_qng.append(float(loss))\n    loss.backward()\n    optimizer.step()\n</code></pre>"},{"location":"model/tutorials/qng/#qng-spsa","title":"QNG-SPSA","text":"<p>The QNG-SPSA optimizer can be constructed similarly to the exact QNG, where now a new argument \\(\\epsilon\\) is used to control the shift used in the finite differences derivatives of the SPSA algorithm.</p> <pre><code># Train with QNG-SPSA\nn_epochs_qng_spsa = 20\nlr_qng_spsa = 0.01\n\nmodel.reset_vparams(initial_params)\noptimizer = QuantumNaturalGradient(\n    model=model,\n    lr=lr_qng_spsa,\n    approximation=FisherApproximation.SPSA,\n    beta=0.1,\n    epsilon=0.01,\n)\n\nloss_qng_spsa = []\nfor i in range(n_epochs_qng_spsa):\n    optimizer.zero_grad()\n    loss = mse_loss(model(values=x_train).squeeze(), y_train.squeeze())\n    loss_qng_spsa.append(float(loss))\n    loss.backward()\n    optimizer.step()\n</code></pre>"},{"location":"model/tutorials/qng/#plotting","title":"Plotting","text":"<p>We now plot the losses corresponding to each of the optimizers: <pre><code># Plot losses\nfig, _ = plt.subplots()\nplt.plot(range(n_epochs_adam), loss_adam, label=\"Adam optimizer\")\nplt.plot(range(n_epochs_qng), loss_qng, label=\"QNG optimizer\")\nplt.plot(range(n_epochs_qng_spsa), loss_qng_spsa, label=\"QNG-SPSA optimizer\")\nplt.legend()\nplt.xlabel(\"Training epochs\")\nplt.ylabel(\"Loss\")\n</code></pre> </p>"},{"location":"model/tutorials/qng/#references","title":"References","text":"<ol> <li> <p>Meyer J., Information in Noisy Intermediate-Scale Quantum Applications, Quantum 5, 539 (2021) \u21a9</p> </li> <li> <p>Stokes et al., Quantum Natural Gradient, Quantum 4, 269 (2020). \u21a9</p> </li> <li> <p>Gacon et al., Simultaneous Perturbation Stochastic Approximation of the Quantum Fisher Information, Quantum 5, 567 (2021). \u21a9</p> </li> </ol>"}]}